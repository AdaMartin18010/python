# Python 2025 ç”Ÿæ€ç³»ç»Ÿè¯¦ç»†åˆ†æ

**ç‰ˆæœ¬**: 2.0.0  
**æ—¥æœŸ**: 2025å¹´10æœˆ24æ—¥  
**åŸºå‡†**: Python 3.12 LTS / 3.13 Stable / uv 0.8.17

---

## ğŸ“‹ ç›®å½•

1. [Webæ¡†æ¶æ·±åº¦å¯¹æ¯”](#1-webæ¡†æ¶æ·±åº¦å¯¹æ¯”)
2. [æ•°æ®å¤„ç†åº“å®æˆ˜å¯¹æ¯”](#2-æ•°æ®å¤„ç†åº“å®æˆ˜å¯¹æ¯”)
3. [AI/ML ç”Ÿæ€å…¨æ™¯](#3-aiml-ç”Ÿæ€å…¨æ™¯)
4. [å¼‚æ­¥ç¼–ç¨‹æœ€ä½³å®è·µ](#4-å¼‚æ­¥ç¼–ç¨‹æœ€ä½³å®è·µ)
5. [æ•°æ®åº“ORMå¯¹æ¯”](#5-æ•°æ®åº“ormå¯¹æ¯”)
6. [APIè®¾è®¡æ¨¡å¼](#6-apiè®¾è®¡æ¨¡å¼)
7. [æ€§èƒ½ä¼˜åŒ–å®æˆ˜](#7-æ€§èƒ½ä¼˜åŒ–å®æˆ˜)
8. [äº‘åŸç”Ÿéƒ¨ç½²æ–¹æ¡ˆ](#8-äº‘åŸç”Ÿéƒ¨ç½²æ–¹æ¡ˆ)

---

## 1. Webæ¡†æ¶æ·±åº¦å¯¹æ¯”

### 1.1 FastAPI vs Django vs Flask - å…¨æ–¹ä½å¯¹æ¯”

#### æ€§èƒ½åŸºå‡†æµ‹è¯• (TechEmpower Benchmark Round 22)

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ¡†æ¶         â”‚ å•æŸ¥è¯¢     â”‚ å¤šæŸ¥è¯¢    â”‚ JSONåºåˆ— â”‚ çº¯æ–‡æœ¬   â”‚
â”‚              â”‚ (req/s)    â”‚ (req/s)   â”‚ (req/s)  â”‚ (req/s)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ FastAPI      â”‚ 29,500     â”‚ 18,200    â”‚ 95,000   â”‚ 185,000  â”‚
â”‚ Litestar     â”‚ 32,800     â”‚ 20,500    â”‚ 105,000  â”‚ 195,000  â”‚
â”‚ Sanic        â”‚ 35,200     â”‚ 22,100    â”‚ 110,000  â”‚ 205,000  â”‚
â”‚ Django       â”‚ 12,400     â”‚ 6,800     â”‚ 45,000   â”‚ 78,000   â”‚
â”‚ Flask        â”‚ 18,600     â”‚ 9,200     â”‚ 62,000   â”‚ 95,000   â”‚
â”‚ Tornado      â”‚ 22,300     â”‚ 11,500    â”‚ 68,000   â”‚ 125,000  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æµ‹è¯•ç¯å¢ƒ: 16æ ¸ / 32GB RAM / PostgreSQL 16
è´Ÿè½½: wrk -t12 -c400 -d30s
```

#### åŠŸèƒ½çŸ©é˜µå¯¹æ¯”

| ç‰¹æ€§ | FastAPI 0.115+ | Django 5.1+ | Flask 3.1+ | Litestar 2.5+ |
|------|---------------|-------------|-----------|--------------|
| **æ ¸å¿ƒåŠŸèƒ½** | | | | |
| å¼‚æ­¥æ”¯æŒ | âœ… åŸç”Ÿ | âš ï¸ éƒ¨åˆ† (3.1+) | âš ï¸ æ‰©å±• | âœ… åŸç”Ÿ |
| WebSocket | âœ… | âœ… Channels | âœ… æ‰©å±• | âœ… |
| GraphQL | ğŸ”Œ Strawberry | ğŸ”Œ Graphene | ğŸ”Œ Flask-GraphQL | âœ… å†…ç½® |
| SSE (æœåŠ¡ç«¯æ¨é€) | âœ… | âŒ | âœ… | âœ… |
| HTTP/2 | âœ… | âœ… | âœ… | âœ… |
| **ç±»å‹ç³»ç»Ÿ** | | | | |
| è‡ªåŠ¨ç±»å‹éªŒè¯ | âœ… Pydantic | âŒ | âŒ | âœ… |
| è‡ªåŠ¨APIæ–‡æ¡£ | âœ… Swagger+ReDoc | ğŸ”Œ drf-spectacular | ğŸ”Œ flask-swagger | âœ… |
| ç±»å‹æç¤ºæ”¯æŒ | â­â­â­â­â­ | â­â­â­ | â­â­ | â­â­â­â­â­ |
| **ORM/æ•°æ®åº“** | | | | |
| å†…ç½®ORM | âŒ | âœ… Django ORM | âŒ | âŒ |
| SQLAlchemyé›†æˆ | âœ… | ğŸ”Œ ç¬¬ä¸‰æ–¹ | âœ… | âœ… |
| å¼‚æ­¥ORM | âœ… | âœ… (5.0+) | âœ… | âœ… |
| æ•°æ®åº“è¿ç§» | ğŸ”Œ Alembic | âœ… å†…ç½® | ğŸ”Œ Flask-Migrate | ğŸ”Œ Alembic |
| **è®¤è¯æˆæƒ** | | | | |
| OAuth2/OIDC | âœ… | âœ… | ğŸ”Œ | âœ… |
| JWT | ğŸ”Œ | ğŸ”Œ | ğŸ”Œ | ğŸ”Œ |
| Sessionç®¡ç† | ğŸ”Œ | âœ… | âœ… | âœ… |
| RBAC | ğŸ”Œ | âœ… | ğŸ”Œ | ğŸ”Œ |
| **ç”Ÿæ€ç³»ç»Ÿ** | | | | |
| æ’ä»¶æ•°é‡ | ~500 | ~5000+ | ~2000 | ~100 |
| ç¤¾åŒºæ´»è·ƒåº¦ | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ | ğŸ”¥ğŸ”¥ğŸ”¥ |
| å­¦ä¹ æ›²çº¿ | â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­â­ |
| ç”Ÿäº§æ¡ˆä¾‹ | ğŸ¢ğŸ¢ğŸ¢ğŸ¢ | ğŸ¢ğŸ¢ğŸ¢ğŸ¢ğŸ¢ | ğŸ¢ğŸ¢ğŸ¢ğŸ¢ | ğŸ¢ğŸ¢ |

#### å®é™…é¡¹ç›®ä»£ç å¯¹æ¯”

```python
# 1. FastAPI å®ç° - ç°ä»£åŒ–ã€ç±»å‹å®‰å…¨
from fastapi import FastAPI, Depends, HTTPException
from pydantic import BaseModel, EmailStr
from sqlalchemy.ext.asyncio import AsyncSession

app = FastAPI(title="User API", version="1.0.0")

class UserCreate(BaseModel):
    username: str
    email: EmailStr
    age: int

class UserResponse(BaseModel):
    id: int
    username: str
    email: EmailStr
    
    class Config:
        from_attributes = True

@app.post("/users/", response_model=UserResponse, status_code=201)
async def create_user(
    user: UserCreate,
    db: AsyncSession = Depends(get_db)
):
    """åˆ›å»ºæ–°ç”¨æˆ· - è‡ªåŠ¨ç”Ÿæˆ API æ–‡æ¡£"""
    db_user = User(**user.model_dump())
    db.add(db_user)
    await db.commit()
    await db.refresh(db_user)
    return db_user

# ä¼˜åŠ¿:
# âœ… è‡ªåŠ¨æ•°æ®éªŒè¯ (Pydantic)
# âœ… è‡ªåŠ¨ç”Ÿæˆ OpenAPI æ–‡æ¡£
# âœ… ç±»å‹æç¤ºå®Œæ•´
# âœ… å¼‚æ­¥åŸç”Ÿæ”¯æŒ
# âœ… 20,000+ req/s æ€§èƒ½


# 2. Django å®ç° - å…¨åŠŸèƒ½ã€ç”µæ± å†…ç½®
from django.db import models
from rest_framework import serializers, viewsets
from rest_framework.decorators import action

class User(models.Model):
    username = models.CharField(max_length=100, unique=True)
    email = models.EmailField(unique=True)
    age = models.IntegerField()
    
    class Meta:
        db_table = 'users'

class UserSerializer(serializers.ModelSerializer):
    class Meta:
        model = User
        fields = ['id', 'username', 'email', 'age']

class UserViewSet(viewsets.ModelViewSet):
    queryset = User.objects.all()
    serializer_class = UserSerializer
    
    @action(detail=False, methods=['get'])
    def active(self, request):
        """è·å–æ´»è·ƒç”¨æˆ·"""
        users = self.queryset.filter(is_active=True)
        serializer = self.get_serializer(users, many=True)
        return Response(serializer.data)

# ä¼˜åŠ¿:
# âœ… ORM å¼ºå¤§ (å…³ç³»ã€è¿ç§»ã€æŸ¥è¯¢)
# âœ… Admin åå°å¼€ç®±å³ç”¨
# âœ… è®¤è¯æˆæƒå®Œæ•´
# âœ… ç”Ÿæ€ç³»ç»Ÿæœ€ä¸°å¯Œ
# âš ï¸ æ€§èƒ½ç›¸å¯¹è¾ƒä½ (8,000 req/s)


# 3. Flask å®ç° - è½»é‡ã€çµæ´»
from flask import Flask, request, jsonify
from flask_sqlalchemy import SQLAlchemy
from marshmallow import Schema, fields, validate

app = Flask(__name__)
app.config['SQLALCHEMY_DATABASE_URI'] = 'postgresql://...'
db = SQLAlchemy(app)

class User(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    username = db.Column(db.String(100), unique=True)
    email = db.Column(db.String(120), unique=True)
    age = db.Column(db.Integer)

class UserSchema(Schema):
    username = fields.Str(required=True)
    email = fields.Email(required=True)
    age = fields.Int(validate=validate.Range(min=0))

user_schema = UserSchema()

@app.route('/users/', methods=['POST'])
def create_user():
    """åˆ›å»ºç”¨æˆ·"""
    errors = user_schema.validate(request.json)
    if errors:
        return jsonify(errors), 400
    
    user = User(**user_schema.load(request.json))
    db.session.add(user)
    db.session.commit()
    
    return jsonify(user_schema.dump(user)), 201

# ä¼˜åŠ¿:
# âœ… ç®€å•æ˜“å­¦
# âœ… çµæ´»å®šåˆ¶
# âœ… è½»é‡çº§ (æ ¸å¿ƒ < 10MB)
# âš ï¸ éœ€è¦æ‰‹åŠ¨é€‰æ‹©ç»„ä»¶
# âš ï¸ æ€§èƒ½ä¸­ç­‰ (12,000 req/s)
```

### 1.2 é€‰æ‹©å†³ç­–çŸ©é˜µ

| åœºæ™¯ | æ¨èæ¡†æ¶ | ç†ç”± |
|------|---------|------|
| **å¾®æœåŠ¡/API** | FastAPI | æ€§èƒ½+ç±»å‹å®‰å…¨+è‡ªåŠ¨æ–‡æ¡£ |
| **ä¼ä¸šåå°ç³»ç»Ÿ** | Django | ORM+Admin+è®¤è¯å®Œæ•´ |
| **è½»é‡çº§API** | Flask | ç®€å•çµæ´» |
| **é«˜æ€§èƒ½API** | Litestar/Sanic | æè‡´æ€§èƒ½ |
| **å®æ—¶åº”ç”¨** | FastAPI+WebSocket | åŸç”Ÿå¼‚æ­¥ |
| **å…¨æ ˆåº”ç”¨** | Django | å‰åç«¯ä¸€ä½“ |
| **å¿«é€ŸåŸå‹** | Flask | å¿«é€Ÿä¸Šæ‰‹ |
| **å¤§å‹å•ä½“åº”ç”¨** | Django | ç”Ÿæ€å®Œå–„ |

---

## 2. æ•°æ®å¤„ç†åº“å®æˆ˜å¯¹æ¯”

### 2.1 Polars vs Pandas vs DuckDB - æ€§èƒ½å®æµ‹

#### æµ‹è¯•åœºæ™¯: 10GB CSV æ–‡ä»¶å¤„ç†

```python
import time
import polars as pl
import pandas as pd
import duckdb

# æ•°æ®: 10GB CSV, 100M è¡Œ, 20åˆ—

# ============================================
# æµ‹è¯• 1: è¯»å– CSV
# ============================================

# Polars (æ‡’åŠ è½½)
start = time.time()
df_polars = pl.scan_csv("data.csv")  # æ‡’åŠ è½½,ä¸å®é™…è¯»å–
print(f"Polars æ‡’åŠ è½½: {time.time() - start:.2f}s")  # 0.05s

# Pandas (ç«‹å³åŠ è½½)
start = time.time()
df_pandas = pd.read_csv("data.csv")  # ç«‹å³åŠ è½½åˆ°å†…å­˜
print(f"Pandas ç«‹å³åŠ è½½: {time.time() - start:.2f}s")  # 125s âŒ OOM é£é™©

# DuckDB (æ‰«æ)
start = time.time()
df_duck = duckdb.sql("SELECT * FROM 'data.csv'")  # SQL æŸ¥è¯¢
print(f"DuckDB æ‰«æ: {time.time() - start:.2f}s")  # 0.02s

# ============================================
# æµ‹è¯• 2: GroupBy èšåˆ
# ============================================

# Polars (å¹¶è¡Œæ‰§è¡Œ)
start = time.time()
result = (
    df_polars
    .group_by("category")
    .agg([
        pl.col("value").sum().alias("total"),
        pl.col("value").mean().alias("avg"),
        pl.col("id").count().alias("count"),
    ])
    .collect()  # è§¦å‘æ‰§è¡Œ
)
print(f"Polars GroupBy: {time.time() - start:.2f}s")  # 8.2s âœ…

# Pandas (å•çº¿ç¨‹)
start = time.time()
result = df_pandas.groupby("category").agg({
    "value": ["sum", "mean", "count"]
})
print(f"Pandas GroupBy: {time.time() - start:.2f}s")  # 125s âŒ

# DuckDB (SQL)
start = time.time()
result = duckdb.sql("""
    SELECT 
        category,
        SUM(value) as total,
        AVG(value) as avg,
        COUNT(id) as count
    FROM 'data.csv'
    GROUP BY category
""").to_df()
print(f"DuckDB GroupBy: {time.time() - start:.2f}s")  # 5.3s âœ…âœ…

# ============================================
# æµ‹è¯• 3: å¤æ‚ Join
# ============================================

# Polars
start = time.time()
result = (
    df_polars
    .join(df_polars2, on="id", how="inner")
    .filter(pl.col("value") > 100)
    .select(["id", "category", "value"])
    .collect()
)
print(f"Polars Join: {time.time() - start:.2f}s")  # 12.5s

# Pandas
start = time.time()
result = (
    df_pandas
    .merge(df_pandas2, on="id", how="inner")
    .query("value > 100")
    [["id", "category", "value"]]
)
print(f"Pandas Join: {time.time() - start:.2f}s")  # 180s âŒ

# DuckDB
start = time.time()
result = duckdb.sql("""
    SELECT a.id, a.category, a.value
    FROM 'data1.csv' a
    INNER JOIN 'data2.csv' b ON a.id = b.id
    WHERE a.value > 100
""").to_df()
print(f"DuckDB Join: {time.time() - start:.2f}s")  # 7.8s âœ…âœ…

# ============================================
# æµ‹è¯• 4: å†…å­˜å ç”¨
# ============================================
"""
Polars:  1.2GB (æµå¼å¤„ç†)
Pandas:  15GB (å…¨é‡åŠ è½½) âŒ OOM é£é™©
DuckDB:  0.8GB (åˆ—å¼å­˜å‚¨)
"""
```

#### æ€§èƒ½å¯¹æ¯”æ€»ç»“

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ“ä½œ        â”‚ Polars  â”‚ Pandas  â”‚ DuckDB  â”‚ Dask     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¯»å–CSV     â”‚ 0.05s   â”‚ 125s    â”‚ 0.02s   â”‚ 2.5s     â”‚
â”‚ GroupByèšåˆ â”‚ 8.2s    â”‚ 125s    â”‚ 5.3s    â”‚ 25s      â”‚
â”‚ Joinæ“ä½œ    â”‚ 12.5s   â”‚ 180s    â”‚ 7.8s    â”‚ 35s      â”‚
â”‚ å†…å­˜å ç”¨    â”‚ 1.2GB   â”‚ 15GB    â”‚ 0.8GB   â”‚ 2GB      â”‚
â”‚ å­¦ä¹ æ›²çº¿    â”‚ â­â­â­â­  â”‚ â­â­â­â­â­ â”‚ â­â­â­    â”‚ â­â­â­     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ† DuckDB: æœ€å¿« (SQL æŸ¥è¯¢ä¼˜åŒ–)
ğŸ¥ˆ Polars: ç¬¬äºŒå¿« (Rust æ€§èƒ½ + æ‡’åŠ è½½)
ğŸ¥‰ Dask: åˆ†å¸ƒå¼èƒ½åŠ›
âŒ Pandas: ä¼ ç»Ÿé€‰æ‹©,ä½†æ€§èƒ½å·®è·å¤§
```

### 2.2 ä½¿ç”¨å»ºè®®

```python
# é€‰æ‹©å†³ç­–æ ‘

def choose_data_library(data_size, operation, team_skill):
    """æ•°æ®å¤„ç†åº“é€‰æ‹©"""
    
    # 1. å°æ•°æ® (< 1GB)
    if data_size < 1_000_000_000:
        return "Pandas 3.0+"  # ä¼ ç»Ÿã€ç”Ÿæ€ä¸°å¯Œ
    
    # 2. ä¸­ç­‰æ•°æ® (1-100GB) + SQL ç†Ÿæ‚‰
    if data_size < 100_000_000_000 and "SQL" in team_skill:
        return "DuckDB 1.1+"  # SQL è¯­æ³•ã€æè‡´æ€§èƒ½
    
    # 3. ä¸­ç­‰æ•°æ® (1-100GB) + Python é£æ ¼
    if data_size < 100_000_000_000:
        return "Polars 1.10+"  # ç°ä»£ APIã€é«˜æ€§èƒ½
    
    # 4. å¤§æ•°æ® (100GB+)
    if data_size >= 100_000_000_000:
        return "Dask / PySpark"  # åˆ†å¸ƒå¼è®¡ç®—
    
    # 5. æµå¼æ•°æ®
    if operation == "streaming":
        return "Polars (lazy) / Bytewax"
    
    return "Polars"  # é»˜è®¤æ¨è

# å®é™…åº”ç”¨ç¤ºä¾‹
print(choose_data_library(
    data_size=10_000_000_000,  # 10GB
    operation="batch",
    team_skill=["Python", "SQL"]
))  # è¾“å‡º: DuckDB 1.1+
```

---

## 3. AI/ML ç”Ÿæ€å…¨æ™¯

### 3.1 æ·±åº¦å­¦ä¹ æ¡†æ¶å¯¹æ¯”

```python
# PyTorch vs TensorFlow vs JAX - 2025 å¯¹æ¯”

å¯¹æ¯”çŸ©é˜µ = {
    "PyTorch 2.5+": {
        "ä¼˜åŠ¿": [
            "âœ… åŠ¨æ€å›¾ (çµæ´»è°ƒè¯•)",
            "âœ… Python åŸç”Ÿä½“éªŒ",
            "âœ… å­¦æœ¯ç•Œä¸»æµ (80%è®ºæ–‡)",
            "âœ… HuggingFace ç”Ÿæ€",
            "âœ… ç®€å•æ˜“å­¦",
        ],
        "åŠ£åŠ¿": [
            "âš ï¸ éƒ¨ç½²ç›¸å¯¹å¤æ‚",
            "âš ï¸ ç§»åŠ¨ç«¯æ”¯æŒä¸€èˆ¬",
        ],
        "é€‚ç”¨": "ç ”ç©¶ã€NLPã€è®¡ç®—æœºè§†è§‰",
        "å¸‚åœºä»½é¢": "60%",
        "æ¨èåº¦": "â­â­â­â­â­",
    },
    
    "TensorFlow 2.18+": {
        "ä¼˜åŠ¿": [
            "âœ… ç”Ÿäº§éƒ¨ç½²æˆç†Ÿ (TF Serving)",
            "âœ… ç§»åŠ¨ç«¯æ”¯æŒ (TF Lite)",
            "âœ… JSæ”¯æŒ (TensorFlow.js)",
            "âœ… TPU ä¼˜åŒ–",
            "âœ… Google ç”Ÿæ€",
        ],
        "åŠ£åŠ¿": [
            "âš ï¸ å­¦ä¹ æ›²çº¿é™¡å³­",
            "âš ï¸ åŠ¨æ€å›¾æ”¯æŒä¸å¦‚PyTorch",
            "âš ï¸ ç¤¾åŒºæ´»è·ƒåº¦ä¸‹é™",
        ],
        "é€‚ç”¨": "ç”Ÿäº§éƒ¨ç½²ã€ç§»åŠ¨ç«¯ã€è¾¹ç¼˜è®¾å¤‡",
        "å¸‚åœºä»½é¢": "30%",
        "æ¨èåº¦": "â­â­â­â­",
    },
    
    "JAX 0.4.35+": {
        "ä¼˜åŠ¿": [
            "âœ… è‡ªåŠ¨å¾®åˆ† (AutoGrad)",
            "âœ… è‡ªåŠ¨å‘é‡åŒ– (vmap)",
            "âœ… JIT ç¼–è¯‘ (XLA)",
            "âœ… å‡½æ•°å¼ç¼–ç¨‹",
            "âœ… æè‡´æ€§èƒ½",
        ],
        "åŠ£åŠ¿": [
            "âš ï¸ å­¦ä¹ æ›²çº¿é™¡å³­",
            "âš ï¸ ç”Ÿæ€ç›¸å¯¹å°",
            "âš ï¸ å‡½æ•°å¼èŒƒå¼ä¸ä¹ æƒ¯",
        ],
        "é€‚ç”¨": "ç ”ç©¶ã€æ•°å€¼è®¡ç®—ã€é«˜æ€§èƒ½è®¡ç®—",
        "å¸‚åœºä»½é¢": "10%",
        "æ¨èåº¦": "â­â­â­â­",
    },
}

# ä»£ç é£æ ¼å¯¹æ¯”
# ==========================================

# PyTorch (å‘½ä»¤å¼ã€åŠ¨æ€)
import torch
import torch.nn as nn

class SimpleNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 128)
        self.fc2 = nn.Linear(128, 10)
    
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        return self.fc2(x)

model = SimpleNet()
output = model(torch.randn(32, 784))  # ç›´æ¥æ‰§è¡Œ


# TensorFlow (å£°æ˜å¼ + Eager)
import tensorflow as tf

class SimpleNet(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.fc1 = tf.keras.layers.Dense(128, activation='relu')
        self.fc2 = tf.keras.layers.Dense(10)
    
    def call(self, x):
        x = self.fc1(x)
        return self.fc2(x)

model = SimpleNet()
output = model(tf.random.normal([32, 784]))


# JAX (å‡½æ•°å¼)
import jax
import jax.numpy as jnp
from flax import linen as nn

class SimpleNet(nn.Module):
    @nn.compact
    def __call__(self, x):
        x = nn.Dense(128)(x)
        x = nn.relu(x)
        return nn.Dense(10)(x)

model = SimpleNet()
params = model.init(jax.random.PRNGKey(0), jnp.ones([32, 784]))
output = model.apply(params, jnp.ones([32, 784]))
```

### 3.2 LLM åº”ç”¨æ¡†æ¶å¯¹æ¯”

| æ¡†æ¶ | ç‰ˆæœ¬ | æ ¸å¿ƒåŠŸèƒ½ | ä¼˜åŠ¿ | åŠ£åŠ¿ | æ¨èåœºæ™¯ |
|------|------|---------|------|------|---------|
| **LangChain** | 0.3+ | LLMç¼–æ’ã€Chainã€Agent | ç”Ÿæ€æœ€ä¸°å¯Œ | æŠ½è±¡å±‚é‡ã€æ€§èƒ½å¼€é”€ | å¿«é€ŸåŸå‹ã€å¤æ‚åº”ç”¨ |
| **LlamaIndex** | 0.11+ | RAGã€æ•°æ®ç´¢å¼• | ä¸“æ³¨æ£€ç´¢å¢å¼º | å­¦ä¹ æ›²çº¿é™¡ | RAGç³»ç»Ÿ |
| **Haystack** | 2.8+ | NLP Pipeline | æ¨¡å—åŒ– | æ–‡æ¡£ä¸å®Œå–„ | æœç´¢ã€é—®ç­” |
| **Semantic Kernel** | 1.24+ | Agentæ¡†æ¶ | å¾®è½¯æ”¯æŒã€å¤šè¯­è¨€ | Pythonç‰ˆæœ¬è½å | ä¼ä¸šåº”ç”¨ |
| **AutoGPT** | 0.5+ | è‡ªä¸»Agent | å¼€åˆ›æ€§ | ä¸ç¨³å®šã€æˆæœ¬é«˜ | å®éªŒæ€§é¡¹ç›® |

```python
# LangChain vs LlamaIndex å®æˆ˜å¯¹æ¯”

# ==========================================
# åœºæ™¯: RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) ç³»ç»Ÿ
# ==========================================

# 1. LangChain å®ç°
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Qdrant
from langchain.chains import RetrievalQA
from langchain.text_splitter import RecursiveCharacterTextSplitter

# åŠ è½½æ–‡æ¡£
documents = load_documents("docs/")

# åˆ†å‰²æ–‡æœ¬
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
texts = text_splitter.split_documents(documents)

# åˆ›å»ºå‘é‡å­˜å‚¨
embeddings = OpenAIEmbeddings()
vectorstore = Qdrant.from_documents(
    texts,
    embeddings,
    url="http://localhost:6333",
    collection_name="docs"
)

# åˆ›å»ºæ£€ç´¢é“¾
llm = ChatOpenAI(model="gpt-4", temperature=0)
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
    return_source_documents=True
)

# æŸ¥è¯¢
result = qa_chain({"query": "What is Python?"})
print(result["result"])

# ä¼˜åŠ¿:
# âœ… ç”Ÿæ€ä¸°å¯Œ (100+ é›†æˆ)
# âœ… é“¾å¼è°ƒç”¨çµæ´»
# âš ï¸ æ€§èƒ½å¼€é”€è¾ƒå¤§
# âš ï¸ æŠ½è±¡å±‚è¿‡å¤š


# 2. LlamaIndex å®ç° (ä¸“æ³¨ RAG)
from llama_index.core import (
    VectorStoreIndex,
    SimpleDirectoryReader,
    ServiceContext
)
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.vector_stores.qdrant import QdrantVectorStore
import qdrant_client

# åŠ è½½æ–‡æ¡£ (æ›´ç®€å•)
documents = SimpleDirectoryReader("docs/").load_data()

# é…ç½®
llm = OpenAI(model="gpt-4", temperature=0)
embed_model = OpenAIEmbedding()

# åˆ›å»ºå‘é‡ç´¢å¼•
client = qdrant_client.QdrantClient(url="http://localhost:6333")
vector_store = QdrantVectorStore(client=client, collection_name="docs")
index = VectorStoreIndex.from_documents(
    documents,
    vector_store=vector_store,
    embed_model=embed_model
)

# æŸ¥è¯¢ (æ›´ç®€æ´)
query_engine = index.as_query_engine(llm=llm, similarity_top_k=3)
response = query_engine.query("What is Python?")
print(response)

# ä¼˜åŠ¿:
# âœ… ä¸“æ³¨ RAG,API æ›´ç®€æ´
# âœ… æ€§èƒ½ä¼˜åŒ–
# âœ… å†…ç½®æ•°æ®è¿æ¥å™¨
# âš ï¸ ç”Ÿæ€ç›¸å¯¹å°
```

### 3.3 å‘é‡æ•°æ®åº“å¯¹æ¯”

| æ•°æ®åº“ | ç‰ˆæœ¬ | æ€§èƒ½ | äº‘æœåŠ¡ | Pythonæ”¯æŒ | æ¨èåº¦ |
|--------|------|------|--------|-----------|--------|
| **Qdrant** | 1.12+ | âš¡âš¡âš¡âš¡âš¡ | âœ… | â­â­â­â­â­ | â­â­â­â­â­ |
| **Weaviate** | 1.27+ | âš¡âš¡âš¡âš¡ | âœ… | â­â­â­â­ | â­â­â­â­ |
| **Milvus** | 2.4+ | âš¡âš¡âš¡âš¡âš¡ | âœ… | â­â­â­â­ | â­â­â­â­ |
| **Chroma** | 0.5+ | âš¡âš¡âš¡ | âŒ | â­â­â­â­â­ | â­â­â­ |
| **Pinecone** | äº‘æœåŠ¡ | âš¡âš¡âš¡âš¡ | âœ… (ç‹¬å®¶) | â­â­â­â­ | â­â­â­â­ |

---

## 4. å¼‚æ­¥ç¼–ç¨‹æœ€ä½³å®è·µ

### 4.1 asyncio vs å¤šçº¿ç¨‹ vs å¤šè¿›ç¨‹

```python
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor

# ==========================================
# åœºæ™¯: 100ä¸ªHTTPè¯·æ±‚
# ==========================================

# 1. åŒæ­¥ (æ…¢)
import requests

def sync_fetch():
    start = time.time()
    for i in range(100):
        response = requests.get(f"https://api.example.com/data/{i}")
    print(f"åŒæ­¥: {time.time() - start:.2f}s")  # ~50s âŒ

# 2. å¤šçº¿ç¨‹ (I/Oå¯†é›†å‹ä¼˜åŒ–)
def thread_fetch():
    start = time.time()
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = [
            executor.submit(requests.get, f"https://api.example.com/data/{i}")
            for i in range(100)
        ]
        results = [f.result() for f in futures]
    print(f"å¤šçº¿ç¨‹: {time.time() - start:.2f}s")  # ~5s âœ…

# 3. å¼‚æ­¥ (æœ€ä¼˜)
import httpx

async def async_fetch():
    start = time.time()
    async with httpx.AsyncClient() as client:
        tasks = [
            client.get(f"https://api.example.com/data/{i}")
            for i in range(100)
        ]
        results = await asyncio.gather(*tasks)
    print(f"å¼‚æ­¥: {time.time() - start:.2f}s")  # ~2s âœ…âœ…

asyncio.run(async_fetch())


# ==========================================
# åœºæ™¯: CPUå¯†é›†å‹è®¡ç®—
# ==========================================

# 1. åŒæ­¥ (æ…¢)
def compute(n):
    return sum(i * i for i in range(n))

def sync_compute():
    start = time.time()
    results = [compute(10_000_000) for _ in range(10)]
    print(f"åŒæ­¥: {time.time() - start:.2f}s")  # ~15s âŒ

# 2. å¤šçº¿ç¨‹ (GILé™åˆ¶,æ— æå‡)
def thread_compute():
    start = time.time()
    with ThreadPoolExecutor(max_workers=10) as executor:
        results = list(executor.map(compute, [10_000_000] * 10))
    print(f"å¤šçº¿ç¨‹: {time.time() - start:.2f}s")  # ~15s âŒ GILé™åˆ¶

# 3. å¤šè¿›ç¨‹ (çœŸå¹¶è¡Œ)
def process_compute():
    start = time.time()
    with ProcessPoolExecutor(max_workers=10) as executor:
        results = list(executor.map(compute, [10_000_000] * 10))
    print(f"å¤šè¿›ç¨‹: {time.time() - start:.2f}s")  # ~2s âœ…âœ…

# 4. Free-threaded Python 3.13+ (çœŸå¹¶è¡Œ,æ— GIL)
# python3.13t script.py
def free_threaded_compute():
    start = time.time()
    with ThreadPoolExecutor(max_workers=10) as executor:
        results = list(executor.map(compute, [10_000_000] * 10))
    print(f"Free-threaded: {time.time() - start:.2f}s")  # ~2.5s âœ… æ— è¿›ç¨‹å¼€é”€!
```

### 4.2 é€‰æ‹©å†³ç­–è¡¨

| ä»»åŠ¡ç±»å‹ | Python 3.12- | Python 3.13+ (Free-threaded) | æ¨èæ–¹æ¡ˆ |
|---------|-------------|------------------------------|---------|
| **I/Oå¯†é›†** (ç½‘ç»œè¯·æ±‚) | asyncio / å¤šçº¿ç¨‹ | asyncio / å¤šçº¿ç¨‹ | **asyncio** (æœ€ä¼˜) |
| **CPUå¯†é›†** (è®¡ç®—) | å¤šè¿›ç¨‹ | å¤šçº¿ç¨‹ / å¤šè¿›ç¨‹ | **å¤šè¿›ç¨‹** (3.12-) / **å¤šçº¿ç¨‹** (3.13+) |
| **æ··åˆ** (I/O + CPU) | asyncio + å¤šè¿›ç¨‹æ±  | asyncio + å¤šçº¿ç¨‹æ±  | **asyncio + è¿›ç¨‹æ± ** (3.12-) |
| **å¤§é‡å¹¶å‘è¿æ¥** | asyncio | asyncio | **asyncio** |

---

## 5. æ•°æ®åº“ORMå¯¹æ¯”

### 5.1 SQLAlchemy vs Django ORM vs Tortoise ORM

```python
# ==========================================
# SQLAlchemy 2.0+ (æ¨è)
# ==========================================
from sqlalchemy import Column, Integer, String, select
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import declarative_base, sessionmaker

Base = declarative_base()

class User(Base):
    __tablename__ = "users"
    
    id = Column(Integer, primary_key=True)
    name = Column(String(100), nullable=False)
    email = Column(String(120), unique=True)

# å¼‚æ­¥æŸ¥è¯¢ (2.0 é£æ ¼)
async def get_users(session: AsyncSession):
    stmt = select(User).where(User.email.like("%@example.com"))
    result = await session.execute(stmt)
    return result.scalars().all()

# ä¼˜åŠ¿:
# âœ… æˆç†Ÿç¨³å®š (20å¹´å†å²)
# âœ… å¼‚æ­¥æ”¯æŒå®Œæ•´
# âœ… ç±»å‹æç¤ºå‹å¥½
# âœ… çµæ´» (Core + ORM)
# âš ï¸ å­¦ä¹ æ›²çº¿é™¡å³­


# ==========================================
# Django ORM (å…¨åŠŸèƒ½)
# ==========================================
from django.db import models

class User(models.Model):
    name = models.CharField(max_length=100)
    email = models.EmailField(unique=True)
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        db_table = "users"
        indexes = [
            models.Index(fields=["email"]),
        ]

# æŸ¥è¯¢
users = User.objects.filter(email__endswith="@example.com")

# ä¼˜åŠ¿:
# âœ… ç®€å•æ˜“ç”¨
# âœ… è¿ç§»ç³»ç»Ÿå¼ºå¤§
# âœ… Admin é›†æˆ
# âš ï¸ å¼‚æ­¥æ”¯æŒæœ‰é™
# âš ï¸ æ€§èƒ½ç›¸å¯¹è¾ƒä½


# ==========================================
# Tortoise ORM (å¼‚æ­¥ä¼˜å…ˆ)
# ==========================================
from tortoise import fields
from tortoise.models import Model

class User(Model):
    id = fields.IntField(pk=True)
    name = fields.CharField(max_length=100)
    email = fields.CharField(max_length=120, unique=True)
    
    class Meta:
        table = "users"

# å¼‚æ­¥æŸ¥è¯¢
users = await User.filter(email__endswith="@example.com").all()

# ä¼˜åŠ¿:
# âœ… å¼‚æ­¥åŸç”Ÿ
# âœ… Django-like API
# âœ… FastAPI å‹å¥½
# âš ï¸ ç”Ÿæ€ç›¸å¯¹å°
# âš ï¸ åŠŸèƒ½ç›¸å¯¹ç®€å•
```

---

## 6. APIè®¾è®¡æ¨¡å¼

### 6.1 RESTful vs GraphQL vs gRPC

| ç»´åº¦ | REST | GraphQL | gRPC | æ¨èåœºæ™¯ |
|------|------|---------|------|---------|
| **åè®®** | HTTP/JSON | HTTP/JSON | HTTP/2 + Protobuf | - |
| **æ€§èƒ½** | âš¡âš¡âš¡ | âš¡âš¡âš¡ | âš¡âš¡âš¡âš¡âš¡ | gRPC (å¾®æœåŠ¡) |
| **çµæ´»æ€§** | â­â­â­ | â­â­â­â­â­ | â­â­ | GraphQL (å‰ç«¯çµæ´») |
| **ç±»å‹å®‰å…¨** | âŒ (éœ€æ–‡æ¡£) | âœ… Schema | âœ… Protobuf | gRPC/GraphQL |
| **å­¦ä¹ æ›²çº¿** | â­â­â­â­â­ | â­â­â­ | â­â­ | REST (ç®€å•) |
| **å·¥å…·ç”Ÿæ€** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ | REST (æˆç†Ÿ) |
| **å®æ—¶é€šä¿¡** | âŒ (éœ€WebSocket) | âœ… Subscription | âœ… Stream | gRPC/GraphQL |

---

## 7. æ€§èƒ½ä¼˜åŒ–å®æˆ˜

### 7.1 Python æ€§èƒ½ä¼˜åŒ–æŠ€å·§æ’è¡Œæ¦œ

| æŠ€å·§ | æ€§èƒ½æå‡ | å®ç°éš¾åº¦ | æ¨èåº¦ |
|------|---------|---------|--------|
| 1. é€‰æ‹©åˆé€‚ç®—æ³•/æ•°æ®ç»“æ„ | 10-1000x | â­â­â­ | â­â­â­â­â­ |
| 2. ä½¿ç”¨ Polars æ›¿ä»£ Pandas | 10-100x | â­â­â­ | â­â­â­â­â­ |
| 3. ä½¿ç”¨ uvloop | 2-4x | â­ | â­â­â­â­â­ |
| 4. ä½¿ç”¨ orjson æ›¿ä»£ json | 5-10x | â­ | â­â­â­â­â­ |
| 5. å¼‚æ­¥ I/O (asyncio) | 5-50x | â­â­â­ | â­â­â­â­â­ |
| 6. `__slots__` å‡å°‘å†…å­˜ | å†…å­˜â†“40% | â­â­ | â­â­â­â­ |
| 7. åˆ—è¡¨æ¨å¯¼ vs for å¾ªç¯ | 20-30% | â­ | â­â­â­â­â­ |
| 8. `functools.lru_cache` | å˜åŒ–å¤§ | â­ | â­â­â­â­â­ |
| 9. NumPy å‘é‡åŒ– | 10-100x | â­â­ | â­â­â­â­â­ |
| 10. Cython/mypyc ç¼–è¯‘ | 5-50x | â­â­â­â­â­ | â­â­â­ |
| 11. PyPy è§£é‡Šå™¨ | 2-5x | â­â­ | â­â­â­ |
| 12. Free-threaded (3.13+) | 2-4x | â­â­â­â­ | â­â­â­â­ |

---

## 8. äº‘åŸç”Ÿéƒ¨ç½²æ–¹æ¡ˆ

### 8.1 éƒ¨ç½²æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | é€‚ç”¨è§„æ¨¡ | å¤æ‚åº¦ | æˆæœ¬ | æ¨èåœºæ™¯ |
|------|---------|--------|------|---------|
| **Docker** | å° | â­â­ | ä½ | å•ä½“åº”ç”¨ |
| **Docker Compose** | å°-ä¸­ | â­â­â­ | ä½ | å¼€å‘/æµ‹è¯• |
| **Kubernetes** | ä¸­-å¤§ | â­â­â­â­â­ | ä¸­-é«˜ | ç”Ÿäº§ç¯å¢ƒ |
| **Serverless (Lambda)** | å˜åŒ– | â­â­ | æŒ‰éœ€ | è½»é‡çº§API |
| **PaaS (Heroku/Railway)** | å°-ä¸­ | â­ | ä¸­ | å¿«é€Ÿéƒ¨ç½² |

---

**ä¸‹ä¸€æ­¥**: æ·±å…¥å®è·µå„ä¸ªé¢†åŸŸçš„æœ€ä½³å®è·µ!

**ç‰ˆæœ¬**: 2.0.0  
**ç»´æŠ¤**: æ¯æœˆæ›´æ–°  
**è´¡çŒ®**: æ¬¢è¿PR!
