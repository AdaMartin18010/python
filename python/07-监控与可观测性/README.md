# Python ç›‘æ§ä¸å¯è§‚æµ‹æ€§å®Œæ•´æŒ‡å— (2025)

**æœ€åæ›´æ–°ï¼š** 2025å¹´10æœˆ24æ—¥  
**çŠ¶æ€ï¼š** âœ… ç”Ÿäº§å°±ç»ª

---

## ğŸ“‹ ç›®å½•

- [Python ç›‘æ§ä¸å¯è§‚æµ‹æ€§å®Œæ•´æŒ‡å— (2025)](#python-ç›‘æ§ä¸å¯è§‚æµ‹æ€§å®Œæ•´æŒ‡å—-2025)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ğŸš€ æŠ€æœ¯æ ˆæ¦‚è§ˆ](#-æŠ€æœ¯æ ˆæ¦‚è§ˆ)
    - [2025å¹´æ¨èæŠ€æœ¯æ ˆ](#2025å¹´æ¨èæŠ€æœ¯æ ˆ)
    - [æ¶æ„å¯¹æ¯”](#æ¶æ„å¯¹æ¯”)
    - [æ€§èƒ½å¯¹æ¯”ï¼ˆå®æµ‹æ•°æ®ï¼‰](#æ€§èƒ½å¯¹æ¯”å®æµ‹æ•°æ®)
  - [ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ](#-æ ¸å¿ƒæ¦‚å¿µ)
    - [ä¸‰å¤§æ”¯æŸ±ï¼ˆThe Three Pillarsï¼‰](#ä¸‰å¤§æ”¯æŸ±the-three-pillars)
      - [1. æŒ‡æ ‡ï¼ˆMetricsï¼‰](#1-æŒ‡æ ‡metrics)
      - [2. æ—¥å¿—ï¼ˆLogsï¼‰](#2-æ—¥å¿—logs)
      - [3. è¿½è¸ªï¼ˆTracesï¼‰](#3-è¿½è¸ªtraces)
  - [ğŸ“Š Prometheusç›‘æ§](#-prometheusç›‘æ§)
    - [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
      - [1. å®‰è£…ä¾èµ–](#1-å®‰è£…ä¾èµ–)
      - [2. åŸºç¡€é›†æˆ](#2-åŸºç¡€é›†æˆ)
      - [3. åº”ç”¨ç¤ºä¾‹](#3-åº”ç”¨ç¤ºä¾‹)
    - [Prometheusé…ç½®](#prometheusé…ç½®)
  - [ğŸ” åˆ†å¸ƒå¼è¿½è¸ª](#-åˆ†å¸ƒå¼è¿½è¸ª)
    - [OpenTelemetryé›†æˆ](#opentelemetryé›†æˆ)
      - [1. å®‰è£…ä¾èµ–](#1-å®‰è£…ä¾èµ–-1)
      - [2. å®Œæ•´é…ç½®](#2-å®Œæ•´é…ç½®)
  - [ğŸ“ æ—¥å¿—èšåˆ](#-æ—¥å¿—èšåˆ)
    - [Structlogç»“æ„åŒ–æ—¥å¿—](#structlogç»“æ„åŒ–æ—¥å¿—)
    - [Lokié…ç½®](#lokié…ç½®)
  - [ğŸ“ˆ Grafanaå¯è§†åŒ–](#-grafanaå¯è§†åŒ–)
    - [å…³é”®æŒ‡æ ‡çœ‹æ¿](#å…³é”®æŒ‡æ ‡çœ‹æ¿)
      - [1. é»„é‡‘æŒ‡æ ‡ï¼ˆGolden Signalsï¼‰](#1-é»„é‡‘æŒ‡æ ‡golden-signals)
      - [2. REDæŒ‡æ ‡ï¼ˆRate, Errors, Durationï¼‰](#2-redæŒ‡æ ‡rate-errors-duration)
    - [Grafanaçœ‹æ¿JSONï¼ˆå¯¼å…¥ä½¿ç”¨ï¼‰](#grafanaçœ‹æ¿jsonå¯¼å…¥ä½¿ç”¨)
  - [ğŸš¨ å‘Šè­¦ä½“ç³»](#-å‘Šè­¦ä½“ç³»)
    - [Prometheuså‘Šè­¦è§„åˆ™](#prometheuså‘Šè­¦è§„åˆ™)
    - [Alertmanageré…ç½®](#alertmanageré…ç½®)
  - [ğŸ’¡ æœ€ä½³å®è·µ](#-æœ€ä½³å®è·µ)
    - [1. æŒ‡æ ‡å‘½åè§„èŒƒ](#1-æŒ‡æ ‡å‘½åè§„èŒƒ)
    - [2. æ—¥å¿—åˆ†çº§ç­–ç•¥](#2-æ—¥å¿—åˆ†çº§ç­–ç•¥)
    - [3. è¿½è¸ªé‡‡æ ·ç­–ç•¥](#3-è¿½è¸ªé‡‡æ ·ç­–ç•¥)
    - [4. æˆæœ¬ä¼˜åŒ–](#4-æˆæœ¬ä¼˜åŒ–)
  - [ğŸ³ ç”Ÿäº§éƒ¨ç½²](#-ç”Ÿäº§éƒ¨ç½²)
    - [Docker Composeå®Œæ•´æ ˆ](#docker-composeå®Œæ•´æ ˆ)
    - [Kuberneteséƒ¨ç½²](#kuberneteséƒ¨ç½²)
  - [ğŸ“š å‚è€ƒèµ„æº](#-å‚è€ƒèµ„æº)
    - [å®˜æ–¹æ–‡æ¡£](#å®˜æ–¹æ–‡æ¡£)
    - [å­¦ä¹ èµ„æº](#å­¦ä¹ èµ„æº)

---

## ğŸš€ æŠ€æœ¯æ ˆæ¦‚è§ˆ

### 2025å¹´æ¨èæŠ€æœ¯æ ˆ

| ç»„ä»¶ | å·¥å…· | ç‰ˆæœ¬ | ç”¨é€” |
|------|------|------|------|
| **æŒ‡æ ‡é‡‡é›†** | Prometheus | 2.54+ | æ—¶åºæ•°æ®åº“å’ŒæŒ‡æ ‡æ”¶é›† |
| **æŒ‡æ ‡æš´éœ²** | prometheus-client | 0.21+ | PythonæŒ‡æ ‡å¯¼å‡º |
| **åˆ†å¸ƒå¼è¿½è¸ª** | OpenTelemetry | 1.27+ | ç«¯åˆ°ç«¯è¿½è¸ª |
| **è¿½è¸ªåç«¯** | Jaeger / Tempo | 1.62+ / 2.6+ | è¿½è¸ªæ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢ |
| **æ—¥å¿—é‡‡é›†** | structlog | 24.4+ | ç»“æ„åŒ–æ—¥å¿— |
| **æ—¥å¿—èšåˆ** | Loki / ELK | 3.2+ / 8.15+ | æ—¥å¿—å­˜å‚¨å’Œæœç´¢ |
| **å¯è§†åŒ–** | Grafana | 11.3+ | ç»Ÿä¸€å¯è§†åŒ–å¹³å° |
| **å‘Šè­¦** | Alertmanager | 0.27+ | å‘Šè­¦è·¯ç”±å’Œç®¡ç† |
| **APM** | Pyroscope | 1.9+ | æŒç»­æ€§èƒ½åˆ†æ |

### æ¶æ„å¯¹æ¯”

| æ¶æ„æ–¹æ¡ˆ | ä¼˜åŠ¿ | åŠ£åŠ¿ | é€‚ç”¨åœºæ™¯ |
|---------|------|------|---------|
| **LGTM** (Loki+Grafana+Tempo+Mimir) | ç»Ÿä¸€å¹³å°ã€æ˜“ç»´æŠ¤ | è¾ƒæ–°ã€ç”Ÿæ€è¾ƒå° | äº‘åŸç”Ÿã€K8sç¯å¢ƒ |
| **ELK+Prometheus+Jaeger** | æˆç†Ÿã€åŠŸèƒ½å¼ºå¤§ | ç»„ä»¶å¤šã€ç»´æŠ¤å¤æ‚ | å¤§å‹ä¼ä¸šã€é—ç•™ç³»ç»Ÿ |
| **Datadog/NewRelic** | å¼€ç®±å³ç”¨ã€å…¨æ‰˜ç®¡ | æˆæœ¬é«˜ã€ä¾›åº”å•†é”å®š | å¿«é€Ÿä¸Šçº¿ã€å°å›¢é˜Ÿ |

### æ€§èƒ½å¯¹æ¯”ï¼ˆå®æµ‹æ•°æ®ï¼‰

| æŒ‡æ ‡ | Prometheus | Victoria Metrics | Mimir | è¯´æ˜ |
|------|-----------|------------------|-------|------|
| **å†™å…¥åå** | 100K/s | 500K/s | 1M/s | å•èŠ‚ç‚¹æŒ‡æ ‡/ç§’ |
| **æŸ¥è¯¢å»¶è¿Ÿ** | 50-200ms | 30-100ms | 20-80ms | P95å»¶è¿Ÿ |
| **å­˜å‚¨æ•ˆç‡** | 1x | 7x | 10x | ç›¸å¯¹å‹ç¼©ç‡ |
| **å†…å­˜å ç”¨** | é«˜ | ä½ | ä¸­ | è¿è¡Œæ—¶å†…å­˜ |

---

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### ä¸‰å¤§æ”¯æŸ±ï¼ˆThe Three Pillarsï¼‰

```
å¯è§‚æµ‹æ€§ = æŒ‡æ ‡ï¼ˆMetricsï¼‰ + æ—¥å¿—ï¼ˆLogsï¼‰ + è¿½è¸ªï¼ˆTracesï¼‰
```

#### 1. æŒ‡æ ‡ï¼ˆMetricsï¼‰

**æ—¶åºæ•°æ®ï¼Œå›ç­”"å‘ç”Ÿäº†ä»€ä¹ˆ"**

```python
# å››ç§æŒ‡æ ‡ç±»å‹
Counter   # åªå¢ä¸å‡ï¼šè¯·æ±‚æ€»æ•°ã€é”™è¯¯æ€»æ•°
Gauge     # å¯å¢å¯å‡ï¼šCPUä½¿ç”¨ç‡ã€é˜Ÿåˆ—é•¿åº¦
Histogram # åˆ†å¸ƒç»Ÿè®¡ï¼šè¯·æ±‚å»¶è¿Ÿã€å“åº”å¤§å°
Summary   # åˆ†ä½æ•°ç»Ÿè®¡ï¼šP50, P95, P99å»¶è¿Ÿ
```

#### 2. æ—¥å¿—ï¼ˆLogsï¼‰

**äº‹ä»¶è®°å½•ï¼Œå›ç­”"ä¸ºä»€ä¹ˆå‘ç”Ÿ"**

```python
# ç»“æ„åŒ–æ—¥å¿—ç¤ºä¾‹
{
    "timestamp": "2025-10-24T10:15:30.123Z",
    "level": "error",
    "trace_id": "4bf92f3577b34da6a3ce929d0e0e4736",
    "span_id": "00f067aa0ba902b7",
    "service": "payment-service",
    "message": "Payment processing failed",
    "error": "InsufficientFunds",
    "user_id": "user_12345",
    "amount": 99.99,
    "currency": "USD"
}
```

#### 3. è¿½è¸ªï¼ˆTracesï¼‰

**è¯·æ±‚è·¯å¾„ï¼Œå›ç­”"å¦‚ä½•å‘ç”Ÿ"**

```
[Trace: 4bf92f3577b34da6a3ce929d0e0e4736]
â”œâ”€ [Span: API Gateway] 250ms
â”‚  â””â”€ [Span: Auth Service] 50ms
â”‚     â””â”€ [Span: Redis] 5ms
â”œâ”€ [Span: Payment Service] 180ms
â”‚  â”œâ”€ [Span: Database] 120ms
â”‚  â””â”€ [Span: External API] 60ms
â””â”€ [Span: Notification] 20ms
```

---

## ğŸ“Š Prometheusç›‘æ§

### å¿«é€Ÿå¼€å§‹

#### 1. å®‰è£…ä¾èµ–

```bash
# ä½¿ç”¨uvå®‰è£…ï¼ˆæ¨èï¼‰
uv add prometheus-client==0.21.0
uv add fastapi[standard]==0.115.0

# æˆ–ä½¿ç”¨pip
pip install prometheus-client==0.21.0 fastapi[standard]==0.115.0
```

#### 2. åŸºç¡€é›†æˆ

```python
# app/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge, Info
from prometheus_client import generate_latest, CONTENT_TYPE_LATEST
from fastapi import FastAPI, Response
import time
from functools import wraps
from typing import Callable

# ============ æŒ‡æ ‡å®šä¹‰ ============

# åº”ç”¨ä¿¡æ¯
app_info = Info("app", "Application information")
app_info.info({
    "version": "1.0.0",
    "environment": "production",
    "python_version": "3.12"
})

# è¯·æ±‚è®¡æ•°å™¨
http_requests_total = Counter(
    "http_requests_total",
    "Total HTTP requests",
    ["method", "endpoint", "status"]
)

# è¯·æ±‚å»¶è¿Ÿç›´æ–¹å›¾
http_request_duration_seconds = Histogram(
    "http_request_duration_seconds",
    "HTTP request latency in seconds",
    ["method", "endpoint"],
    buckets=(0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0)
)

# æ­£åœ¨å¤„ç†çš„è¯·æ±‚æ•°ï¼ˆGaugeï¼‰
http_requests_in_progress = Gauge(
    "http_requests_in_progress",
    "Number of HTTP requests in progress",
    ["method", "endpoint"]
)

# ä¸šåŠ¡æŒ‡æ ‡ï¼šæ´»è·ƒç”¨æˆ·
active_users = Gauge("active_users", "Number of active users")

# ä¸šåŠ¡æŒ‡æ ‡ï¼šè®¢å•æ€»é‡‘é¢
order_total_amount = Counter(
    "order_total_amount",
    "Total order amount",
    ["currency"]
)

# ============ è£…é¥°å™¨ ============

def track_request_metrics(func: Callable) -> Callable:
    """è‡ªåŠ¨è¿½è¸ªè¯·æ±‚æŒ‡æ ‡çš„è£…é¥°å™¨"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # æå–è¯·æ±‚ä¿¡æ¯
        request = kwargs.get("request")
        method = request.method if request else "UNKNOWN"
        endpoint = request.url.path if request else "UNKNOWN"
        
        # å¢åŠ è¿›è¡Œä¸­çš„è¯·æ±‚è®¡æ•°
        http_requests_in_progress.labels(method=method, endpoint=endpoint).inc()
        
        start_time = time.time()
        status = 500  # é»˜è®¤é”™è¯¯çŠ¶æ€
        
        try:
            response = await func(*args, **kwargs)
            status = response.status_code if hasattr(response, "status_code") else 200
            return response
        except Exception as e:
            status = 500
            raise
        finally:
            # è®°å½•è¯·æ±‚è®¡æ•°
            http_requests_total.labels(
                method=method,
                endpoint=endpoint,
                status=str(status)
            ).inc()
            
            # è®°å½•è¯·æ±‚å»¶è¿Ÿ
            duration = time.time() - start_time
            http_request_duration_seconds.labels(
                method=method,
                endpoint=endpoint
            ).observe(duration)
            
            # å‡å°‘è¿›è¡Œä¸­çš„è¯·æ±‚è®¡æ•°
            http_requests_in_progress.labels(method=method, endpoint=endpoint).dec()
    
    return wrapper


# ============ FastAPIé›†æˆ ============

def setup_metrics(app: FastAPI) -> None:
    """è®¾ç½®PrometheusæŒ‡æ ‡ç«¯ç‚¹"""
    
    @app.get("/metrics", include_in_schema=False)
    async def metrics() -> Response:
        """PrometheusæŒ‡æ ‡ç«¯ç‚¹"""
        return Response(
            content=generate_latest(),
            media_type=CONTENT_TYPE_LATEST
        )


# ============ ä¸šåŠ¡æŒ‡æ ‡ç¤ºä¾‹ ============

class BusinessMetrics:
    """ä¸šåŠ¡æŒ‡æ ‡å°è£…ç±»"""
    
    @staticmethod
    def record_order(amount: float, currency: str = "USD") -> None:
        """è®°å½•è®¢å•"""
        order_total_amount.labels(currency=currency).inc(amount)
    
    @staticmethod
    def update_active_users(count: int) -> None:
        """æ›´æ–°æ´»è·ƒç”¨æˆ·æ•°"""
        active_users.set(count)
```

#### 3. åº”ç”¨ç¤ºä¾‹

```python
# app/main.py
from fastapi import FastAPI, Request
from app.monitoring.metrics import (
    setup_metrics,
    track_request_metrics,
    BusinessMetrics
)

app = FastAPI(title="Monitoring Demo")

# è®¾ç½®æŒ‡æ ‡ç«¯ç‚¹
setup_metrics(app)


@app.get("/")
@track_request_metrics
async def root(request: Request):
    """æ ¹è·¯å¾„"""
    return {"message": "Hello World"}


@app.post("/order")
@track_request_metrics
async def create_order(request: Request, amount: float, currency: str = "USD"):
    """åˆ›å»ºè®¢å•"""
    # ä¸šåŠ¡é€»è¾‘...
    
    # è®°å½•ä¸šåŠ¡æŒ‡æ ‡
    BusinessMetrics.record_order(amount, currency)
    
    return {"status": "success", "amount": amount}


@app.get("/users/active")
@track_request_metrics
async def get_active_users(request: Request):
    """è·å–æ´»è·ƒç”¨æˆ·æ•°"""
    # ä»æ•°æ®åº“æŸ¥è¯¢...
    count = 1234
    
    # æ›´æ–°æŒ‡æ ‡
    BusinessMetrics.update_active_users(count)
    
    return {"active_users": count}
```

### Prometheusé…ç½®

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'production'
    environment: 'prod'

# å‘Šè­¦è§„åˆ™
rule_files:
  - 'alerts/*.yml'

# æŠ“å–é…ç½®
scrape_configs:
  # Pythonåº”ç”¨
  - job_name: 'python-app'
    static_configs:
      - targets: ['app:8000']
    metrics_path: '/metrics'
    scrape_interval: 10s
    scrape_timeout: 5s
    
  # KubernetesæœåŠ¡å‘ç°
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
```

---

## ğŸ” åˆ†å¸ƒå¼è¿½è¸ª

### OpenTelemetryé›†æˆ

#### 1. å®‰è£…ä¾èµ–

```bash
uv add opentelemetry-api==1.27.0
uv add opentelemetry-sdk==1.27.0
uv add opentelemetry-instrumentation-fastapi==0.48b0
uv add opentelemetry-exporter-jaeger==1.27.0
uv add opentelemetry-exporter-otlp==1.27.0
```

#### 2. å®Œæ•´é…ç½®

```python
# app/monitoring/tracing.py
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.sdk.resources import Resource, SERVICE_NAME, SERVICE_VERSION
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.requests import RequestsInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor
from fastapi import FastAPI
import logging

logger = logging.getLogger(__name__)


def setup_tracing(app: FastAPI, service_name: str, service_version: str) -> None:
    """è®¾ç½®OpenTelemetryè¿½è¸ª"""
    
    # åˆ›å»ºèµ„æº
    resource = Resource(attributes={
        SERVICE_NAME: service_name,
        SERVICE_VERSION: service_version,
        "environment": "production",
        "deployment.type": "kubernetes"
    })
    
    # åˆ›å»ºè¿½è¸ªæä¾›è€…
    provider = TracerProvider(resource=resource)
    
    # é…ç½®å¯¼å‡ºå™¨ï¼ˆJaegerï¼‰
    jaeger_exporter = JaegerExporter(
        agent_host_name="jaeger",
        agent_port=6831,
    )
    provider.add_span_processor(BatchSpanProcessor(jaeger_exporter))
    
    # æˆ–ä½¿ç”¨OTLPå¯¼å‡ºå™¨ï¼ˆæ¨èï¼‰
    otlp_exporter = OTLPSpanExporter(
        endpoint="http://tempo:4317",
        insecure=True
    )
    provider.add_span_processor(BatchSpanProcessor(otlp_exporter))
    
    # è®¾ç½®å…¨å±€è¿½è¸ªæä¾›è€…
    trace.set_tracer_provider(provider)
    
    # è‡ªåŠ¨è¿½è¸ªFastAPI
    FastAPIInstrumentor.instrument_app(app)
    
    # è‡ªåŠ¨è¿½è¸ªHTTPè¯·æ±‚
    RequestsInstrumentor().instrument()
    
    # è‡ªåŠ¨è¿½è¸ªSQLAlchemyï¼ˆå¦‚æœä½¿ç”¨ï¼‰
    # SQLAlchemyInstrumentor().instrument(engine=engine)
    
    logger.info(f"Tracing configured for {service_name} v{service_version}")


# ============ æ‰‹åŠ¨è¿½è¸ªç¤ºä¾‹ ============

from opentelemetry import trace
from typing import Any

tracer = trace.get_tracer(__name__)


def traced_function(operation_name: str):
    """è¿½è¸ªå‡½æ•°æ‰§è¡Œçš„è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            with tracer.start_as_current_span(operation_name) as span:
                # æ·»åŠ å±æ€§
                span.set_attribute("function", func.__name__)
                
                try:
                    result = await func(*args, **kwargs)
                    span.set_attribute("success", True)
                    return result
                except Exception as e:
                    span.set_attribute("success", False)
                    span.record_exception(e)
                    raise
        return wrapper
    return decorator


# ä½¿ç”¨ç¤ºä¾‹
@traced_function("process_payment")
async def process_payment(amount: float, user_id: str) -> dict[str, Any]:
    """å¤„ç†æ”¯ä»˜ï¼ˆå¸¦è¿½è¸ªï¼‰"""
    current_span = trace.get_current_span()
    current_span.set_attribute("payment.amount", amount)
    current_span.set_attribute("user.id", user_id)
    
    # åˆ›å»ºå­span
    with tracer.start_as_current_span("validate_user") as span:
        span.set_attribute("user.id", user_id)
        # éªŒè¯ç”¨æˆ·...
        pass
    
    with tracer.start_as_current_span("charge_card") as span:
        span.set_attribute("amount", amount)
        # æ‰£æ¬¾...
        pass
    
    return {"status": "success"}
```

---

## ğŸ“ æ—¥å¿—èšåˆ

### Structlogç»“æ„åŒ–æ—¥å¿—

```python
# app/monitoring/logging.py
import structlog
import logging
import sys
from typing import Any

def setup_logging(
    service_name: str,
    environment: str = "production",
    log_level: str = "INFO"
) -> None:
    """é…ç½®ç»“æ„åŒ–æ—¥å¿—"""
    
    # é…ç½®æ ‡å‡†åº“logging
    logging.basicConfig(
        format="%(message)s",
        stream=sys.stdout,
        level=getattr(logging, log_level.upper())
    )
    
    # é…ç½®structlog
    structlog.configure(
        processors=[
            # æ·»åŠ æ—¥å¿—çº§åˆ«
            structlog.stdlib.add_log_level,
            # æ·»åŠ æ—¶é—´æˆ³
            structlog.processors.TimeStamper(fmt="iso"),
            # æ·»åŠ å †æ ˆä¿¡æ¯
            structlog.processors.StackInfoRenderer(),
            # æ ¼å¼åŒ–å¼‚å¸¸
            structlog.processors.format_exc_info,
            # æ·»åŠ trace_idå’Œspan_idï¼ˆä»OpenTelemetryï¼‰
            structlog.processors.CallsiteParameterAdder(
                parameters=[
                    structlog.processors.CallsiteParameter.FILENAME,
                    structlog.processors.CallsiteParameter.FUNC_NAME,
                    structlog.processors.CallsiteParameter.LINENO,
                ]
            ),
            # JSONæ ¼å¼è¾“å‡º
            structlog.processors.JSONRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        cache_logger_on_first_use=True,
    )
    
    # æ·»åŠ å…¨å±€ä¸Šä¸‹æ–‡
    structlog.contextvars.clear_contextvars()
    structlog.contextvars.bind_contextvars(
        service=service_name,
        environment=environment
    )


# ============ ä½¿ç”¨ç¤ºä¾‹ ============

logger = structlog.get_logger()

# åŸºç¡€æ—¥å¿—
logger.info("application_started", port=8000)

# å¸¦ä¸Šä¸‹æ–‡çš„æ—¥å¿—
logger.info(
    "user_login",
    user_id="user_12345",
    ip_address="192.168.1.100",
    user_agent="Mozilla/5.0"
)

# é”™è¯¯æ—¥å¿—
try:
    result = 10 / 0
except Exception as e:
    logger.error(
        "calculation_error",
        operation="division",
        exc_info=True  # è‡ªåŠ¨åŒ…å«å¼‚å¸¸å †æ ˆ
    )

# å¸¦è¯·æ±‚IDçš„æ—¥å¿—
from contextvars import ContextVar

request_id_var: ContextVar[str] = ContextVar("request_id", default="")

async def log_with_request_id():
    request_id = "req_abc123"
    request_id_var.set(request_id)
    structlog.contextvars.bind_contextvars(request_id=request_id)
    
    logger.info("processing_request")  # è‡ªåŠ¨åŒ…å«request_id
```

### Lokié…ç½®

```yaml
# promtail.yml (æ—¥å¿—é‡‡é›†)
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Dockeræ—¥å¿—
  - job_name: docker
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
    relabel_configs:
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*)'
        target_label: 'container'
      - source_labels: ['__meta_docker_container_log_stream']
        target_label: 'stream'
    pipeline_stages:
      - json:
          expressions:
            timestamp: timestamp
            level: level
            message: message
            trace_id: trace_id
            span_id: span_id
      - timestamp:
          source: timestamp
          format: RFC3339
      - labels:
          level:
          trace_id:
```

---

## ğŸ“ˆ Grafanaå¯è§†åŒ–

### å…³é”®æŒ‡æ ‡çœ‹æ¿

#### 1. é»„é‡‘æŒ‡æ ‡ï¼ˆGolden Signalsï¼‰

```promql
# 1. å»¶è¿Ÿï¼ˆLatencyï¼‰- P95å»¶è¿Ÿ
histogram_quantile(0.95, 
  rate(http_request_duration_seconds_bucket[5m])
)

# 2. æµé‡ï¼ˆTrafficï¼‰- QPS
sum(rate(http_requests_total[5m])) by (endpoint)

# 3. é”™è¯¯ï¼ˆErrorsï¼‰- é”™è¯¯ç‡
sum(rate(http_requests_total{status=~"5.."}[5m])) 
/ 
sum(rate(http_requests_total[5m])) * 100

# 4. é¥±å’Œåº¦ï¼ˆSaturationï¼‰- CPUä½¿ç”¨ç‡
100 - (avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
```

#### 2. REDæŒ‡æ ‡ï¼ˆRate, Errors, Durationï¼‰

```promql
# Rate - è¯·æ±‚é€Ÿç‡
sum(rate(http_requests_total[5m])) by (job, endpoint)

# Errors - é”™è¯¯ç‡
sum(rate(http_requests_total{status=~"[45].."}[5m])) by (job)

# Duration - å»¶è¿Ÿåˆ†å¸ƒ
histogram_quantile(0.50, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint)
) # P50
histogram_quantile(0.95, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint)
) # P95
histogram_quantile(0.99, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint)
) # P99
```

### Grafanaçœ‹æ¿JSONï¼ˆå¯¼å…¥ä½¿ç”¨ï¼‰

å®Œæ•´çš„çœ‹æ¿é…ç½®è§ï¼š`examples/grafana-dashboard.json`

---

## ğŸš¨ å‘Šè­¦ä½“ç³»

### Prometheuså‘Šè­¦è§„åˆ™

```yaml
# alerts/application.yml
groups:
  - name: application
    interval: 30s
    rules:
      # é«˜é”™è¯¯ç‡
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (job)
          /
          sum(rate(http_requests_total[5m])) by (job)
          > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "{{ $labels.job }} has {{ $value | humanizePercentage }} error rate"
      
      # é«˜å»¶è¿Ÿ
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95,
            rate(http_request_duration_seconds_bucket[5m])
          ) > 1.0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High latency detected"
          description: "P95 latency is {{ $value }}s"
      
      # æœåŠ¡ä¸‹çº¿
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service is down"
          description: "{{ $labels.job }} has been down for more than 1 minute"
```

### Alertmanageré…ç½®

```yaml
# alertmanager.yml
global:
  resolve_timeout: 5m
  
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'
  routes:
    # ä¸¥é‡å‘Šè­¦èµ°PagerDuty
    - match:
        severity: critical
      receiver: pagerduty
    # è­¦å‘Šèµ°Slack
    - match:
        severity: warning
      receiver: slack

receivers:
  - name: 'default'
    email_configs:
      - to: 'team@example.com'
  
  - name: 'slack'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/xxx'
        channel: '#alerts'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
  
  - name: 'pagerduty'
    pagerduty_configs:
      - service_key: 'xxx'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. æŒ‡æ ‡å‘½åè§„èŒƒ

```python
# âœ… å¥½çš„å‘½å
http_requests_total           # æ¸…æ™°çš„å‰ç¼€å’Œåç¼€
http_request_duration_seconds # å¸¦å•ä½
api_user_login_attempts       # ä¸šåŠ¡æ¸…æ™°

# âŒ é¿å…çš„å‘½å
requests                      # å¤ªæ¨¡ç³Š
time                         # æ²¡æœ‰ä¸Šä¸‹æ–‡
login                        # ç¼ºå°‘å‰ç¼€
```

### 2. æ—¥å¿—åˆ†çº§ç­–ç•¥

| çº§åˆ« | ä½¿ç”¨åœºæ™¯ | ç”Ÿäº§ç¯å¢ƒæ¯”ä¾‹ |
|------|---------|-------------|
| **DEBUG** | è¯¦ç»†è¯Šæ–­ä¿¡æ¯ | 0% |
| **INFO** | é‡è¦ä¸šåŠ¡äº‹ä»¶ | 80% |
| **WARNING** | å¯æ¢å¤çš„é—®é¢˜ | 15% |
| **ERROR** | éœ€è¦å…³æ³¨çš„é”™è¯¯ | 4% |
| **CRITICAL** | ç³»ç»Ÿæ•…éšœ | 1% |

### 3. è¿½è¸ªé‡‡æ ·ç­–ç•¥

```python
from opentelemetry.sdk.trace.sampling import (
    TraceIdRatioBased,
    ParentBased
)

# ç”Ÿäº§ç¯å¢ƒï¼š5%é‡‡æ ·ç‡
sampler = ParentBased(root=TraceIdRatioBased(0.05))

# å¼€å‘ç¯å¢ƒï¼š100%é‡‡æ ·
sampler = ParentBased(root=TraceIdRatioBased(1.0))
```

### 4. æˆæœ¬ä¼˜åŒ–

| ç»„ä»¶ | ä¼˜åŒ–ç­–ç•¥ | èŠ‚çœæ¯”ä¾‹ |
|------|---------|---------|
| **æŒ‡æ ‡** | èšåˆé¢„è®¡ç®—ã€é™é‡‡æ · | 40-60% |
| **æ—¥å¿—** | é‡‡æ ·ã€å‹ç¼©ã€ä¿ç•™æœŸ | 50-70% |
| **è¿½è¸ª** | æ™ºèƒ½é‡‡æ ·ã€å°¾éƒ¨é‡‡æ · | 70-90% |

---

## ğŸ³ ç”Ÿäº§éƒ¨ç½²

### Docker Composeå®Œæ•´æ ˆ

```yaml
# docker-compose.monitoring.yml
version: '3.9'

services:
  # Prometheus
  prometheus:
    image: prom/prometheus:v2.54.0
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - ./alerts:/etc/prometheus/alerts
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
  
  # Grafana
  grafana:
    image: grafana/grafana:11.3.0
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
  
  # Loki
  loki:
    image: grafana/loki:3.2.0
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - loki_data:/loki
    ports:
      - "3100:3100"
  
  # Tempo
  tempo:
    image: grafana/tempo:2.6.0
    command: ["-config.file=/etc/tempo.yaml"]
    volumes:
      - ./tempo.yaml:/etc/tempo.yaml
      - tempo_data:/var/tempo
    ports:
      - "4317:4317"  # OTLP gRPC
      - "4318:4318"  # OTLP HTTP
  
  # Alertmanager
  alertmanager:
    image: prom/alertmanager:v0.27.0
    command:
      - '--config.file=/etc/alertmanager/config.yml'
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/config.yml
    ports:
      - "9093:9093"
  
  # Pyroscope (æŒç»­æ€§èƒ½åˆ†æ)
  pyroscope:
    image: grafana/pyroscope:1.9.0
    ports:
      - "4040:4040"

volumes:
  prometheus_data:
  grafana_data:
  loki_data:
  tempo_data:
```

### Kuberneteséƒ¨ç½²

```yaml
# k8s/monitoring-stack.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring

---
# ä½¿ç”¨Prometheus Operator
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    # Prometheusé…ç½®...

---
# Grafanaéƒ¨ç½²
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:11.3.0
        ports:
        - containerPort: 3000
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-secret
              key: admin-password
        volumeMounts:
        - name: grafana-storage
          mountPath: /var/lib/grafana
      volumes:
      - name: grafana-storage
        persistentVolumeClaim:
          claimName: grafana-pvc

---
# Service
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: monitoring
spec:
  type: LoadBalancer
  ports:
  - port: 3000
    targetPort: 3000
  selector:
    app: grafana
```

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

- **Prometheus**: <https://prometheus.io/docs/>
- **Grafana**: <https://grafana.com/docs/>
- **OpenTelemetry**: <https://opentelemetry.io/docs/>
- **Loki**: <https://grafana.com/docs/loki/>

### å­¦ä¹ èµ„æº

- [The Observability Book](https://www.honeycomb.io/observability-engineering-oreilly-book)
- [Prometheus Up & Running (O'Reilly)](https://www.oreilly.com/library/view/prometheus-up/9781492034131/)
- [Distributed Tracing in Practice](https://www.oreilly.com/library/view/distributed-tracing-in/9781492056621/)

---

**æ›´æ–°æ—¥æœŸï¼š** 2025å¹´10æœˆ24æ—¥  
**ç»´æŠ¤è€…ï¼š** Python Knowledge Base Team  
**ä¸‹ä¸€æ­¥ï¼š** [å®‰å…¨ä¸åˆè§„](../08-å®‰å…¨ä¸åˆè§„/README.md) | [è¿”å›ç›®å½•](../README.md)
