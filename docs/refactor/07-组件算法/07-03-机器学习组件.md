# 机器学习组件

## 7.3 机器学习组件

### 概念与原理

机器学习是人工智能的一个分支，通过算法让计算机从数据中学习模式，并做出预测或决策。

#### 核心特征
1. **数据驱动**：从数据中学习模式
2. **自动优化**：自动调整模型参数
3. **泛化能力**：对未见数据做出预测
4. **可解释性**：理解模型决策过程

### 监督学习

#### 1. 线性回归
```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score

class LinearRegression:
    def __init__(self, learning_rate=0.01, epochs=1000):
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.weights = None
        self.bias = None
        self.history = {'loss': []}
    
    def fit(self, X, y):
        """训练线性回归模型"""
        n_samples, n_features = X.shape
        
        # 初始化参数
        self.weights = np.zeros(n_features)
        self.bias = 0
        
        # 梯度下降
        for epoch in range(self.epochs):
            # 前向传播
            y_pred = self.predict(X)
            
            # 计算损失
            loss = mean_squared_error(y, y_pred)
            self.history['loss'].append(loss)
            
            # 计算梯度
            dw = (2/n_samples) * np.dot(X.T, (y_pred - y))
            db = (2/n_samples) * np.sum(y_pred - y)
            
            # 更新参数
            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db
    
    def predict(self, X):
        """预测"""
        return np.dot(X, self.weights) + self.bias
    
    def score(self, X, y):
        """计算R²分数"""
        y_pred = self.predict(X)
        return r2_score(y, y_pred)

def linear_regression_example():
    """线性回归示例"""
    # 生成数据
    np.random.seed(42)
    X = np.random.rand(100, 1) * 10
    y = 2 * X.flatten() + 1 + np.random.randn(100) * 0.5
    
    # 训练模型
    model = LinearRegression(learning_rate=0.01, epochs=1000)
    model.fit(X, y)
    
    # 预测
    y_pred = model.predict(X)
    
    # 评估
    r2 = model.score(X, y)
    mse = mean_squared_error(y, y_pred)
    
    print(f"R²分数: {r2:.4f}")
    print(f"均方误差: {mse:.4f}")
    print(f"权重: {model.weights[0]:.4f}")
    print(f"偏置: {model.bias:.4f}")
    
    return model
```

#### 2. 逻辑回归
```python
class LogisticRegression:
    def __init__(self, learning_rate=0.01, epochs=1000):
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.weights = None
        self.bias = None
        self.history = {'loss': []}
    
    def sigmoid(self, z):
        """sigmoid函数"""
        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))
    
    def fit(self, X, y):
        """训练逻辑回归模型"""
        n_samples, n_features = X.shape
        
        # 初始化参数
        self.weights = np.zeros(n_features)
        self.bias = 0
        
        # 梯度下降
        for epoch in range(self.epochs):
            # 前向传播
            z = np.dot(X, self.weights) + self.bias
            y_pred = self.sigmoid(z)
            
            # 计算损失（交叉熵）
            epsilon = 1e-15
            y_pred = np.clip(y_pred, epsilon, 1 - epsilon)
            loss = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))
            self.history['loss'].append(loss)
            
            # 计算梯度
            dw = (1/n_samples) * np.dot(X.T, (y_pred - y))
            db = (1/n_samples) * np.sum(y_pred - y)
            
            # 更新参数
            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db
    
    def predict(self, X):
        """预测"""
        z = np.dot(X, self.weights) + self.bias
        return self.sigmoid(z)
    
    def predict_classes(self, X, threshold=0.5):
        """预测类别"""
        return (self.predict(X) >= threshold).astype(int)
    
    def score(self, X, y):
        """计算准确率"""
        y_pred = self.predict_classes(X)
        return np.mean(y_pred == y)

def logistic_regression_example():
    """逻辑回归示例"""
    # 生成数据
    np.random.seed(42)
    X = np.random.randn(100, 2)
    y = (X[:, 0] + X[:, 1] > 0).astype(int)
    
    # 训练模型
    model = LogisticRegression(learning_rate=0.1, epochs=1000)
    model.fit(X, y)
    
    # 预测
    y_pred = model.predict_classes(X)
    
    # 评估
    accuracy = model.score(X, y)
    print(f"准确率: {accuracy:.4f}")
    
    return model
```

#### 3. 决策树
```python
class DecisionTree:
    def __init__(self, max_depth=None, min_samples_split=2):
        self.max_depth = max_depth
        self.min_samples_split = min_samples_split
        self.root = None
    
    def fit(self, X, y):
        """训练决策树"""
        self.root = self._build_tree(X, y, depth=0)
    
    def _build_tree(self, X, y, depth):
        """构建决策树"""
        n_samples, n_features = X.shape
        n_classes = len(np.unique(y))
        
        # 停止条件
        if (self.max_depth is not None and depth >= self.max_depth or
            n_samples < self.min_samples_split or
            n_classes == 1):
            return {'type': 'leaf', 'value': np.argmax(np.bincount(y))}
        
        # 寻找最佳分割
        best_feature, best_threshold, best_gain = self._find_best_split(X, y)
        
        if best_gain == 0:
            return {'type': 'leaf', 'value': np.argmax(np.bincount(y))}
        
        # 分割数据
        left_mask = X[:, best_feature] <= best_threshold
        right_mask = ~left_mask
        
        # 递归构建子树
        left_tree = self._build_tree(X[left_mask], y[left_mask], depth + 1)
        right_tree = self._build_tree(X[right_mask], y[right_mask], depth + 1)
        
        return {
            'type': 'node',
            'feature': best_feature,
            'threshold': best_threshold,
            'left': left_tree,
            'right': right_tree
        }
    
    def _find_best_split(self, X, y):
        """寻找最佳分割点"""
        n_samples, n_features = X.shape
        best_gain = 0
        best_feature = 0
        best_threshold = 0
        
        for feature in range(n_features):
            thresholds = np.unique(X[:, feature])
            
            for threshold in thresholds:
                left_mask = X[:, feature] <= threshold
                right_mask = ~left_mask
                
                if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:
                    continue
                
                gain = self._information_gain(y, y[left_mask], y[right_mask])
                
                if gain > best_gain:
                    best_gain = gain
                    best_feature = feature
                    best_threshold = threshold
        
        return best_feature, best_threshold, best_gain
    
    def _information_gain(self, parent, left, right):
        """计算信息增益"""
        parent_entropy = self._entropy(parent)
        left_entropy = self._entropy(left)
        right_entropy = self._entropy(right)
        
        n_left = len(left)
        n_right = len(right)
        n_parent = len(parent)
        
        return parent_entropy - (n_left/n_parent * left_entropy + 
                                n_right/n_parent * right_entropy)
    
    def _entropy(self, y):
        """计算熵"""
        if len(y) == 0:
            return 0
        
        counts = np.bincount(y)
        probs = counts / len(y)
        probs = probs[probs > 0]
        
        return -np.sum(probs * np.log2(probs))
    
    def predict(self, X):
        """预测"""
        return np.array([self._predict_single(x, self.root) for x in X])
    
    def _predict_single(self, x, node):
        """预测单个样本"""
        if node['type'] == 'leaf':
            return node['value']
        
        if x[node['feature']] <= node['threshold']:
            return self._predict_single(x, node['left'])
        else:
            return self._predict_single(x, node['right'])

def decision_tree_example():
    """决策树示例"""
    # 生成数据
    np.random.seed(42)
    X = np.random.randn(100, 2)
    y = (X[:, 0] + X[:, 1] > 0).astype(int)
    
    # 训练模型
    model = DecisionTree(max_depth=5)
    model.fit(X, y)
    
    # 预测
    y_pred = model.predict(X)
    
    # 评估
    accuracy = np.mean(y_pred == y)
    print(f"准确率: {accuracy:.4f}")
    
    return model
```

### 无监督学习

#### 1. K-means聚类
```python
class KMeans:
    def __init__(self, n_clusters=3, max_iters=100):
        self.n_clusters = n_clusters
        self.max_iters = max_iters
        self.centroids = None
        self.labels = None
    
    def fit(self, X):
        """训练K-means模型"""
        n_samples, n_features = X.shape
        
        # 随机初始化聚类中心
        indices = np.random.choice(n_samples, self.n_clusters, replace=False)
        self.centroids = X[indices]
        
        for _ in range(self.max_iters):
            # 分配样本到最近的聚类中心
            distances = np.sqrt(((X - self.centroids[:, np.newaxis])**2).sum(axis=2))
            self.labels = np.argmin(distances, axis=0)
            
            # 更新聚类中心
            new_centroids = np.array([X[self.labels == k].mean(axis=0) 
                                    for k in range(self.n_clusters)])
            
            # 检查收敛
            if np.allclose(self.centroids, new_centroids):
                break
            
            self.centroids = new_centroids
    
    def predict(self, X):
        """预测聚类标签"""
        distances = np.sqrt(((X - self.centroids[:, np.newaxis])**2).sum(axis=2))
        return np.argmin(distances, axis=0)
    
    def inertia(self, X):
        """计算惯性（簇内平方和）"""
        return np.sum([np.sum((X[self.labels == k] - self.centroids[k])**2) 
                      for k in range(self.n_clusters)])

def kmeans_example():
    """K-means示例"""
    # 生成数据
    np.random.seed(42)
    X = np.random.randn(300, 2)
    
    # 训练模型
    model = KMeans(n_clusters=3)
    model.fit(X)
    
    # 预测
    labels = model.predict(X)
    
    # 评估
    inertia = model.inertia(X)
    print(f"惯性: {inertia:.4f}")
    
    return model
```

#### 2. 主成分分析（PCA）
```python
class PCA:
    def __init__(self, n_components=None):
        self.n_components = n_components
        self.components = None
        self.mean = None
        self.explained_variance_ratio = None
    
    def fit(self, X):
        """训练PCA模型"""
        # 中心化数据
        self.mean = np.mean(X, axis=0)
        X_centered = X - self.mean
        
        # 计算协方差矩阵
        cov_matrix = np.cov(X_centered.T)
        
        # 特征值分解
        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)
        
        # 按特征值降序排列
        indices = np.argsort(eigenvalues)[::-1]
        eigenvalues = eigenvalues[indices]
        eigenvectors = eigenvectors[:, indices]
        
        # 选择主成分
        if self.n_components is None:
            self.n_components = X.shape[1]
        
        self.components = eigenvectors[:, :self.n_components]
        self.explained_variance_ratio = eigenvalues[:self.n_components] / np.sum(eigenvalues)
    
    def transform(self, X):
        """降维"""
        X_centered = X - self.mean
        return np.dot(X_centered, self.components)
    
    def inverse_transform(self, X_transformed):
        """逆变换"""
        return np.dot(X_transformed, self.components.T) + self.mean

def pca_example():
    """PCA示例"""
    # 生成数据
    np.random.seed(42)
    X = np.random.randn(100, 3)
    
    # 训练模型
    model = PCA(n_components=2)
    model.fit(X)
    
    # 降维
    X_transformed = model.transform(X)
    
    # 评估
    explained_variance = model.explained_variance_ratio
    print(f"解释方差比例: {explained_variance}")
    print(f"累计解释方差: {np.sum(explained_variance):.4f}")
    
    return model
```

### 深度学习

#### 1. 神经网络
```python
class NeuralNetwork:
    def __init__(self, layers, learning_rate=0.01, epochs=1000):
        self.layers = layers
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.weights = []
        self.biases = []
        self.history = {'loss': []}
        
        # 初始化权重和偏置
        for i in range(len(layers) - 1):
            w = np.random.randn(layers[i + 1], layers[i]) * 0.01
            b = np.zeros((layers[i + 1], 1))
            self.weights.append(w)
            self.biases.append(b)
    
    def sigmoid(self, z):
        """sigmoid激活函数"""
        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))
    
    def sigmoid_derivative(self, z):
        """sigmoid导数"""
        s = self.sigmoid(z)
        return s * (1 - s)
    
    def forward(self, X):
        """前向传播"""
        self.activations = [X]
        self.z_values = []
        
        for i in range(len(self.weights)):
            z = np.dot(self.weights[i], self.activations[-1]) + self.biases[i]
            self.z_values.append(z)
            
            if i == len(self.weights) - 1:
                # 输出层使用sigmoid
                activation = self.sigmoid(z)
            else:
                # 隐藏层使用sigmoid
                activation = self.sigmoid(z)
            
            self.activations.append(activation)
        
        return self.activations[-1]
    
    def backward(self, X, y):
        """反向传播"""
        m = X.shape[1]
        
        # 计算输出层误差
        delta = self.activations[-1] - y
        
        # 反向传播误差
        for i in range(len(self.weights) - 1, -1, -1):
            # 计算梯度
            dw = np.dot(delta, self.activations[i].T) / m
            db = np.sum(delta, axis=1, keepdims=True) / m
            
            # 更新参数
            self.weights[i] -= self.learning_rate * dw
            self.biases[i] -= self.learning_rate * db
            
            # 计算下一层的误差
            if i > 0:
                delta = np.dot(self.weights[i].T, delta) * self.sigmoid_derivative(self.z_values[i - 1])
    
    def fit(self, X, y):
        """训练神经网络"""
        for epoch in range(self.epochs):
            # 前向传播
            y_pred = self.forward(X)
            
            # 计算损失
            loss = -np.mean(y * np.log(y_pred + 1e-15) + (1 - y) * np.log(1 - y_pred + 1e-15))
            self.history['loss'].append(loss)
            
            # 反向传播
            self.backward(X, y)
    
    def predict(self, X, threshold=0.5):
        """预测"""
        y_pred = self.forward(X)
        return (y_pred >= threshold).astype(int)
    
    def score(self, X, y):
        """计算准确率"""
        y_pred = self.predict(X)
        return np.mean(y_pred == y)

def neural_network_example():
    """神经网络示例"""
    # 生成数据
    np.random.seed(42)
    X = np.random.randn(2, 100)
    y = (X[0] + X[1] > 0).astype(float).reshape(1, -1)
    
    # 训练模型
    model = NeuralNetwork([2, 4, 1], learning_rate=0.1, epochs=1000)
    model.fit(X, y)
    
    # 预测
    y_pred = model.predict(X)
    
    # 评估
    accuracy = model.score(X, y)
    print(f"准确率: {accuracy:.4f}")
    
    return model
```

### 强化学习

#### 1. Q-Learning
```python
class QLearning:
    def __init__(self, n_states, n_actions, learning_rate=0.1, discount_factor=0.95, epsilon=0.1):
        self.n_states = n_states
        self.n_actions = n_actions
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.epsilon = epsilon
        self.q_table = np.zeros((n_states, n_actions))
    
    def choose_action(self, state):
        """选择动作（ε-贪婪策略）"""
        if np.random.random() < self.epsilon:
            return np.random.randint(self.n_actions)
        else:
            return np.argmax(self.q_table[state])
    
    def update(self, state, action, reward, next_state):
        """更新Q值"""
        old_value = self.q_table[state, action]
        next_max = np.max(self.q_table[next_state])
        
        new_value = (1 - self.learning_rate) * old_value + \
                   self.learning_rate * (reward + self.discount_factor * next_max)
        
        self.q_table[state, action] = new_value
    
    def get_policy(self):
        """获取最优策略"""
        return np.argmax(self.q_table, axis=1)

def qlearning_example():
    """Q-Learning示例"""
    # 简单的网格世界环境
    n_states = 16  # 4x4网格
    n_actions = 4  # 上下左右
    
    # 创建环境
    def get_next_state(state, action):
        """获取下一个状态"""
        row = state // 4
        col = state % 4
        
        if action == 0:  # 上
            row = max(0, row - 1)
        elif action == 1:  # 下
            row = min(3, row + 1)
        elif action == 2:  # 左
            col = max(0, col - 1)
        elif action == 3:  # 右
            col = min(3, col + 1)
        
        return row * 4 + col
    
    def get_reward(state):
        """获取奖励"""
        if state == 15:  # 目标状态
            return 100
        else:
            return -1
    
    # 训练Q-Learning
    agent = QLearning(n_states, n_actions)
    
    for episode in range(1000):
        state = 0  # 起始状态
        
        for step in range(100):
            action = agent.choose_action(state)
            next_state = get_next_state(state, action)
            reward = get_reward(next_state)
            
            agent.update(state, action, reward, next_state)
            
            state = next_state
            
            if state == 15:  # 到达目标
                break
    
    # 获取最优策略
    policy = agent.get_policy()
    print("最优策略:")
    for i in range(4):
        print(policy[i*4:(i+1)*4])
    
    return agent
```

### 模型评估

#### 1. 交叉验证
```python
def cross_validation(X, y, model, k=5):
    """K折交叉验证"""
    n_samples = len(X)
    fold_size = n_samples // k
    scores = []
    
    for i in range(k):
        # 划分训练集和验证集
        start_idx = i * fold_size
        end_idx = start_idx + fold_size if i < k - 1 else n_samples
        
        X_val = X[start_idx:end_idx]
        y_val = y[start_idx:end_idx]
        X_train = np.concatenate([X[:start_idx], X[end_idx:]])
        y_train = np.concatenate([y[:start_idx], y[end_idx:]])
        
        # 训练和评估
        model.fit(X_train, y_train)
        score = model.score(X_val, y_val)
        scores.append(score)
    
    return np.mean(scores), np.std(scores)

def model_evaluation_example():
    """模型评估示例"""
    # 生成数据
    np.random.seed(42)
    X = np.random.randn(100, 2)
    y = (X[:, 0] + X[:, 1] > 0).astype(int)
    
    # 线性回归
    lr_model = LinearRegression()
    lr_mean, lr_std = cross_validation(X, y, lr_model)
    print(f"线性回归 - 平均分数: {lr_mean:.4f} ± {lr_std:.4f}")
    
    # 逻辑回归
    log_model = LogisticRegression()
    log_mean, log_std = cross_validation(X, y, log_model)
    print(f"逻辑回归 - 平均分数: {log_mean:.4f} ± {log_std:.4f}")
    
    # 决策树
    dt_model = DecisionTree()
    dt_mean, dt_std = cross_validation(X, y, dt_model)
    print(f"决策树 - 平均分数: {dt_mean:.4f} ± {dt_std:.4f}")
```

### 实战案例：机器学习流水线

```python
class MLPipeline:
    def __init__(self):
        self.preprocessor = None
        self.model = None
        self.scaler = None
    
    def preprocess_data(self, X, y=None, is_training=True):
        """数据预处理"""
        if is_training:
            # 标准化
            self.scaler = StandardScaler()
            X_scaled = self.scaler.fit_transform(X)
        else:
            X_scaled = self.scaler.transform(X)
        
        return X_scaled
    
    def train(self, X, y, model_type='logistic'):
        """训练模型"""
        # 预处理
        X_processed = self.preprocess_data(X, y, is_training=True)
        
        # 选择模型
        if model_type == 'linear':
            self.model = LinearRegression()
        elif model_type == 'logistic':
            self.model = LogisticRegression()
        elif model_type == 'decision_tree':
            self.model = DecisionTree()
        elif model_type == 'neural_network':
            self.model = NeuralNetwork([X.shape[1], 10, 1])
        
        # 训练
        self.model.fit(X_processed, y)
    
    def predict(self, X):
        """预测"""
        X_processed = self.preprocess_data(X, is_training=False)
        return self.model.predict(X_processed)
    
    def evaluate(self, X, y):
        """评估模型"""
        y_pred = self.predict(X)
        
        if hasattr(self.model, 'score'):
            return self.model.score(X, y)
        else:
            return np.mean(y_pred == y)

def ml_pipeline_example():
    """机器学习流水线示例"""
    # 生成数据
    np.random.seed(42)
    X = np.random.randn(200, 3)
    y = (X[:, 0] + X[:, 1] + X[:, 2] > 0).astype(int)
    
    # 划分训练集和测试集
    split_idx = int(0.8 * len(X))
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    # 创建流水线
    pipeline = MLPipeline()
    
    # 训练不同模型
    models = ['logistic', 'decision_tree', 'neural_network']
    
    for model_type in models:
        print(f"\n训练 {model_type} 模型:")
        pipeline.train(X_train, y_train, model_type)
        
        # 评估
        train_score = pipeline.evaluate(X_train, y_train)
        test_score = pipeline.evaluate(X_test, y_test)
        
        print(f"训练集准确率: {train_score:.4f}")
        print(f"测试集准确率: {test_score:.4f}")
    
    return pipeline

# 运行示例
if __name__ == "__main__":
    print("=== 机器学习组件实战示例 ===")
    
    # 线性回归
    print("\n1. 线性回归")
    lr_model = linear_regression_example()
    
    # 逻辑回归
    print("\n2. 逻辑回归")
    log_model = logistic_regression_example()
    
    # 决策树
    print("\n3. 决策树")
    dt_model = decision_tree_example()
    
    # K-means聚类
    print("\n4. K-means聚类")
    kmeans_model = kmeans_example()
    
    # PCA降维
    print("\n5. PCA降维")
    pca_model = pca_example()
    
    # 神经网络
    print("\n6. 神经网络")
    nn_model = neural_network_example()
    
    # Q-Learning
    print("\n7. Q-Learning")
    ql_model = qlearning_example()
    
    # 模型评估
    print("\n8. 模型评估")
    model_evaluation_example()
    
    # 机器学习流水线
    print("\n9. 机器学习流水线")
    pipeline = ml_pipeline_example()
    
    print("\n机器学习组件实战完成！")
```

### 理论总结

机器学习是人工智能的核心技术，通过监督学习、无监督学习、深度学习和强化学习等方法，能够从数据中学习模式并做出预测。线性回归和逻辑回归适用于简单的线性关系，决策树适用于非线性关系，神经网络能够学习复杂的非线性模式，聚类算法能够发现数据的内在结构，强化学习能够通过与环境交互学习最优策略。合理选择机器学习算法和评估方法能够构建有效的预测模型。 