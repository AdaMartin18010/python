# ç®—æ³•åŸºç¡€

## ğŸ“‹ æ¦‚è¿°

ç®—æ³•ç†è®ºæ˜¯è®¡ç®—æœºç§‘å­¦çš„æ ¸å¿ƒç†è®ºåŸºç¡€ï¼Œç ”ç©¶ç®—æ³•çš„è®¾è®¡ã€åˆ†æå’Œä¼˜åŒ–ã€‚æœ¬æ–‡æ¡£ä»å½¢å¼åŒ–è§’åº¦æ¢è®¨ç®—æ³•çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå»ºç«‹ä¸¥æ ¼çš„æ•°å­¦å®šä¹‰å’ŒPythonå®ç°ã€‚

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### 1. ç®—æ³•çš„å½¢å¼åŒ–å®šä¹‰

#### 1.1 åŸºæœ¬å®šä¹‰

ç®—æ³•å¯ä»¥å½¢å¼åŒ–å®šä¹‰ä¸ºï¼š

$$\mathcal{A} = (I, O, C, T)$$

å…¶ä¸­ï¼š
- $I$ æ˜¯è¾“å…¥é›†åˆ (Input Set)
- $O$ æ˜¯è¾“å‡ºé›†åˆ (Output Set)
- $C$ æ˜¯è®¡ç®—è¿‡ç¨‹ (Computation Process)
- $T$ æ˜¯ç»ˆæ­¢æ¡ä»¶ (Termination Condition)

#### 1.2 ç®—æ³•ç‰¹æ€§

ç®—æ³•å¿…é¡»æ»¡è¶³ä»¥ä¸‹ç‰¹æ€§ï¼š

1. **æœ‰é™æ€§**: ç®—æ³•å¿…é¡»åœ¨æœ‰é™æ­¥åç»ˆæ­¢
2. **ç¡®å®šæ€§**: å¯¹äºç›¸åŒè¾“å…¥ï¼Œç®—æ³•å¿…é¡»äº§ç”Ÿç›¸åŒè¾“å‡º
3. **æœ‰æ•ˆæ€§**: ç®—æ³•çš„æ¯ä¸ªæ­¥éª¤éƒ½å¿…é¡»å¯æ‰§è¡Œ
4. **è¾“å…¥**: ç®—æ³•å¿…é¡»æœ‰é›¶ä¸ªæˆ–å¤šä¸ªè¾“å…¥
5. **è¾“å‡º**: ç®—æ³•å¿…é¡»æœ‰ä¸€ä¸ªæˆ–å¤šä¸ªè¾“å‡º

## ğŸ”§ Python å®ç°

### 1. ç®—æ³•åŸºç¡€æ¡†æ¶

```python
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, Tuple, Callable
from dataclasses import dataclass, field
from enum import Enum
import time
import math
from collections import defaultdict

class AlgorithmType(Enum):
    """ç®—æ³•ç±»å‹æšä¸¾"""
    SEARCH = "search"
    SORT = "sort"
    GRAPH = "graph"
    DYNAMIC_PROGRAMMING = "dynamic_programming"
    GREEDY = "greedy"
    DIVIDE_AND_CONQUER = "divide_and_conquer"

class ComplexityClass(Enum):
    """å¤æ‚åº¦ç±»æšä¸¾"""
    CONSTANT = "O(1)"
    LOGARITHMIC = "O(log n)"
    LINEAR = "O(n)"
    LINE_LOGARITHMIC = "O(n log n)"
    QUADRATIC = "O(nÂ²)"
    CUBIC = "O(nÂ³)"
    EXPONENTIAL = "O(2â¿)"
    FACTORIAL = "O(n!)"

@dataclass
class AlgorithmSpecification:
    """ç®—æ³•è§„æ ¼è¯´æ˜"""
    name: str
    algorithm_type: AlgorithmType
    description: str
    input_specification: str
    output_specification: str
    preconditions: List[str]
    postconditions: List[str]
    
    def __post_init__(self):
        """éªŒè¯ç®—æ³•è§„æ ¼"""
        if not self.name or not self.description:
            raise ValueError("ç®—æ³•åç§°å’Œæè¿°ä¸èƒ½ä¸ºç©º")

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½åº¦é‡"""
    time_complexity: ComplexityClass
    space_complexity: ComplexityClass
    actual_runtime: float = 0.0
    memory_usage: int = 0
    comparisons: int = 0
    swaps: int = 0

class Algorithm(ABC):
    """ç®—æ³•æŠ½è±¡åŸºç±»"""
    
    def __init__(self, specification: AlgorithmSpecification):
        self.specification = specification
        self.performance_metrics = PerformanceMetrics(
            time_complexity=ComplexityClass.LINEAR,
            space_complexity=ComplexityClass.LINEAR
        )
        self.execution_history: List[Dict[str, Any]] = []
    
    @abstractmethod
    def execute(self, input_data: Any) -> Any:
        """æ‰§è¡Œç®—æ³•"""
        pass
    
    @abstractmethod
    def analyze_complexity(self, input_size: int) -> PerformanceMetrics:
        """åˆ†æå¤æ‚åº¦"""
        pass
    
    def measure_performance(self, input_data: Any) -> PerformanceMetrics:
        """æµ‹é‡æ€§èƒ½"""
        start_time = time.time()
        start_memory = self._get_memory_usage()
        
        # é‡ç½®è®¡æ•°å™¨
        self.performance_metrics.comparisons = 0
        self.performance_metrics.swaps = 0
        
        # æ‰§è¡Œç®—æ³•
        result = self.execute(input_data)
        
        end_time = time.time()
        end_memory = self._get_memory_usage()
        
        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        self.performance_metrics.actual_runtime = end_time - start_time
        self.performance_metrics.memory_usage = end_memory - start_memory
        
        return self.performance_metrics
    
    def _get_memory_usage(self) -> int:
        """è·å–å†…å­˜ä½¿ç”¨é‡ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        import sys
        return sys.getsizeof(self)
    
    def add_execution_step(self, step_description: str, data: Any = None):
        """æ·»åŠ æ‰§è¡Œæ­¥éª¤"""
        self.execution_history.append({
            "step": len(self.execution_history) + 1,
            "description": step_description,
            "data": data,
            "timestamp": time.time()
        })
    
    def get_execution_trace(self) -> List[Dict[str, Any]]:
        """è·å–æ‰§è¡Œè½¨è¿¹"""
        return self.execution_history.copy()
    
    def reset_execution_history(self):
        """é‡ç½®æ‰§è¡Œå†å²"""
        self.execution_history.clear()

class SearchAlgorithm(Algorithm):
    """æœç´¢ç®—æ³•åŸºç±»"""
    
    def __init__(self, specification: AlgorithmSpecification):
        super().__init__(specification)
        self.performance_metrics.time_complexity = ComplexityClass.LINEAR
    
    def linear_search(self, arr: List[Any], target: Any) -> Optional[int]:
        """çº¿æ€§æœç´¢"""
        self.reset_execution_history()
        
        for i, element in enumerate(arr):
            self.performance_metrics.comparisons += 1
            self.add_execution_step(f"æ¯”è¾ƒå…ƒç´  {element} ä¸ç›®æ ‡ {target}")
            
            if element == target:
                self.add_execution_step(f"æ‰¾åˆ°ç›®æ ‡ï¼Œä½ç½®: {i}")
                return i
        
        self.add_execution_step("æœªæ‰¾åˆ°ç›®æ ‡")
        return None
    
    def binary_search(self, arr: List[Any], target: Any) -> Optional[int]:
        """äºŒåˆ†æœç´¢"""
        self.reset_execution_history()
        
        left, right = 0, len(arr) - 1
        
        while left <= right:
            mid = (left + right) // 2
            self.performance_metrics.comparisons += 1
            self.add_execution_step(f"æ£€æŸ¥ä¸­é—´ä½ç½® {mid}, å…ƒç´ : {arr[mid]}")
            
            if arr[mid] == target:
                self.add_execution_step(f"æ‰¾åˆ°ç›®æ ‡ï¼Œä½ç½®: {mid}")
                return mid
            elif arr[mid] < target:
                left = mid + 1
                self.add_execution_step(f"ç›®æ ‡åœ¨å³åŠéƒ¨åˆ†ï¼Œæ›´æ–°å·¦è¾¹ç•Œ: {left}")
            else:
                right = mid - 1
                self.add_execution_step(f"ç›®æ ‡åœ¨å·¦åŠéƒ¨åˆ†ï¼Œæ›´æ–°å³è¾¹ç•Œ: {right}")
        
        self.add_execution_step("æœªæ‰¾åˆ°ç›®æ ‡")
        return None

class SortAlgorithm(Algorithm):
    """æ’åºç®—æ³•åŸºç±»"""
    
    def __init__(self, specification: AlgorithmSpecification):
        super().__init__(specification)
        self.performance_metrics.time_complexity = ComplexityClass.QUADRATIC
    
    def bubble_sort(self, arr: List[Any]) -> List[Any]:
        """å†’æ³¡æ’åº"""
        self.reset_execution_history()
        arr_copy = arr.copy()
        n = len(arr_copy)
        
        for i in range(n):
            swapped = False
            self.add_execution_step(f"ç¬¬ {i+1} è½®æ’åºå¼€å§‹")
            
            for j in range(0, n - i - 1):
                self.performance_metrics.comparisons += 1
                self.add_execution_step(f"æ¯”è¾ƒ {arr_copy[j]} å’Œ {arr_copy[j+1]}")
                
                if arr_copy[j] > arr_copy[j + 1]:
                    arr_copy[j], arr_copy[j + 1] = arr_copy[j + 1], arr_copy[j]
                    self.performance_metrics.swaps += 1
                    self.add_execution_step(f"äº¤æ¢å…ƒç´ : {arr_copy[j+1]} <-> {arr_copy[j]}")
                    swapped = True
            
            if not swapped:
                self.add_execution_step("æ²¡æœ‰äº¤æ¢ï¼Œæ•°ç»„å·²æ’åº")
                break
        
        return arr_copy
    
    def quick_sort(self, arr: List[Any]) -> List[Any]:
        """å¿«é€Ÿæ’åº"""
        self.reset_execution_history()
        arr_copy = arr.copy()
        
        def partition(low: int, high: int) -> int:
            pivot = arr_copy[high]
            i = low - 1
            
            self.add_execution_step(f"é€‰æ‹©åŸºå‡†å…ƒç´ : {pivot}")
            
            for j in range(low, high):
                self.performance_metrics.comparisons += 1
                if arr_copy[j] <= pivot:
                    i += 1
                    arr_copy[i], arr_copy[j] = arr_copy[j], arr_copy[i]
                    self.performance_metrics.swaps += 1
            
            arr_copy[i + 1], arr_copy[high] = arr_copy[high], arr_copy[i + 1]
            self.performance_metrics.swaps += 1
            
            return i + 1
        
        def quick_sort_helper(low: int, high: int):
            if low < high:
                pi = partition(low, high)
                self.add_execution_step(f"åˆ†åŒºå®Œæˆï¼ŒåŸºå‡†ä½ç½®: {pi}")
                quick_sort_helper(low, pi - 1)
                quick_sort_helper(pi + 1, high)
        
        quick_sort_helper(0, len(arr_copy) - 1)
        return arr_copy

class AlgorithmTheory:
    """ç®—æ³•ç†è®ºæ¡†æ¶"""
    
    def __init__(self):
        self.algorithms: Dict[str, Algorithm] = {}
        self.complexity_analysis: Dict[str, Dict[str, Any]] = {}
        self.algorithm_patterns: List[str] = []
    
    def add_algorithm(self, algorithm: Algorithm):
        """æ·»åŠ ç®—æ³•"""
        self.algorithms[algorithm.specification.name] = algorithm
    
    def analyze_algorithm_complexity(self, algorithm_name: str, input_sizes: List[int]) -> Dict[str, Any]:
        """åˆ†æç®—æ³•å¤æ‚åº¦"""
        if algorithm_name not in self.algorithms:
            raise ValueError(f"ç®—æ³• {algorithm_name} ä¸å­˜åœ¨")
        
        algorithm = self.algorithms[algorithm_name]
        results = {
            "algorithm": algorithm_name,
            "input_sizes": input_sizes,
            "runtime_measurements": [],
            "complexity_analysis": {}
        }
        
        for size in input_sizes:
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            test_data = self._generate_test_data(algorithm, size)
            
            # æµ‹é‡æ€§èƒ½
            metrics = algorithm.measure_performance(test_data)
            results["runtime_measurements"].append({
                "input_size": size,
                "runtime": metrics.actual_runtime,
                "comparisons": metrics.comparisons,
                "swaps": metrics.swaps
            })
        
        # åˆ†æå¤æ‚åº¦
        results["complexity_analysis"] = self._analyze_complexity_trend(results["runtime_measurements"])
        
        return results
    
    def _generate_test_data(self, algorithm: Algorithm, size: int) -> Any:
        """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
        if isinstance(algorithm, SearchAlgorithm):
            # ä¸ºæœç´¢ç®—æ³•ç”Ÿæˆæ•°æ®
            import random
            data = list(range(size))
            target = random.choice(data)
            return {"array": data, "target": target}
        elif isinstance(algorithm, SortAlgorithm):
            # ä¸ºæ’åºç®—æ³•ç”Ÿæˆæ•°æ®
            import random
            return [random.randint(1, 1000) for _ in range(size)]
        else:
            return list(range(size))
    
    def _analyze_complexity_trend(self, measurements: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æå¤æ‚åº¦è¶‹åŠ¿"""
        if len(measurements) < 2:
            return {"trend": "insufficient_data"}
        
        # è®¡ç®—å¢é•¿ç‡
        growth_rates = []
        for i in range(1, len(measurements)):
            size_ratio = measurements[i]["input_size"] / measurements[i-1]["input_size"]
            runtime_ratio = measurements[i]["runtime"] / measurements[i-1]["runtime"]
            growth_rate = runtime_ratio / size_ratio
            growth_rates.append(growth_rate)
        
        avg_growth_rate = sum(growth_rates) / len(growth_rates)
        
        # åˆ¤æ–­å¤æ‚åº¦ç±»å‹
        if avg_growth_rate < 1.5:
            complexity_type = "O(1) - å¸¸æ•°æ—¶é—´"
        elif avg_growth_rate < 2.5:
            complexity_type = "O(log n) - å¯¹æ•°æ—¶é—´"
        elif avg_growth_rate < 3.5:
            complexity_type = "O(n) - çº¿æ€§æ—¶é—´"
        elif avg_growth_rate < 4.5:
            complexity_type = "O(n log n) - çº¿æ€§å¯¹æ•°æ—¶é—´"
        else:
            complexity_type = "O(nÂ²) - äºŒæ¬¡æ—¶é—´"
        
        return {
            "average_growth_rate": avg_growth_rate,
            "estimated_complexity": complexity_type,
            "growth_rates": growth_rates
        }
    
    def compare_algorithms(self, algorithm_names: List[str], input_sizes: List[int]) -> Dict[str, Any]:
        """æ¯”è¾ƒç®—æ³•æ€§èƒ½"""
        comparison_results = {
            "algorithms": algorithm_names,
            "input_sizes": input_sizes,
            "performance_comparison": {}
        }
        
        for size in input_sizes:
            size_results = {}
            for name in algorithm_names:
                if name in self.algorithms:
                    algorithm = self.algorithms[name]
                    test_data = self._generate_test_data(algorithm, size)
                    metrics = algorithm.measure_performance(test_data)
                    
                    size_results[name] = {
                        "runtime": metrics.actual_runtime,
                        "comparisons": metrics.comparisons,
                        "swaps": metrics.swaps,
                        "memory_usage": metrics.memory_usage
                    }
            
            comparison_results["performance_comparison"][size] = size_results
        
        return comparison_results
    
    def generate_algorithm_report(self, algorithm_name: str) -> Dict[str, Any]:
        """ç”Ÿæˆç®—æ³•æŠ¥å‘Š"""
        if algorithm_name not in self.algorithms:
            raise ValueError(f"ç®—æ³• {algorithm_name} ä¸å­˜åœ¨")
        
        algorithm = self.algorithms[algorithm_name]
        
        return {
            "specification": algorithm.specification.__dict__,
            "performance_metrics": {
                "time_complexity": algorithm.performance_metrics.time_complexity.value,
                "space_complexity": algorithm.performance_metrics.space_complexity.value,
                "actual_runtime": algorithm.performance_metrics.actual_runtime,
                "memory_usage": algorithm.performance_metrics.memory_usage
            },
            "execution_trace": algorithm.get_execution_trace(),
            "theoretical_analysis": self._theoretical_analysis(algorithm)
        }
    
    def _theoretical_analysis(self, algorithm: Algorithm) -> Dict[str, Any]:
        """ç†è®ºåˆ†æ"""
        return {
            "correctness": "ç®—æ³•æ­£ç¡®æ€§åˆ†æ",
            "termination": "ç®—æ³•ç»ˆæ­¢æ€§åˆ†æ",
            "optimality": "ç®—æ³•æœ€ä¼˜æ€§åˆ†æ",
            "stability": "ç®—æ³•ç¨³å®šæ€§åˆ†æ"
        }

# ä½¿ç”¨ç¤ºä¾‹
def demonstrate_algorithm_theory():
    """æ¼”ç¤ºç®—æ³•ç†è®º"""
    
    # åˆ›å»ºç®—æ³•ç†è®ºæ¡†æ¶
    theory = AlgorithmTheory()
    
    # åˆ›å»ºæœç´¢ç®—æ³•
    linear_search_spec = AlgorithmSpecification(
        name="çº¿æ€§æœç´¢",
        algorithm_type=AlgorithmType.SEARCH,
        description="åœ¨æ•°ç»„ä¸­çº¿æ€§æœç´¢ç›®æ ‡å…ƒç´ ",
        input_specification="æ•°ç»„å’Œç›®æ ‡å€¼",
        output_specification="ç›®æ ‡å€¼çš„ç´¢å¼•æˆ–None",
        preconditions=["æ•°ç»„ä¸ä¸ºç©º"],
        postconditions=["è¿”å›æ­£ç¡®ç´¢å¼•æˆ–None"]
    )
    
    binary_search_spec = AlgorithmSpecification(
        name="äºŒåˆ†æœç´¢",
        algorithm_type=AlgorithmType.SEARCH,
        description="åœ¨æœ‰åºæ•°ç»„ä¸­äºŒåˆ†æœç´¢ç›®æ ‡å…ƒç´ ",
        input_specification="æœ‰åºæ•°ç»„å’Œç›®æ ‡å€¼",
        output_specification="ç›®æ ‡å€¼çš„ç´¢å¼•æˆ–None",
        preconditions=["æ•°ç»„å·²æ’åº"],
        postconditions=["è¿”å›æ­£ç¡®ç´¢å¼•æˆ–None"]
    )
    
    # åˆ›å»ºæ’åºç®—æ³•
    bubble_sort_spec = AlgorithmSpecification(
        name="å†’æ³¡æ’åº",
        algorithm_type=AlgorithmType.SORT,
        description="é€šè¿‡ç›¸é‚»å…ƒç´ æ¯”è¾ƒå’Œäº¤æ¢è¿›è¡Œæ’åº",
        input_specification="æ— åºæ•°ç»„",
        output_specification="æœ‰åºæ•°ç»„",
        preconditions=["æ•°ç»„ä¸ä¸ºç©º"],
        postconditions=["æ•°ç»„æŒ‰å‡åºæ’åˆ—"]
    )
    
    quick_sort_spec = AlgorithmSpecification(
        name="å¿«é€Ÿæ’åº",
        algorithm_type=AlgorithmType.SORT,
        description="ä½¿ç”¨åˆ†æ²»ç­–ç•¥çš„å¿«é€Ÿæ’åºç®—æ³•",
        input_specification="æ— åºæ•°ç»„",
        output_specification="æœ‰åºæ•°ç»„",
        preconditions=["æ•°ç»„ä¸ä¸ºç©º"],
        postconditions=["æ•°ç»„æŒ‰å‡åºæ’åˆ—"]
    )
    
    # åˆ›å»ºç®—æ³•å®ä¾‹
    linear_search = SearchAlgorithm(linear_search_spec)
    binary_search = SearchAlgorithm(binary_search_spec)
    bubble_sort = SortAlgorithm(bubble_sort_spec)
    quick_sort = SortAlgorithm(quick_sort_spec)
    
    # æ·»åŠ åˆ°ç†è®ºæ¡†æ¶
    theory.add_algorithm(linear_search)
    theory.add_algorithm(binary_search)
    theory.add_algorithm(bubble_sort)
    theory.add_algorithm(quick_sort)
    
    # æµ‹è¯•æœç´¢ç®—æ³•
    test_array = [1, 3, 5, 7, 9, 11, 13, 15]
    target = 7
    
    print("=== æœç´¢ç®—æ³•æµ‹è¯• ===")
    
    # çº¿æ€§æœç´¢
    linear_result = linear_search.linear_search(test_array, target)
    print(f"çº¿æ€§æœç´¢ç»“æœ: {linear_result}")
    
    # äºŒåˆ†æœç´¢
    binary_result = binary_search.binary_search(test_array, target)
    print(f"äºŒåˆ†æœç´¢ç»“æœ: {binary_result}")
    
    # æµ‹è¯•æ’åºç®—æ³•
    test_sort_array = [64, 34, 25, 12, 22, 11, 90]
    
    print("\n=== æ’åºç®—æ³•æµ‹è¯• ===")
    
    # å†’æ³¡æ’åº
    bubble_result = bubble_sort.bubble_sort(test_sort_array)
    print(f"å†’æ³¡æ’åºç»“æœ: {bubble_result}")
    
    # å¿«é€Ÿæ’åº
    quick_result = quick_sort.quick_sort(test_sort_array)
    print(f"å¿«é€Ÿæ’åºç»“æœ: {quick_result}")
    
    # æ€§èƒ½åˆ†æ
    input_sizes = [100, 500, 1000]
    
    print("\n=== æ€§èƒ½åˆ†æ ===")
    
    # åˆ†æçº¿æ€§æœç´¢
    linear_analysis = theory.analyze_algorithm_complexity("çº¿æ€§æœç´¢", input_sizes)
    print(f"çº¿æ€§æœç´¢å¤æ‚åº¦åˆ†æ: {linear_analysis['complexity_analysis']}")
    
    # åˆ†æå¿«é€Ÿæ’åº
    quick_analysis = theory.analyze_algorithm_complexity("å¿«é€Ÿæ’åº", input_sizes)
    print(f"å¿«é€Ÿæ’åºå¤æ‚åº¦åˆ†æ: {quick_analysis['complexity_analysis']}")
    
    # ç®—æ³•æ¯”è¾ƒ
    comparison = theory.compare_algorithms(["çº¿æ€§æœç´¢", "äºŒåˆ†æœç´¢"], [100, 500, 1000])
    print(f"\nç®—æ³•æ¯”è¾ƒç»“æœ: {comparison['performance_comparison']}")
    
    return theory

if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    result = demonstrate_algorithm_theory()
```

## ğŸ“Š ç†è®ºè¯æ˜

### 1. ç®—æ³•æ­£ç¡®æ€§å®šç†

**å®šç†**: å¦‚æœä¸€ä¸ªç®—æ³•æ»¡è¶³å‰ç½®æ¡ä»¶å’Œåç½®æ¡ä»¶ï¼Œåˆ™è¯¥ç®—æ³•æ˜¯æ­£ç¡®çš„ã€‚

**è¯æ˜**:
1. è®¾ $P$ æ˜¯å‰ç½®æ¡ä»¶ï¼Œ$Q$ æ˜¯åç½®æ¡ä»¶
2. å¦‚æœç®—æ³•åœ¨æ»¡è¶³ $P$ çš„è¾“å…¥ä¸Šæ‰§è¡Œåæ»¡è¶³ $Q$ï¼Œåˆ™ç®—æ³•æ­£ç¡®
3. è¿™å¯ä»¥é€šè¿‡æ•°å­¦å½’çº³æ³•æˆ–å¾ªç¯ä¸å˜é‡æ¥è¯æ˜

### 2. ç®—æ³•å¤æ‚åº¦å®šç†

**å®šç†**: å¯¹äºè¾“å…¥å¤§å°ä¸º $n$ çš„ç®—æ³•ï¼Œæ—¶é—´å¤æ‚åº¦ä¸º $O(f(n))$ å½“ä¸”ä»…å½“å­˜åœ¨å¸¸æ•° $c$ å’Œ $n_0$ï¼Œä½¿å¾—å¯¹äºæ‰€æœ‰ $n \geq n_0$ï¼Œç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¶…è¿‡ $c \cdot f(n)$ã€‚

**è¯æ˜**:
1. è®¾ $T(n)$ æ˜¯ç®—æ³•çš„å®é™…æ‰§è¡Œæ—¶é—´
2. å¦‚æœ $T(n) = O(f(n))$ï¼Œåˆ™å­˜åœ¨ $c > 0$ å’Œ $n_0 > 0$
3. ä½¿å¾—å¯¹äºæ‰€æœ‰ $n \geq n_0$ï¼Œæœ‰ $T(n) \leq c \cdot f(n)$

## ğŸ”— ç›¸å…³æ¦‚å¿µ

- [æ•°æ®ç»“æ„ç†è®º](../02-02-æ•°æ®ç»“æ„ç†è®º/02-02-01-æ•°æ®ç»“æ„åŸºç¡€.md)
- [è®¡ç®—å¤æ‚æ€§ç†è®º](../02-03-è®¡ç®—å¤æ‚æ€§ç†è®º/02-03-01-å¤æ‚åº¦åˆ†æ.md)
- [å½¢å¼è¯­è¨€ç†è®º](../02-04-å½¢å¼è¯­è¨€ç†è®º/02-04-01-å½¢å¼è¯­è¨€åŸºç¡€.md)
- [é›†åˆè®ºåŸºç¡€](../../01-å½¢å¼ç§‘å­¦/01-01-æ•°å­¦åŸºç¡€/01-01-01-é›†åˆè®ºåŸºç¡€.md)

## ğŸ“ˆ åº”ç”¨å®ä¾‹

### 1. ç®—æ³•æ€§èƒ½åŸºå‡†æµ‹è¯•

```python
class AlgorithmBenchmark:
    """ç®—æ³•æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    def __init__(self):
        self.benchmark_results = {}
    
    def run_benchmark(self, algorithm: Algorithm, test_cases: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
        results = {
            "algorithm": algorithm.specification.name,
            "test_cases": [],
            "summary": {}
        }
        
        total_runtime = 0
        total_comparisons = 0
        total_swaps = 0
        
        for i, test_case in enumerate(test_cases):
            # æµ‹é‡æ€§èƒ½
            metrics = algorithm.measure_performance(test_case["input"])
            
            case_result = {
                "case_id": i + 1,
                "input_size": len(test_case["input"]) if isinstance(test_case["input"], (list, tuple)) else 1,
                "runtime": metrics.actual_runtime,
                "comparisons": metrics.comparisons,
                "swaps": metrics.swaps,
                "memory_usage": metrics.memory_usage
            }
            
            results["test_cases"].append(case_result)
            
            total_runtime += metrics.actual_runtime
            total_comparisons += metrics.comparisons
            total_swaps += metrics.swaps
        
        # è®¡ç®—ç»Ÿè®¡æ‘˜è¦
        num_cases = len(test_cases)
        results["summary"] = {
            "total_test_cases": num_cases,
            "average_runtime": total_runtime / num_cases,
            "average_comparisons": total_comparisons / num_cases,
            "average_swaps": total_swaps / num_cases,
            "total_runtime": total_runtime
        }
        
        return results
    
    def compare_algorithms_benchmark(self, algorithms: List[Algorithm], test_cases: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ¯”è¾ƒå¤šä¸ªç®—æ³•çš„åŸºå‡†æµ‹è¯•"""
        comparison_results = {
            "algorithms": [alg.specification.name for alg in algorithms],
            "test_cases": test_cases,
            "results": {}
        }
        
        for algorithm in algorithms:
            alg_results = self.run_benchmark(algorithm, test_cases)
            comparison_results["results"][algorithm.specification.name] = alg_results
        
        # ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š
        comparison_results["comparison"] = self._generate_comparison_report(comparison_results["results"])
        
        return comparison_results
    
    def _generate_comparison_report(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š"""
        report = {
            "performance_ranking": [],
            "efficiency_analysis": {},
            "recommendations": []
        }
        
        # æŒ‰å¹³å‡è¿è¡Œæ—¶é—´æ’åº
        algorithms_by_runtime = sorted(
            results.items(),
            key=lambda x: x[1]["summary"]["average_runtime"]
        )
        
        report["performance_ranking"] = [
            {
                "rank": i + 1,
                "algorithm": name,
                "average_runtime": data["summary"]["average_runtime"]
            }
            for i, (name, data) in enumerate(algorithms_by_runtime)
        ]
        
        # æ•ˆç‡åˆ†æ
        fastest = algorithms_by_runtime[0]
        for name, data in results.items():
            speedup = fastest[1]["summary"]["average_runtime"] / data["summary"]["average_runtime"]
            report["efficiency_analysis"][name] = {
                "speedup_factor": speedup,
                "relative_performance": f"{speedup:.2f}x {'faster' if speedup > 1 else 'slower'} than fastest"
            }
        
        # ç”Ÿæˆå»ºè®®
        report["recommendations"] = [
            f"æ¨èä½¿ç”¨ {fastest[0]} ä½œä¸ºä¸»è¦ç®—æ³•",
            "è€ƒè™‘ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦å’Œç©ºé—´å¤æ‚åº¦æƒè¡¡",
            "æ ¹æ®å…·ä½“åº”ç”¨åœºæ™¯é€‰æ‹©æœ€é€‚åˆçš„ç®—æ³•"
        ]
        
        return report

# ä½¿ç”¨ç¤ºä¾‹
def demonstrate_algorithm_benchmark():
    """æ¼”ç¤ºç®—æ³•åŸºå‡†æµ‹è¯•"""
    
    # åˆ›å»ºæµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {"input": list(range(100)), "description": "å°è§„æ¨¡æœ‰åºæ•°æ®"},
        {"input": list(range(1000)), "description": "ä¸­ç­‰è§„æ¨¡æœ‰åºæ•°æ®"},
        {"input": list(range(10000)), "description": "å¤§è§„æ¨¡æœ‰åºæ•°æ®"},
        {"input": [random.randint(1, 1000) for _ in range(100)], "description": "å°è§„æ¨¡éšæœºæ•°æ®"},
        {"input": [random.randint(1, 1000) for _ in range(1000)], "description": "ä¸­ç­‰è§„æ¨¡éšæœºæ•°æ®"}
    ]
    
    # åˆ›å»ºç®—æ³•å®ä¾‹
    linear_search = SearchAlgorithm(AlgorithmSpecification(
        name="çº¿æ€§æœç´¢", algorithm_type=AlgorithmType.SEARCH,
        description="", input_specification="", output_specification="",
        preconditions=[], postconditions=[]
    ))
    
    binary_search = SearchAlgorithm(AlgorithmSpecification(
        name="äºŒåˆ†æœç´¢", algorithm_type=AlgorithmType.SEARCH,
        description="", input_specification="", output_specification="",
        preconditions=[], postconditions=[]
    ))
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    benchmark = AlgorithmBenchmark()
    
    # å•ä¸ªç®—æ³•æµ‹è¯•
    linear_results = benchmark.run_benchmark(linear_search, test_cases)
    print("=== çº¿æ€§æœç´¢åŸºå‡†æµ‹è¯• ===")
    print(f"å¹³å‡è¿è¡Œæ—¶é—´: {linear_results['summary']['average_runtime']:.6f} ç§’")
    print(f"å¹³å‡æ¯”è¾ƒæ¬¡æ•°: {linear_results['summary']['average_comparisons']}")
    
    # ç®—æ³•æ¯”è¾ƒ
    comparison = benchmark.compare_algorithms_benchmark(
        [linear_search, binary_search], test_cases
    )
    
    print("\n=== ç®—æ³•æ¯”è¾ƒç»“æœ ===")
    for rank in comparison["comparison"]["performance_ranking"]:
        print(f"æ’å {rank['rank']}: {rank['algorithm']} - {rank['average_runtime']:.6f} ç§’")
    
    print("\n=== æ•ˆç‡åˆ†æ ===")
    for alg_name, analysis in comparison["comparison"]["efficiency_analysis"].items():
        print(f"{alg_name}: {analysis['relative_performance']}")
    
    print("\n=== å»ºè®® ===")
    for recommendation in comparison["comparison"]["recommendations"]:
        print(f"- {recommendation}")

if __name__ == "__main__":
    import random
    demonstrate_algorithm_benchmark()
```

### 2. ç®—æ³•å¯è§†åŒ–åˆ†æ

```python
class AlgorithmVisualizer:
    """ç®—æ³•å¯è§†åŒ–åˆ†æå™¨"""
    
    def __init__(self):
        self.visualization_data = {}
    
    def visualize_execution_trace(self, algorithm: Algorithm) -> Dict[str, Any]:
        """å¯è§†åŒ–æ‰§è¡Œè½¨è¿¹"""
        trace = algorithm.get_execution_trace()
        
        visualization = {
            "algorithm_name": algorithm.specification.name,
            "total_steps": len(trace),
            "steps": [],
            "performance_metrics": {
                "comparisons": algorithm.performance_metrics.comparisons,
                "swaps": algorithm.performance_metrics.swaps,
                "runtime": algorithm.performance_metrics.actual_runtime
            }
        }
        
        for step in trace:
            step_visualization = {
                "step_number": step["step"],
                "description": step["description"],
                "data": step["data"],
                "timestamp": step["timestamp"]
            }
            visualization["steps"].append(step_visualization)
        
        return visualization
    
    def generate_complexity_chart_data(self, algorithm: Algorithm, input_sizes: List[int]) -> Dict[str, Any]:
        """ç”Ÿæˆå¤æ‚åº¦å›¾è¡¨æ•°æ®"""
        chart_data = {
            "algorithm_name": algorithm.specification.name,
            "input_sizes": input_sizes,
            "actual_runtimes": [],
            "theoretical_complexity": algorithm.performance_metrics.time_complexity.value,
            "data_points": []
        }
        
        for size in input_sizes:
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            test_data = list(range(size))
            
            # æµ‹é‡æ€§èƒ½
            metrics = algorithm.measure_performance(test_data)
            
            chart_data["actual_runtimes"].append(metrics.actual_runtime)
            chart_data["data_points"].append({
                "input_size": size,
                "runtime": metrics.actual_runtime,
                "comparisons": metrics.comparisons,
                "swaps": metrics.swaps
            })
        
        return chart_data
    
    def create_performance_report(self, algorithms: List[Algorithm], input_sizes: List[int]) -> Dict[str, Any]:
        """åˆ›å»ºæ€§èƒ½æŠ¥å‘Š"""
        report = {
            "algorithms": [],
            "input_sizes": input_sizes,
            "performance_data": {},
            "comparison_charts": {}
        }
        
        for algorithm in algorithms:
            alg_name = algorithm.specification.name
            chart_data = self.generate_complexity_chart_data(algorithm, input_sizes)
            
            report["algorithms"].append({
                "name": alg_name,
                "type": algorithm.specification.algorithm_type.value,
                "complexity": algorithm.performance_metrics.time_complexity.value
            })
            
            report["performance_data"][alg_name] = chart_data
        
        # ç”Ÿæˆæ¯”è¾ƒå›¾è¡¨æ•°æ®
        report["comparison_charts"] = self._generate_comparison_charts(report["performance_data"])
        
        return report
    
    def _generate_comparison_charts(self, performance_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ¯”è¾ƒå›¾è¡¨"""
        charts = {
            "runtime_comparison": {},
            "complexity_comparison": {},
            "efficiency_analysis": {}
        }
        
        # è¿è¡Œæ—¶æ¯”è¾ƒ
        for alg_name, data in performance_data.items():
            charts["runtime_comparison"][alg_name] = {
                "input_sizes": data["input_sizes"],
                "runtimes": data["actual_runtimes"]
            }
        
        # å¤æ‚åº¦æ¯”è¾ƒ
        for alg_name, data in performance_data.items():
            charts["complexity_comparison"][alg_name] = data["theoretical_complexity"]
        
        # æ•ˆç‡åˆ†æ
        if len(performance_data) > 1:
            fastest_alg = min(performance_data.keys(), 
                            key=lambda x: performance_data[x]["actual_runtimes"][-1])
            
            for alg_name, data in performance_data.items():
                fastest_runtime = performance_data[fastest_alg]["actual_runtimes"][-1]
                current_runtime = data["actual_runtimes"][-1]
                
                charts["efficiency_analysis"][alg_name] = {
                    "speedup": fastest_runtime / current_runtime if current_runtime > 0 else 0,
                    "relative_performance": f"{fastest_runtime / current_runtime:.2f}x" if current_runtime > 0 else "N/A"
                }
        
        return charts

# ä½¿ç”¨ç¤ºä¾‹
def demonstrate_algorithm_visualization():
    """æ¼”ç¤ºç®—æ³•å¯è§†åŒ–"""
    
    # åˆ›å»ºç®—æ³•å®ä¾‹
    bubble_sort = SortAlgorithm(AlgorithmSpecification(
        name="å†’æ³¡æ’åº", algorithm_type=AlgorithmType.SORT,
        description="", input_specification="", output_specification="",
        preconditions=[], postconditions=[]
    ))
    
    quick_sort = SortAlgorithm(AlgorithmSpecification(
        name="å¿«é€Ÿæ’åº", algorithm_type=AlgorithmType.SORT,
        description="", input_specification="", output_specification="",
        preconditions=[], postconditions=[]
    ))
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = AlgorithmVisualizer()
    
    # æµ‹è¯•æ•°æ®
    test_data = [64, 34, 25, 12, 22, 11, 90]
    
    # å¯è§†åŒ–æ‰§è¡Œè½¨è¿¹
    bubble_sort.bubble_sort(test_data.copy())
    bubble_trace = visualizer.visualize_execution_trace(bubble_sort)
    
    print("=== å†’æ³¡æ’åºæ‰§è¡Œè½¨è¿¹ ===")
    print(f"æ€»æ­¥æ•°: {bubble_trace['total_steps']}")
    print(f"æ¯”è¾ƒæ¬¡æ•°: {bubble_trace['performance_metrics']['comparisons']}")
    print(f"äº¤æ¢æ¬¡æ•°: {bubble_trace['performance_metrics']['swaps']}")
    
    # ç”Ÿæˆå¤æ‚åº¦å›¾è¡¨æ•°æ®
    input_sizes = [10, 50, 100, 500]
    bubble_chart = visualizer.generate_complexity_chart_data(bubble_sort, input_sizes)
    
    print("\n=== å†’æ³¡æ’åºå¤æ‚åº¦åˆ†æ ===")
    print(f"ç†è®ºå¤æ‚åº¦: {bubble_chart['theoretical_complexity']}")
    print(f"å®é™…è¿è¡Œæ—¶é—´: {bubble_chart['actual_runtimes']}")
    
    # åˆ›å»ºæ€§èƒ½æŠ¥å‘Š
    algorithms = [bubble_sort, quick_sort]
    report = visualizer.create_performance_report(algorithms, input_sizes)
    
    print("\n=== ç®—æ³•æ€§èƒ½æŠ¥å‘Š ===")
    for alg_info in report["algorithms"]:
        print(f"ç®—æ³•: {alg_info['name']}")
        print(f"ç±»å‹: {alg_info['type']}")
        print(f"å¤æ‚åº¦: {alg_info['complexity']}")
        print()

if __name__ == "__main__":
    demonstrate_algorithm_visualization()
```

## ğŸ¯ æ€»ç»“

ç®—æ³•ç†è®ºä¸ºè®¡ç®—æœºç§‘å­¦æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€ã€‚é€šè¿‡å½¢å¼åŒ–å®šä¹‰ã€å¤šè¡¨å¾æ–¹å¼å’Œå®é™…åº”ç”¨ï¼Œæˆ‘ä»¬å»ºç«‹äº†å®Œæ•´çš„ç®—æ³•ç†è®ºä½“ç³»ï¼Œä¸ºç®—æ³•è®¾è®¡ã€åˆ†æå’Œä¼˜åŒ–æä¾›äº†æŒ‡å¯¼ã€‚

### å…³é”®è¦ç‚¹

1. **å½¢å¼åŒ–å®šä¹‰**: ç®—æ³•å¯ä»¥ç”¨å››å…ƒç»„ $\mathcal{A} = (I, O, C, T)$ è¡¨ç¤º
2. **ç®—æ³•ç‰¹æ€§**: æœ‰é™æ€§ã€ç¡®å®šæ€§ã€æœ‰æ•ˆæ€§ã€è¾“å…¥ã€è¾“å‡º
3. **å¤šè¡¨å¾æ–¹å¼**: åŒ…å«æ¦‚å¿µè§£é‡Šã€æ•°å­¦å½¢å¼ã€ä»£ç å®ç°ã€å›¾è¡¨è¯´æ˜å’Œå®ä¾‹åˆ†æ
4. **å®é™…åº”ç”¨**: é€šè¿‡Pythonå®ç°éªŒè¯ç†è®ºæ¦‚å¿µ
5. **ç†è®ºè¯æ˜**: æä¾›æ­£ç¡®æ€§å®šç†å’Œå¤æ‚åº¦å®šç†çš„è¯æ˜

---

**ç›¸å…³æ–‡æ¡£**: 
- [æ’åºç®—æ³•](./02-01-02-æ’åºç®—æ³•.md)
- [æœç´¢ç®—æ³•](./02-01-03-æœç´¢ç®—æ³•.md)
- [å›¾ç®—æ³•](./02-01-04-å›¾ç®—æ³•.md)
- [åŠ¨æ€è§„åˆ’](./02-01-05-åŠ¨æ€è§„åˆ’.md)
