# 内存优化

## 📋 概述

内存优化是性能优化的重要组成部分，涉及内存管理、垃圾回收、内存池化、内存泄漏检测等技术。本文档提供内存优化的形式化定义、技术实现和最佳实践。

## 1. 形式化定义

### 1.1 内存系统定义

**定义 1.1** (内存系统)
内存系统是一个五元组 $\mathcal{M} = (A, F, G, P, O)$，其中：

- $A$ 是内存分配，$A = (R, S, T)$
- $F$ 是内存释放，$F = (D, C, R)$
- $G$ 是垃圾回收，$G = (M, S, C)$
- $P$ 是内存池化，$P = (I, R, M)$
- $O$ 是内存优化，$O = (L, C, P)$

**定义 1.2** (内存使用模式)
内存使用模式是一个三元组 $\mathcal{U} = (A, L, F)$，其中：

- $A$ 是分配模式，$A = (S, F, T)$
- $L$ 是生命周期，$L = (C, D, R)$
- $F$ 是碎片化，$F = (I, E, C)$

### 1.2 内存优化策略

**定义 1.3** (内存优化策略)
内存优化策略是一个四元组 $\mathcal{O} = (P, C, L, M)$，其中：

- $P$ 是池化策略，$P = (I, R, M)$
- $C$ 是缓存策略，$C = (S, T, R)$
- $L$ 是生命周期管理，$L = (C, D, R)$
- $M$ 是内存映射，$M = (F, P, S)$

## 2. 技术实现

### 2.1 内存监控系统

```python
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Callable, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import psutil
import tracemalloc
import gc
import sys
import time
import threading
import weakref
from collections import defaultdict, deque
import logging

class MemoryMetric(Enum):
    """内存指标类型"""
    USED = "used"
    AVAILABLE = "available"
    PERCENT = "percent"
    CACHED = "cached"
    BUFFERS = "buffers"

@dataclass
class MemorySnapshot:
    """内存快照"""
    timestamp: float
    used_memory: int
    available_memory: int
    total_memory: int
    memory_percent: float
    object_count: int
    gc_stats: Dict[str, Any] = field(default_factory=dict)

@dataclass
class MemoryLeak:
    """内存泄漏"""
    object_type: str
    count: int
    size: int
    traceback: List[str]
    first_seen: float
    last_seen: float

class MemoryMonitor:
    """内存监控器"""
    
    def __init__(self):
        self.snapshots: List[MemorySnapshot] = []
        self.leaks: Dict[str, MemoryLeak] = {}
        self.monitoring = False
        self.monitor_thread = None
        
    def start_monitoring(self, interval: float = 1.0):
        """开始监控"""
        if self.monitoring:
            return
        
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, args=(interval,))
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
        
        logging.info("Memory monitoring started")
    
    def stop_monitoring(self):
        """停止监控"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()
        
        logging.info("Memory monitoring stopped")
    
    def _monitor_loop(self, interval: float):
        """监控循环"""
        while self.monitoring:
            self.take_snapshot()
            time.sleep(interval)
    
    def take_snapshot(self) -> MemorySnapshot:
        """获取内存快照"""
        # 获取系统内存信息
        memory = psutil.virtual_memory()
        
        # 获取Python对象统计
        object_count = len(gc.get_objects())
        
        # 获取垃圾回收统计
        gc_stats = {
            "collections": gc.get_stats(),
            "counts": gc.get_count(),
            "thresholds": gc.get_threshold()
        }
        
        snapshot = MemorySnapshot(
            timestamp=time.time(),
            used_memory=memory.used,
            available_memory=memory.available,
            total_memory=memory.total,
            memory_percent=memory.percent,
            object_count=object_count,
            gc_stats=gc_stats
        )
        
        self.snapshots.append(snapshot)
        return snapshot
    
    def detect_memory_leaks(self) -> List[MemoryLeak]:
        """检测内存泄漏"""
        if len(self.snapshots) < 2:
            return []
        
        leaks = []
        
        # 分析内存增长趋势
        recent_snapshots = self.snapshots[-10:]  # 最近10个快照
        
        if len(recent_snapshots) >= 2:
            first = recent_snapshots[0]
            last = recent_snapshots[-1]
            
            # 计算内存增长率
            memory_growth = (last.used_memory - first.used_memory) / first.used_memory
            object_growth = (last.object_count - first.object_count) / first.object_count
            
            if memory_growth > 0.1:  # 内存增长超过10%
                leak = MemoryLeak(
                    object_type="unknown",
                    count=last.object_count - first.object_count,
                    size=last.used_memory - first.used_memory,
                    traceback=[],
                    first_seen=first.timestamp,
                    last_seen=last.timestamp
                )
                leaks.append(leak)
        
        return leaks
    
    def get_memory_report(self) -> Dict[str, Any]:
        """获取内存报告"""
        if not self.snapshots:
            return {}
        
        latest = self.snapshots[-1]
        first = self.snapshots[0]
        
        return {
            "current_memory": {
                "used_mb": latest.used_memory / 1024 / 1024,
                "available_mb": latest.available_memory / 1024 / 1024,
                "total_mb": latest.total_memory / 1024 / 1024,
                "percent": latest.memory_percent
            },
            "memory_growth": {
                "total_growth_mb": (latest.used_memory - first.used_memory) / 1024 / 1024,
                "growth_percent": (latest.used_memory - first.used_memory) / first.used_memory * 100
            },
            "object_stats": {
                "current_objects": latest.object_count,
                "object_growth": latest.object_count - first.object_count
            },
            "gc_stats": latest.gc_stats
        }

class MemoryProfiler:
    """内存分析器"""
    
    def __init__(self):
        self.tracemalloc_enabled = False
        self.snapshots = []
    
    def start_tracemalloc(self):
        """启动内存跟踪"""
        if not self.tracemalloc_enabled:
            tracemalloc.start()
            self.tracemalloc_enabled = True
    
    def stop_tracemalloc(self):
        """停止内存跟踪"""
        if self.tracemalloc_enabled:
            tracemalloc.stop()
            self.tracemalloc_enabled = False
    
    def take_tracemalloc_snapshot(self):
        """获取内存跟踪快照"""
        if not self.tracemalloc_enabled:
            self.start_tracemalloc()
        
        snapshot = tracemalloc.take_snapshot()
        self.snapshots.append(snapshot)
        return snapshot
    
    def compare_snapshots(self, snapshot1_index: int = -2, snapshot2_index: int = -1) -> Dict[str, Any]:
        """比较两个快照"""
        if len(self.snapshots) < 2:
            return {}
        
        snapshot1 = self.snapshots[snapshot1_index]
        snapshot2 = self.snapshots[snapshot2_index]
        
        # 计算差异
        top_stats = snapshot2.compare_to(snapshot1, 'lineno')
        
        return {
            "top_changes": [
                {
                    "file": stat.traceback.format()[-1],
                    "size_diff": stat.size_diff,
                    "count_diff": stat.count_diff
                }
                for stat in top_stats[:10]
            ]
        }
    
    def get_top_allocations(self, limit: int = 10) -> List[Dict[str, Any]]:
        """获取内存分配最多的位置"""
        if not self.snapshots:
            return []
        
        latest_snapshot = self.snapshots[-1]
        top_stats = latest_snapshot.statistics('lineno')
        
        return [
            {
                "file": stat.traceback.format()[-1],
                "size": stat.size,
                "count": stat.count,
                "average_size": stat.size / stat.count if stat.count > 0 else 0
            }
            for stat in top_stats[:limit]
        ]

### 2.2 内存池化系统

```python
class MemoryPool:
    """内存池"""
    
    def __init__(self, block_size: int, max_blocks: int = 1000):
        self.block_size = block_size
        self.max_blocks = max_blocks
        self.available_blocks = deque()
        self.used_blocks = set()
        self.total_allocated = 0
    
    def allocate(self) -> Optional[bytearray]:
        """分配内存块"""
        if self.available_blocks:
            block = self.available_blocks.popleft()
        elif self.total_allocated < self.max_blocks:
            block = bytearray(self.block_size)
            self.total_allocated += 1
        else:
            return None
        
        self.used_blocks.add(id(block))
        return block
    
    def deallocate(self, block: bytearray):
        """释放内存块"""
        if id(block) in self.used_blocks:
            self.used_blocks.remove(id(block))
            block.clear()  # 清空内容
            self.available_blocks.append(block)
    
    def get_stats(self) -> Dict[str, Any]:
        """获取池统计信息"""
        return {
            "block_size": self.block_size,
            "total_blocks": self.total_allocated,
            "used_blocks": len(self.used_blocks),
            "available_blocks": len(self.available_blocks),
            "utilization": len(self.used_blocks) / self.total_allocated if self.total_allocated > 0 else 0
        }

class MemoryPoolManager:
    """内存池管理器"""
    
    def __init__(self):
        self.pools: Dict[int, MemoryPool] = {}
        self.default_sizes = [64, 128, 256, 512, 1024, 2048, 4096]
        
        # 初始化默认池
        for size in self.default_sizes:
            self.pools[size] = MemoryPool(size)
    
    def allocate(self, size: int) -> Optional[bytearray]:
        """分配内存"""
        # 找到合适的池大小
        pool_size = self._find_suitable_pool_size(size)
        
        if pool_size in self.pools:
            return self.pools[pool_size].allocate()
        
        # 如果没有合适的池，创建新的
        self.pools[size] = MemoryPool(size)
        return self.pools[size].allocate()
    
    def deallocate(self, block: bytearray):
        """释放内存"""
        block_size = len(block)
        
        if block_size in self.pools:
            self.pools[block_size].deallocate(block)
    
    def _find_suitable_pool_size(self, size: int) -> int:
        """找到合适的池大小"""
        for pool_size in sorted(self.pools.keys()):
            if pool_size >= size:
                return pool_size
        return size
    
    def get_all_stats(self) -> Dict[str, Any]:
        """获取所有池的统计信息"""
        stats = {}
        total_used = 0
        total_allocated = 0
        
        for size, pool in self.pools.items():
            pool_stats = pool.get_stats()
            stats[f"pool_{size}"] = pool_stats
            total_used += pool_stats["used_blocks"] * size
            total_allocated += pool_stats["total_blocks"] * size
        
        stats["overall"] = {
            "total_used_memory": total_used,
            "total_allocated_memory": total_allocated,
            "memory_efficiency": total_used / total_allocated if total_allocated > 0 else 0
        }
        
        return stats

### 2.3 垃圾回收优化

```python
class GarbageCollectionOptimizer:
    """垃圾回收优化器"""
    
    def __init__(self):
        self.original_thresholds = gc.get_threshold()
        self.optimization_history = []
    
    def optimize_gc_thresholds(self, memory_pressure: float) -> Dict[str, Any]:
        """优化垃圾回收阈值"""
        # 根据内存压力调整阈值
        if memory_pressure > 0.8:  # 高内存压力
            new_thresholds = (
                max(1, self.original_thresholds[0] // 2),  # 减少第0代阈值
                max(1, self.original_thresholds[1] // 2),  # 减少第1代阈值
                max(1, self.original_thresholds[2] // 2)   # 减少第2代阈值
            )
        elif memory_pressure < 0.3:  # 低内存压力
            new_thresholds = (
                self.original_thresholds[0] * 2,  # 增加第0代阈值
                self.original_thresholds[1] * 2,  # 增加第1代阈值
                self.original_thresholds[2] * 2   # 增加第2代阈值
            )
        else:
            new_thresholds = self.original_thresholds
        
        # 设置新阈值
        gc.set_threshold(*new_thresholds)
        
        optimization = {
            "memory_pressure": memory_pressure,
            "original_thresholds": self.original_thresholds,
            "new_thresholds": new_thresholds,
            "timestamp": time.time()
        }
        
        self.optimization_history.append(optimization)
        return optimization
    
    def force_garbage_collection(self) -> Dict[str, Any]:
        """强制垃圾回收"""
        # 获取回收前的统计
        before_stats = gc.get_stats()
        before_counts = gc.get_count()
        
        # 执行垃圾回收
        collected = gc.collect()
        
        # 获取回收后的统计
        after_stats = gc.get_stats()
        after_counts = gc.get_count()
        
        return {
            "objects_collected": collected,
            "before_stats": before_stats,
            "after_stats": after_stats,
            "before_counts": before_counts,
            "after_counts": after_counts,
            "timestamp": time.time()
        }
    
    def analyze_gc_performance(self) -> Dict[str, Any]:
        """分析垃圾回收性能"""
        stats = gc.get_stats()
        
        total_collections = sum(stat["collections"] for stat in stats)
        total_time = sum(stat["collections"] * stat["avg_time"] for stat in stats)
        
        return {
            "total_collections": total_collections,
            "total_time": total_time,
            "average_time_per_collection": total_time / total_collections if total_collections > 0 else 0,
            "generation_stats": stats
        }
    
    def restore_original_thresholds(self):
        """恢复原始阈值"""
        gc.set_threshold(*self.original_thresholds)

### 2.4 内存泄漏检测

```python
class MemoryLeakDetector:
    """内存泄漏检测器"""
    
    def __init__(self):
        self.object_tracker = weakref.WeakSet()
        self.leak_suspicious = defaultdict(int)
        self.detection_history = []
    
    def track_object(self, obj: Any, obj_type: str = None):
        """跟踪对象"""
        if obj_type is None:
            obj_type = type(obj).__name__
        
        # 使用弱引用跟踪对象
        weak_ref = weakref.ref(obj, lambda ref: self._object_finalized(obj_type))
        self.object_tracker.add(weak_ref)
    
    def _object_finalized(self, obj_type: str):
        """对象被垃圾回收时的回调"""
        # 减少可疑计数
        if obj_type in self.leak_suspicious:
            self.leak_suspicious[obj_type] = max(0, self.leak_suspicious[obj_type] - 1)
    
    def check_for_leaks(self) -> List[Dict[str, Any]]:
        """检查内存泄漏"""
        leaks = []
        
        # 获取当前对象统计
        objects = gc.get_objects()
        type_counts = defaultdict(int)
        
        for obj in objects:
            obj_type = type(obj).__name__
            type_counts[obj_type] += 1
        
        # 检查可疑的对象类型
        for obj_type, count in type_counts.items():
            if count > 1000:  # 对象数量过多
                self.leak_suspicious[obj_type] += 1
                
                if self.leak_suspicious[obj_type] > 5:  # 连续多次检测到
                    leak_info = {
                        "object_type": obj_type,
                        "count": count,
                        "suspicious_level": self.leak_suspicious[obj_type],
                        "timestamp": time.time()
                    }
                    leaks.append(leak_info)
        
        self.detection_history.append({
            "timestamp": time.time(),
            "total_objects": len(objects),
            "leaks_found": len(leaks)
        })
        
        return leaks
    
    def get_leak_report(self) -> Dict[str, Any]:
        """获取泄漏报告"""
        return {
            "suspicious_objects": dict(self.leak_suspicious),
            "detection_history": self.detection_history,
            "current_leaks": self.check_for_leaks()
        }

# 使用示例
def main():
    """主函数"""
    # 创建内存监控系统
    monitor = MemoryMonitor()
    profiler = MemoryProfiler()
    pool_manager = MemoryPoolManager()
    gc_optimizer = GarbageCollectionOptimizer()
    leak_detector = MemoryLeakDetector()
    
    # 开始监控
    monitor.start_monitoring(interval=2.0)
    profiler.start_tracemalloc()
    
    print("Memory optimization system started...")
    
    # 模拟内存使用
    objects = []
    for i in range(1000):
        # 分配内存
        obj = bytearray(1024)  # 1KB对象
        objects.append(obj)
        
        # 跟踪对象
        leak_detector.track_object(obj, "bytearray")
        
        # 每100个对象检查一次
        if i % 100 == 0:
            # 获取内存报告
            memory_report = monitor.get_memory_report()
            print(f"Memory usage: {memory_report['current_memory']['used_mb']:.2f} MB")
            
            # 检查泄漏
            leaks = leak_detector.check_for_leaks()
            if leaks:
                print(f"Potential leaks detected: {len(leaks)}")
            
            # 优化垃圾回收
            memory_pressure = memory_report['current_memory']['percent'] / 100
            gc_optimization = gc_optimizer.optimize_gc_thresholds(memory_pressure)
    
    # 释放部分对象
    for i in range(500):
        objects.pop()
    
    # 强制垃圾回收
    gc_result = gc_optimizer.force_garbage_collection()
    print(f"Garbage collection collected {gc_result['objects_collected']} objects")
    
    # 获取最终报告
    final_report = monitor.get_memory_report()
    leak_report = leak_detector.get_leak_report()
    pool_stats = pool_manager.get_all_stats()
    
    print("\nFinal Memory Report:")
    print(f"Memory usage: {final_report['current_memory']['used_mb']:.2f} MB")
    print(f"Memory growth: {final_report['memory_growth']['growth_percent']:.2f}%")
    print(f"Object count: {final_report['object_stats']['current_objects']}")
    
    print("\nPool Statistics:")
    for pool_name, stats in pool_stats.items():
        if pool_name != "overall":
            print(f"{pool_name}: {stats['utilization']:.2%} utilization")
    
    # 停止监控
    monitor.stop_monitoring()
    profiler.stop_tracemalloc()
    
    print("\nMemory optimization system stopped.")

if __name__ == "__main__":
    main()
```

## 3. 实际应用案例

### 3.1 大数据处理内存优化

```python
class BigDataMemoryOptimizer:
    """大数据处理内存优化器"""
    
    def __init__(self):
        self.chunk_size = 10000
        self.memory_limit = 1024 * 1024 * 1024  # 1GB
    
    def process_large_dataset(self, data_generator: Callable, processor: Callable) -> List[Any]:
        """处理大数据集"""
        results = []
        current_chunk = []
        current_memory = 0
        
        for item in data_generator():
            # 检查内存使用
            if current_memory > self.memory_limit or len(current_chunk) >= self.chunk_size:
                # 处理当前块
                chunk_results = processor(current_chunk)
                results.extend(chunk_results)
                
                # 清空当前块
                current_chunk.clear()
                current_memory = 0
                
                # 强制垃圾回收
                gc.collect()
            
            # 添加新项目
            current_chunk.append(item)
            current_memory += sys.getsizeof(item)
        
        # 处理最后一个块
        if current_chunk:
            chunk_results = processor(current_chunk)
            results.extend(chunk_results)
        
        return results
```

### 3.2 缓存内存优化

```python
class CacheMemoryOptimizer:
    """缓存内存优化器"""
    
    def __init__(self, max_size: int = 1000):
        self.max_size = max_size
        self.cache = {}
        self.access_count = defaultdict(int)
        self.size_tracker = 0
    
    def get(self, key: str) -> Any:
        """获取缓存项"""
        if key in self.cache:
            self.access_count[key] += 1
            return self.cache[key]
        return None
    
    def set(self, key: str, value: Any) -> bool:
        """设置缓存项"""
        item_size = sys.getsizeof(value)
        
        # 检查是否需要清理
        while self.size_tracker + item_size > self.max_size and self.cache:
            self._evict_least_used()
        
        # 添加新项
        if self.size_tracker + item_size <= self.max_size:
            self.cache[key] = value
            self.size_tracker += item_size
            self.access_count[key] = 1
            return True
        
        return False
    
    def _evict_least_used(self):
        """驱逐最少使用的项"""
        if not self.cache:
            return
        
        # 找到最少使用的项
        least_used_key = min(self.access_count.keys(), key=lambda k: self.access_count[k])
        
        # 移除项
        item_size = sys.getsizeof(self.cache[least_used_key])
        del self.cache[least_used_key]
        del self.access_count[least_used_key]
        self.size_tracker -= item_size
```

## 4. 总结

### 4.1 技术要点

1. **内存监控**: 实时内存使用监控
2. **内存池化**: 减少内存分配开销
3. **垃圾回收优化**: 调整GC策略
4. **泄漏检测**: 及时发现内存泄漏

### 4.2 最佳实践

1. **定期监控**: 持续监控内存使用
2. **及时释放**: 及时释放不再使用的对象
3. **使用池化**: 对频繁分配的对象使用内存池
4. **优化GC**: 根据应用特点调整GC参数

### 4.3 扩展方向

1. **智能优化**: 基于机器学习的自动优化
2. **分布式内存**: 集群内存管理
3. **内存压缩**: 内存压缩技术
4. **预测优化**: 内存使用预测和预防

---

**相关文档**:

- [算法优化](./07-03-01-算法优化.md)
- [并发优化](./07-03-03-并发优化.md)
- [垃圾回收理论](../02-理论基础/02-03-计算复杂性理论/)
