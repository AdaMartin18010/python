# æ•°æ®ç§‘å­¦åŸºç¡€

## ğŸ“‹ æ¦‚è¿°

æ•°æ®ç§‘å­¦æ˜¯ä¸€é—¨è·¨å­¦ç§‘é¢†åŸŸï¼Œç»“åˆç»Ÿè®¡å­¦ã€è®¡ç®—æœºç§‘å­¦å’Œé¢†åŸŸçŸ¥è¯†ï¼Œé€šè¿‡æ•°æ®æ”¶é›†ã€å¤„ç†ã€åˆ†æå’Œå»ºæ¨¡æ¥å‘ç°æ´å¯Ÿå’Œè§£å†³å¤æ‚é—®é¢˜ã€‚

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### æ•°æ®ç§‘å­¦å®šä¹‰

**å½¢å¼åŒ–å®šä¹‰**ï¼šæ•°æ®ç§‘å­¦æ˜¯ä¸€ä¸ªå››å…ƒç»„ $DS = (D, M, A, I)$ï¼Œå…¶ä¸­ï¼š

- $D = \{d_1, d_2, ..., d_n\}$ æ˜¯æ•°æ®é›†é›†åˆ
- $M = \{m_1, m_2, ..., m_k\}$ æ˜¯æ¨¡å‹é›†åˆ
- $A = \{a_1, a_2, ..., a_l\}$ æ˜¯ç®—æ³•é›†åˆ
- $I = \{i_1, i_2, ..., i_p\}$ æ˜¯æ´å¯Ÿé›†åˆ

### æ•°æ®ç§‘å­¦æµç¨‹

**CRISP-DMæ¨¡å‹**ï¼š

1. **ä¸šåŠ¡ç†è§£**ï¼š$BU = f(Domain, Objectives, Constraints)$
2. **æ•°æ®ç†è§£**ï¼š$DU = f(DataSources, DataQuality, DataStructure)$
3. **æ•°æ®å‡†å¤‡**ï¼š$DP = f(Cleaning, Transformation, Integration)$
4. **å»ºæ¨¡**ï¼š$M = f(Algorithm, Parameters, Validation)$
5. **è¯„ä¼°**ï¼š$E = f(Performance, BusinessValue, Deployment)$
6. **éƒ¨ç½²**ï¼š$D = f(Integration, Monitoring, Maintenance)$

## ğŸ”§ Pythonå®ç°

### æ•°æ®ç§‘å­¦åŸºç¡€æ¡†æ¶

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import logging
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# æ•°æ®ç±»å‹
class DataType(Enum):
    NUMERICAL = "numerical"
    CATEGORICAL = "categorical"
    TEXT = "text"
    DATETIME = "datetime"
    BOOLEAN = "boolean"

# æ•°æ®è´¨é‡æŒ‡æ ‡
class DataQualityMetric(Enum):
    COMPLETENESS = "completeness"
    ACCURACY = "accuracy"
    CONSISTENCY = "consistency"
    TIMELINESS = "timeliness"
    VALIDITY = "validity"

# æ•°æ®ç§‘å­¦é¡¹ç›®
@dataclass
class DataScienceProject:
    name: str
    description: str
    objectives: List[str]
    data_sources: List[str]
    created_at: datetime
    status: str = "planning"
    metadata: Dict[str, Any] = field(default_factory=dict)

# æ•°æ®é›†
@dataclass
class Dataset:
    name: str
    data: pd.DataFrame
    description: str
    source: str
    created_at: datetime
    schema: Dict[str, DataType] = field(default_factory=dict)
    quality_metrics: Dict[str, float] = field(default_factory=dict)

# æ•°æ®ç§‘å­¦å·¥ä½œæµ
class DataScienceWorkflow:
    """æ•°æ®ç§‘å­¦å·¥ä½œæµ"""
    
    def __init__(self, project: DataScienceProject):
        self.project = project
        self.datasets: Dict[str, Dataset] = {}
        self.models: Dict[str, Any] = {}
        self.results: Dict[str, Any] = {}
        self.logger = logging.getLogger(f"ds_workflow.{project.name}")
        
    def add_dataset(self, dataset: Dataset) -> None:
        """æ·»åŠ æ•°æ®é›†"""
        self.datasets[dataset.name] = dataset
        self.logger.info(f"Dataset added: {dataset.name}")
        
    def get_dataset(self, name: str) -> Optional[Dataset]:
        """è·å–æ•°æ®é›†"""
        return self.datasets.get(name)
        
    def list_datasets(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰æ•°æ®é›†"""
        return list(self.datasets.keys())
        
    def save_model(self, name: str, model: Any) -> None:
        """ä¿å­˜æ¨¡å‹"""
        self.models[name] = model
        self.logger.info(f"Model saved: {name}")
        
    def get_model(self, name: str) -> Optional[Any]:
        """è·å–æ¨¡å‹"""
        return self.models.get(name)
        
    def save_result(self, name: str, result: Any) -> None:
        """ä¿å­˜ç»“æœ"""
        self.results[name] = result
        self.logger.info(f"Result saved: {name}")
        
    def get_result(self, name: str) -> Optional[Any]:
        """è·å–ç»“æœ"""
        return self.results.get(name)
```

### æ•°æ®æ¢ç´¢æ€§åˆ†æ

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from typing import Dict, List, Any, Optional, Tuple

class ExploratoryDataAnalysis:
    """æ¢ç´¢æ€§æ•°æ®åˆ†æ"""
    
    def __init__(self, dataset: Dataset):
        self.dataset = dataset
        self.data = dataset.data
        self.logger = logging.getLogger("eda")
        
    def basic_info(self) -> Dict[str, Any]:
        """åŸºæœ¬ä¿¡æ¯"""
        info = {
            "shape": self.data.shape,
            "columns": list(self.data.columns),
            "dtypes": self.data.dtypes.to_dict(),
            "memory_usage": self.data.memory_usage(deep=True).sum(),
            "missing_values": self.data.isnull().sum().to_dict()
        }
        
        return info
        
    def numerical_summary(self) -> pd.DataFrame:
        """æ•°å€¼å‹æ•°æ®æ‘˜è¦"""
        numerical_cols = self.data.select_dtypes(include=[np.number]).columns
        if len(numerical_cols) == 0:
            return pd.DataFrame()
            
        summary = self.data[numerical_cols].describe()
        
        # æ·»åŠ ååº¦å’Œå³°åº¦
        skewness = self.data[numerical_cols].skew()
        kurtosis = self.data[numerical_cols].kurtosis()
        
        summary.loc['skewness'] = skewness
        summary.loc['kurtosis'] = kurtosis
        
        return summary
        
    def categorical_summary(self) -> Dict[str, pd.DataFrame]:
        """åˆ†ç±»å‹æ•°æ®æ‘˜è¦"""
        categorical_cols = self.data.select_dtypes(include=['object', 'category']).columns
        summary = {}
        
        for col in categorical_cols:
            value_counts = self.data[col].value_counts()
            summary[col] = pd.DataFrame({
                'count': value_counts,
                'percentage': (value_counts / len(self.data) * 100).round(2)
            })
            
        return summary
        
    def correlation_analysis(self) -> pd.DataFrame:
        """ç›¸å…³æ€§åˆ†æ"""
        numerical_cols = self.data.select_dtypes(include=[np.number]).columns
        if len(numerical_cols) < 2:
            return pd.DataFrame()
            
        correlation_matrix = self.data[numerical_cols].corr()
        return correlation_matrix
        
    def missing_value_analysis(self) -> Dict[str, Any]:
        """ç¼ºå¤±å€¼åˆ†æ"""
        missing_data = self.data.isnull().sum()
        missing_percentage = (missing_data / len(self.data) * 100).round(2)
        
        missing_summary = pd.DataFrame({
            'missing_count': missing_data,
            'missing_percentage': missing_percentage
        }).sort_values('missing_percentage', ascending=False)
        
        # ç¼ºå¤±å€¼æ¨¡å¼åˆ†æ
        missing_patterns = self._analyze_missing_patterns()
        
        return {
            'summary': missing_summary,
            'patterns': missing_patterns
        }
        
    def _analyze_missing_patterns(self) -> Dict[str, Any]:
        """åˆ†æç¼ºå¤±å€¼æ¨¡å¼"""
        missing_matrix = self.data.isnull()
        
        # è®¡ç®—ç¼ºå¤±å€¼ç»„åˆ
        missing_combinations = missing_matrix.sum(axis=1).value_counts().sort_index()
        
        # æ‰¾å‡ºå®Œå…¨ç¼ºå¤±çš„è¡Œ
        completely_missing = missing_matrix.all(axis=1).sum()
        
        return {
            'missing_combinations': missing_combinations,
            'completely_missing_rows': completely_missing
        }
        
    def outlier_analysis(self, method: str = 'iqr') -> Dict[str, List[int]]:
        """å¼‚å¸¸å€¼åˆ†æ"""
        numerical_cols = self.data.select_dtypes(include=[np.number]).columns
        outliers = {}
        
        for col in numerical_cols:
            if method == 'iqr':
                outliers[col] = self._detect_outliers_iqr(col)
            elif method == 'zscore':
                outliers[col] = self._detect_outliers_zscore(col)
                
        return outliers
        
    def _detect_outliers_iqr(self, column: str) -> List[int]:
        """ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼"""
        Q1 = self.data[column].quantile(0.25)
        Q3 = self.data[column].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = self.data[
            (self.data[column] < lower_bound) | 
            (self.data[column] > upper_bound)
        ].index.tolist()
        
        return outliers
        
    def _detect_outliers_zscore(self, column: str, threshold: float = 3.0) -> List[int]:
        """ä½¿ç”¨Z-scoreæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼"""
        z_scores = np.abs(stats.zscore(self.data[column].dropna()))
        outliers = self.data[column].dropna()[z_scores > threshold].index.tolist()
        
        return outliers
        
    def distribution_analysis(self) -> Dict[str, Dict[str, Any]]:
        """åˆ†å¸ƒåˆ†æ"""
        numerical_cols = self.data.select_dtypes(include=[np.number]).columns
        distributions = {}
        
        for col in numerical_cols:
            data = self.data[col].dropna()
            
            # æ­£æ€æ€§æ£€éªŒ
            shapiro_stat, shapiro_p = stats.shapiro(data)
            
            # ååº¦å’Œå³°åº¦
            skewness = stats.skew(data)
            kurtosis = stats.kurtosis(data)
            
            distributions[col] = {
                'shapiro_statistic': shapiro_stat,
                'shapiro_pvalue': shapiro_p,
                'is_normal': shapiro_p > 0.05,
                'skewness': skewness,
                'kurtosis': kurtosis
            }
            
        return distributions
        
    def generate_report(self) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = []
        report.append("# æ¢ç´¢æ€§æ•°æ®åˆ†ææŠ¥å‘Š")
        report.append(f"## æ•°æ®é›†: {self.dataset.name}")
        report.append(f"## åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # åŸºæœ¬ä¿¡æ¯
        info = self.basic_info()
        report.append("\n## åŸºæœ¬ä¿¡æ¯")
        report.append(f"- æ•°æ®å½¢çŠ¶: {info['shape']}")
        report.append(f"- åˆ—æ•°: {len(info['columns'])}")
        report.append(f"- å†…å­˜ä½¿ç”¨: {info['memory_usage'] / 1024 / 1024:.2f} MB")
        
        # ç¼ºå¤±å€¼ä¿¡æ¯
        missing_summary = self.missing_value_analysis()['summary']
        if not missing_summary.empty:
            report.append("\n## ç¼ºå¤±å€¼åˆ†æ")
            report.append("| åˆ—å | ç¼ºå¤±æ•°é‡ | ç¼ºå¤±æ¯”ä¾‹(%) |")
            report.append("|------|----------|-------------|")
            for col, row in missing_summary.iterrows():
                report.append(f"| {col} | {row['missing_count']} | {row['missing_percentage']} |")
                
        # æ•°å€¼å‹æ•°æ®æ‘˜è¦
        numerical_summary = self.numerical_summary()
        if not numerical_summary.empty:
            report.append("\n## æ•°å€¼å‹æ•°æ®æ‘˜è¦")
            report.append(numerical_summary.to_string())
            
        # å¼‚å¸¸å€¼åˆ†æ
        outliers = self.outlier_analysis()
        if outliers:
            report.append("\n## å¼‚å¸¸å€¼åˆ†æ")
            for col, outlier_indices in outliers.items():
                report.append(f"- {col}: {len(outlier_indices)} ä¸ªå¼‚å¸¸å€¼")
                
        return "\n".join(report)
```

### æ•°æ®é¢„å¤„ç†

```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.feature_selection import SelectKBest, f_classif, f_regression
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple

class DataPreprocessor:
    """æ•°æ®é¢„å¤„ç†å™¨"""
    
    def __init__(self):
        self.scalers: Dict[str, Any] = {}
        self.encoders: Dict[str, Any] = {}
        self.imputers: Dict[str, Any] = {}
        self.feature_selectors: Dict[str, Any] = {}
        self.logger = logging.getLogger("data_preprocessor")
        
    def detect_data_types(self, data: pd.DataFrame) -> Dict[str, DataType]:
        """æ£€æµ‹æ•°æ®ç±»å‹"""
        data_types = {}
        
        for column in data.columns:
            if data[column].dtype in ['int64', 'float64']:
                data_types[column] = DataType.NUMERICAL
            elif data[column].dtype == 'bool':
                data_types[column] = DataType.BOOLEAN
            elif data[column].dtype == 'datetime64[ns]':
                data_types[column] = DataType.DATETIME
            elif data[column].dtype == 'object':
                # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æœ¬
                if data[column].str.len().mean() > 50:
                    data_types[column] = DataType.TEXT
                else:
                    data_types[column] = DataType.CATEGORICAL
            else:
                data_types[column] = DataType.CATEGORICAL
                
        return data_types
        
    def handle_missing_values(self, data: pd.DataFrame, strategy: str = 'auto') -> pd.DataFrame:
        """å¤„ç†ç¼ºå¤±å€¼"""
        data_copy = data.copy()
        
        for column in data_copy.columns:
            if data_copy[column].isnull().sum() > 0:
                if strategy == 'auto':
                    # è‡ªåŠ¨é€‰æ‹©ç­–ç•¥
                    if data_copy[column].dtype in ['int64', 'float64']:
                        imputer = SimpleImputer(strategy='mean')
                    else:
                        imputer = SimpleImputer(strategy='most_frequent')
                elif strategy == 'mean':
                    imputer = SimpleImputer(strategy='mean')
                elif strategy == 'median':
                    imputer = SimpleImputer(strategy='median')
                elif strategy == 'most_frequent':
                    imputer = SimpleImputer(strategy='most_frequent')
                elif strategy == 'knn':
                    imputer = KNNImputer(n_neighbors=5)
                else:
                    continue
                    
                # æ‹Ÿåˆå’Œè½¬æ¢
                data_copy[column] = imputer.fit_transform(data_copy[[column]])
                self.imputers[column] = imputer
                
        return data_copy
        
    def scale_numerical_features(self, data: pd.DataFrame, method: str = 'standard') -> pd.DataFrame:
        """ç¼©æ”¾æ•°å€¼ç‰¹å¾"""
        numerical_cols = data.select_dtypes(include=[np.number]).columns
        data_copy = data.copy()
        
        for col in numerical_cols:
            if method == 'standard':
                scaler = StandardScaler()
            elif method == 'minmax':
                scaler = MinMaxScaler()
            else:
                continue
                
            # æ‹Ÿåˆå’Œè½¬æ¢
            data_copy[col] = scaler.fit_transform(data_copy[[col]])
            self.scalers[col] = scaler
            
        return data_copy
        
    def encode_categorical_features(self, data: pd.DataFrame, method: str = 'label') -> pd.DataFrame:
        """ç¼–ç åˆ†ç±»ç‰¹å¾"""
        categorical_cols = data.select_dtypes(include=['object', 'category']).columns
        data_copy = data.copy()
        
        for col in categorical_cols:
            if method == 'label':
                encoder = LabelEncoder()
                data_copy[col] = encoder.fit_transform(data_copy[col].astype(str))
                self.encoders[col] = encoder
            elif method == 'onehot':
                encoder = OneHotEncoder(sparse=False, drop='first')
                encoded_data = encoder.fit_transform(data_copy[[col]])
                encoded_df = pd.DataFrame(
                    encoded_data,
                    columns=[f"{col}_{cat}" for cat in encoder.categories_[0][1:]]
                )
                data_copy = pd.concat([data_copy.drop(col, axis=1), encoded_df], axis=1)
                self.encoders[col] = encoder
                
        return data_copy
        
    def feature_selection(self, data: pd.DataFrame, target: str, method: str = 'kbest', k: int = 10) -> pd.DataFrame:
        """ç‰¹å¾é€‰æ‹©"""
        if method == 'kbest':
            # ç¡®å®šè¯„åˆ†å‡½æ•°
            if data[target].dtype in ['int64', 'float64']:
                score_func = f_regression
            else:
                score_func = f_classif
                
            selector = SelectKBest(score_func=score_func, k=k)
            
            # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
            X = data.drop(target, axis=1)
            y = data[target]
            
            # åªé€‰æ‹©æ•°å€¼å‹ç‰¹å¾
            numerical_cols = X.select_dtypes(include=[np.number]).columns
            X_numerical = X[numerical_cols]
            
            # æ‹Ÿåˆå’Œè½¬æ¢
            X_selected = selector.fit_transform(X_numerical, y)
            
            # è·å–é€‰ä¸­çš„ç‰¹å¾
            selected_features = numerical_cols[selector.get_support()]
            
            # åˆ›å»ºæ–°çš„æ•°æ®æ¡†
            selected_data = data[list(selected_features) + [target]]
            self.feature_selectors['kbest'] = selector
            
            return selected_data
            
        return data
        
    def remove_outliers(self, data: pd.DataFrame, method: str = 'iqr') -> pd.DataFrame:
        """ç§»é™¤å¼‚å¸¸å€¼"""
        numerical_cols = data.select_dtypes(include=[np.number]).columns
        data_copy = data.copy()
        
        for col in numerical_cols:
            if method == 'iqr':
                Q1 = data_copy[col].quantile(0.25)
                Q3 = data_copy[col].quantile(0.75)
                IQR = Q3 - Q1
                
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                data_copy = data_copy[
                    (data_copy[col] >= lower_bound) & 
                    (data_copy[col] <= upper_bound)
                ]
                
        return data_copy
        
    def create_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºæ–°ç‰¹å¾"""
        data_copy = data.copy()
        
        # æ•°å€¼å‹ç‰¹å¾äº¤äº’
        numerical_cols = data_copy.select_dtypes(include=[np.number]).columns
        if len(numerical_cols) >= 2:
            for i, col1 in enumerate(numerical_cols):
                for col2 in numerical_cols[i+1:]:
                    # ä¹˜ç§¯ç‰¹å¾
                    data_copy[f'{col1}_times_{col2}'] = data_copy[col1] * data_copy[col2]
                    # æ¯”ç‡ç‰¹å¾
                    if data_copy[col2].min() > 0:
                        data_copy[f'{col1}_div_{col2}'] = data_copy[col1] / data_copy[col2]
                        
        # å¤šé¡¹å¼ç‰¹å¾
        for col in numerical_cols[:3]:  # é™åˆ¶æ•°é‡é¿å…ç»´åº¦çˆ†ç‚¸
            data_copy[f'{col}_squared'] = data_copy[col] ** 2
            data_copy[f'{col}_cubed'] = data_copy[col] ** 3
            
        return data_copy
        
    def preprocess_pipeline(self, data: pd.DataFrame, target: str = None, 
                          steps: List[str] = None) -> pd.DataFrame:
        """é¢„å¤„ç†æµæ°´çº¿"""
        if steps is None:
            steps = ['missing_values', 'outliers', 'scaling', 'encoding', 'feature_selection']
            
        data_copy = data.copy()
        
        for step in steps:
            if step == 'missing_values':
                data_copy = self.handle_missing_values(data_copy)
            elif step == 'outliers':
                data_copy = self.remove_outliers(data_copy)
            elif step == 'scaling':
                data_copy = self.scale_numerical_features(data_copy)
            elif step == 'encoding':
                data_copy = self.encode_categorical_features(data_copy)
            elif step == 'feature_selection' and target:
                data_copy = self.feature_selection(data_copy, target)
            elif step == 'feature_creation':
                data_copy = self.create_features(data_copy)
                
        return data_copy
```

### ç»Ÿè®¡å»ºæ¨¡

```python
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.svm import SVR, SVC
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple

class StatisticalModeling:
    """ç»Ÿè®¡å»ºæ¨¡"""
    
    def __init__(self):
        self.models: Dict[str, Any] = {}
        self.results: Dict[str, Dict[str, Any]] = {}
        self.logger = logging.getLogger("statistical_modeling")
        
    def train_linear_regression(self, X: pd.DataFrame, y: pd.Series, 
                              model_name: str = 'linear_regression') -> Dict[str, Any]:
        """è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹"""
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # è®­ç»ƒæ¨¡å‹
        model = LinearRegression()
        model.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)
        
        # è¯„ä¼°
        train_mse = mean_squared_error(y_train, y_pred_train)
        test_mse = mean_squared_error(y_test, y_pred_test)
        train_r2 = r2_score(y_train, y_pred_train)
        test_r2 = r2_score(y_test, y_pred_test)
        
        # äº¤å‰éªŒè¯
        cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')
        
        # ä¿å­˜ç»“æœ
        results = {
            'model': model,
            'train_mse': train_mse,
            'test_mse': test_mse,
            'train_r2': train_r2,
            'test_r2': test_r2,
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'coefficients': dict(zip(X.columns, model.coef_)),
            'intercept': model.intercept_
        }
        
        self.models[model_name] = model
        self.results[model_name] = results
        
        return results
        
    def train_logistic_regression(self, X: pd.DataFrame, y: pd.Series,
                                model_name: str = 'logistic_regression') -> Dict[str, Any]:
        """è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹"""
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # è®­ç»ƒæ¨¡å‹
        model = LogisticRegression(random_state=42)
        model.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)
        
        # è¯„ä¼°
        train_accuracy = accuracy_score(y_train, y_pred_train)
        test_accuracy = accuracy_score(y_test, y_pred_test)
        
        # äº¤å‰éªŒè¯
        cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
        
        # åˆ†ç±»æŠ¥å‘Š
        classification_rep = classification_report(y_test, y_pred_test, output_dict=True)
        
        # ä¿å­˜ç»“æœ
        results = {
            'model': model,
            'train_accuracy': train_accuracy,
            'test_accuracy': test_accuracy,
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'classification_report': classification_rep,
            'coefficients': dict(zip(X.columns, model.coef_[0])),
            'intercept': model.intercept_[0]
        }
        
        self.models[model_name] = model
        self.results[model_name] = results
        
        return results
        
    def train_random_forest(self, X: pd.DataFrame, y: pd.Series, 
                          model_type: str = 'regression',
                          model_name: str = 'random_forest') -> Dict[str, Any]:
        """è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹"""
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # é€‰æ‹©æ¨¡å‹ç±»å‹
        if model_type == 'regression':
            model = RandomForestRegressor(n_estimators=100, random_state=42)
            scoring = 'r2'
        else:
            model = RandomForestClassifier(n_estimators=100, random_state=42)
            scoring = 'accuracy'
            
        # è®­ç»ƒæ¨¡å‹
        model.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)
        
        # è¯„ä¼°
        if model_type == 'regression':
            train_score = r2_score(y_train, y_pred_train)
            test_score = r2_score(y_test, y_pred_test)
        else:
            train_score = accuracy_score(y_train, y_pred_train)
            test_score = accuracy_score(y_test, y_pred_test)
            
        # äº¤å‰éªŒè¯
        cv_scores = cross_val_score(model, X, y, cv=5, scoring=scoring)
        
        # ç‰¹å¾é‡è¦æ€§
        feature_importance = dict(zip(X.columns, model.feature_importances_))
        
        # ä¿å­˜ç»“æœ
        results = {
            'model': model,
            'train_score': train_score,
            'test_score': test_score,
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'feature_importance': feature_importance
        }
        
        if model_type == 'classification':
            results['classification_report'] = classification_report(y_test, y_pred_test, output_dict=True)
            
        self.models[model_name] = model
        self.results[model_name] = results
        
        return results
        
    def hyperparameter_tuning(self, X: pd.DataFrame, y: pd.Series, 
                            model_type: str = 'regression',
                            model_name: str = 'tuned_model') -> Dict[str, Any]:
        """è¶…å‚æ•°è°ƒä¼˜"""
        # å®šä¹‰å‚æ•°ç½‘æ ¼
        if model_type == 'regression':
            model = RandomForestRegressor(random_state=42)
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [10, 20, None],
                'min_samples_split': [2, 5, 10],
                'min_samples_leaf': [1, 2, 4]
            }
            scoring = 'r2'
        else:
            model = RandomForestClassifier(random_state=42)
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [10, 20, None],
                'min_samples_split': [2, 5, 10],
                'min_samples_leaf': [1, 2, 4]
            }
            scoring = 'accuracy'
            
        # ç½‘æ ¼æœç´¢
        grid_search = GridSearchCV(
            estimator=model,
            param_grid=param_grid,
            cv=5,
            scoring=scoring,
            n_jobs=-1,
            verbose=1
        )
        
        grid_search.fit(X, y)
        
        # è·å–æœ€ä½³æ¨¡å‹
        best_model = grid_search.best_estimator_
        best_params = grid_search.best_params_
        best_score = grid_search.best_score_
        
        # ä¿å­˜ç»“æœ
        results = {
            'model': best_model,
            'best_params': best_params,
            'best_cv_score': best_score,
            'cv_results': grid_search.cv_results_
        }
        
        self.models[model_name] = best_model
        self.results[model_name] = results
        
        return results
        
    def model_comparison(self, X: pd.DataFrame, y: pd.Series) -> pd.DataFrame:
        """æ¨¡å‹æ¯”è¾ƒ"""
        models = {
            'Linear Regression': LinearRegression(),
            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
            'SVR': SVR()
        }
        
        results = []
        
        for name, model in models.items():
            # äº¤å‰éªŒè¯
            cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')
            
            results.append({
                'Model': name,
                'CV Mean': cv_scores.mean(),
                'CV Std': cv_scores.std(),
                'CV Min': cv_scores.min(),
                'CV Max': cv_scores.max()
            })
            
        return pd.DataFrame(results)
        
    def generate_model_report(self, model_name: str) -> str:
        """ç”Ÿæˆæ¨¡å‹æŠ¥å‘Š"""
        if model_name not in self.results:
            return f"Model {model_name} not found"
            
        result = self.results[model_name]
        report = []
        
        report.append(f"# æ¨¡å‹æŠ¥å‘Š: {model_name}")
        report.append(f"## æ¨¡å‹ç±»å‹: {type(result['model']).__name__}")
        
        if 'train_score' in result:
            report.append(f"## è®­ç»ƒåˆ†æ•°: {result['train_score']:.4f}")
            report.append(f"## æµ‹è¯•åˆ†æ•°: {result['test_score']:.4f}")
            
        if 'cv_mean' in result:
            report.append(f"## äº¤å‰éªŒè¯å¹³å‡åˆ†æ•°: {result['cv_mean']:.4f}")
            report.append(f"## äº¤å‰éªŒè¯æ ‡å‡†å·®: {result['cv_std']:.4f}")
            
        if 'best_params' in result:
            report.append("## æœ€ä½³å‚æ•°:")
            for param, value in result['best_params'].items():
                report.append(f"- {param}: {value}")
                
        if 'feature_importance' in result:
            report.append("## ç‰¹å¾é‡è¦æ€§:")
            sorted_features = sorted(result['feature_importance'].items(), 
                                   key=lambda x: x[1], reverse=True)
            for feature, importance in sorted_features[:10]:
                report.append(f"- {feature}: {importance:.4f}")
                
        return "\n".join(report)
```

## ğŸ“Š æ€§èƒ½åˆ†æ

### æ¨¡å‹è¯„ä¼°æŒ‡æ ‡

**å›å½’æ¨¡å‹**ï¼š

- **å‡æ–¹è¯¯å·®**ï¼š$MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$
- **å†³å®šç³»æ•°**ï¼š$R^2 = 1 - \frac{SS_{res}}{SS_{tot}}$

**åˆ†ç±»æ¨¡å‹**ï¼š

- **å‡†ç¡®ç‡**ï¼š$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$
- **ç²¾ç¡®ç‡**ï¼š$Precision = \frac{TP}{TP + FP}$
- **å¬å›ç‡**ï¼š$Recall = \frac{TP}{TP + FN}$

### æ•°æ®è´¨é‡æŒ‡æ ‡

**å®Œæ•´æ€§**ï¼š$Completeness = \frac{NonMissingValues}{TotalValues}$

**ä¸€è‡´æ€§**ï¼š$Consistency = \frac{ConsistentRecords}{TotalRecords}$

## ğŸ›¡ï¸ æœ€ä½³å®è·µ

### 1. æ•°æ®ç§‘å­¦æµç¨‹

- **é—®é¢˜å®šä¹‰**ï¼šæ˜ç¡®å®šä¹‰ä¸šåŠ¡é—®é¢˜å’Œç›®æ ‡
- **æ•°æ®æ”¶é›†**ï¼šæ”¶é›†ç›¸å…³å’Œé«˜è´¨é‡çš„æ•°æ®
- **æ•°æ®æ¢ç´¢**ï¼šæ·±å…¥ç†è§£æ•°æ®ç‰¹å¾å’Œåˆ†å¸ƒ
- **ç‰¹å¾å·¥ç¨‹**ï¼šåˆ›å»ºæœ‰æ„ä¹‰çš„ç‰¹å¾
- **æ¨¡å‹é€‰æ‹©**ï¼šé€‰æ‹©åˆé€‚çš„ç®—æ³•å’Œæ¨¡å‹
- **æ¨¡å‹è¯„ä¼°**ï¼šä½¿ç”¨å¤šç§æŒ‡æ ‡è¯„ä¼°æ¨¡å‹
- **æ¨¡å‹éƒ¨ç½²**ï¼šå°†æ¨¡å‹é›†æˆåˆ°ç”Ÿäº§ç¯å¢ƒ

### 2. æ•°æ®è´¨é‡ä¿è¯

```python
class DataQualityChecker:
    """æ•°æ®è´¨é‡æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.quality_metrics = {}
        
    def check_completeness(self, data: pd.DataFrame) -> float:
        """æ£€æŸ¥å®Œæ•´æ€§"""
        total_values = data.size
        missing_values = data.isnull().sum().sum()
        completeness = (total_values - missing_values) / total_values
        return completeness
        
    def check_consistency(self, data: pd.DataFrame) -> float:
        """æ£€æŸ¥ä¸€è‡´æ€§"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æ ¹æ®ä¸šåŠ¡è§„åˆ™æ£€æŸ¥
        return 1.0
        
    def check_accuracy(self, data: pd.DataFrame, reference_data: pd.DataFrame) -> float:
        """æ£€æŸ¥å‡†ç¡®æ€§"""
        # ä¸å‚è€ƒæ•°æ®æ¯”è¾ƒ
        common_columns = set(data.columns) & set(reference_data.columns)
        if not common_columns:
            return 0.0
            
        accuracy_scores = []
        for col in common_columns:
            if data[col].dtype == reference_data[col].dtype:
                # ç®€å•çš„å‡†ç¡®æ€§æ£€æŸ¥
                accuracy = (data[col] == reference_data[col]).mean()
                accuracy_scores.append(accuracy)
                
        return np.mean(accuracy_scores) if accuracy_scores else 0.0
        
    def generate_quality_report(self, data: pd.DataFrame) -> Dict[str, float]:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        report = {
            'completeness': self.check_completeness(data),
            'consistency': self.check_consistency(data)
        }
        
        return report
```

### 3. æ¨¡å‹ç›‘æ§

```python
class ModelMonitor:
    """æ¨¡å‹ç›‘æ§å™¨"""
    
    def __init__(self):
        self.performance_history = []
        
    def record_performance(self, model_name: str, metrics: Dict[str, float]) -> None:
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        record = {
            'timestamp': datetime.now(),
            'model_name': model_name,
            **metrics
        }
        self.performance_history.append(record)
        
    def detect_drift(self, current_metrics: Dict[str, float], 
                    window_size: int = 10) -> Dict[str, bool]:
        """æ£€æµ‹æ¨¡å‹æ¼‚ç§»"""
        if len(self.performance_history) < window_size:
            return {}
            
        recent_history = self.performance_history[-window_size:]
        drift_detected = {}
        
        for metric, current_value in current_metrics.items():
            historical_values = [record[metric] for record in recent_history 
                               if metric in record]
            
            if historical_values:
                mean_value = np.mean(historical_values)
                std_value = np.std(historical_values)
                
                # æ£€æµ‹å¼‚å¸¸å€¼
                z_score = abs(current_value - mean_value) / std_value
                drift_detected[metric] = z_score > 2.0
                
        return drift_detected
```

## ğŸ”— ç›¸å…³é“¾æ¥

- [04-è¡Œä¸šé¢†åŸŸ/04-01-Webå¼€å‘/04-01-01-Webæ¶æ„åŸºç¡€.md](../04-01-Webå¼€å‘/04-01-01-Webæ¶æ„åŸºç¡€.md) - Webæ¶æ„åŸºç¡€
- [04-è¡Œä¸šé¢†åŸŸ/04-02-IoTå¼€å‘/04-02-01-IoTåŸºç¡€.md](../04-02-IoTå¼€å‘/04-02-01-IoTåŸºç¡€.md) - IoTå¼€å‘åŸºç¡€
- [02-ç†è®ºåŸºç¡€/02-01-ç®—æ³•ç†è®º/02-01-01-ç®—æ³•åŸºç¡€.md](../../02-ç†è®ºåŸºç¡€/02-01-ç®—æ³•ç†è®º/02-01-01-ç®—æ³•åŸºç¡€.md) - ç®—æ³•ç†è®ºåŸºç¡€

---

*æœ¬æ–‡æ¡£æä¾›äº†æ•°æ®ç§‘å­¦çš„å®Œæ•´ç†è®ºåŸºç¡€å’ŒPythonå®ç°ï¼ŒåŒ…æ‹¬æ•°æ®æ¢ç´¢ã€é¢„å¤„ç†ã€å»ºæ¨¡ç­‰æ ¸å¿ƒç»„ä»¶ã€‚*
