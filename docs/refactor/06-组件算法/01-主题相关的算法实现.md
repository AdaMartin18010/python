# 01-主题相关的算法实现

**文件路径**: `docs/refactor/06-组件算法/01-主题相关的算法实现.md`  
**树形编号**: 06-01-01  
**相关文件**: 
- [05-架构领域/01-主题驱动的系统架构](../05-架构领域/01-主题驱动的系统架构.md)
- [02-形式科学/01-主题的集合论基础](../02-形式科学/01-主题的集合论基础.md)
- [03-理论基础/01-主题在计算理论中的角色](../03-理论基础/01-主题在计算理论中的角色.md)

---

## 1. 主题聚类算法

### 1.1 主题相似度计算

#### 数学定义

**定义 1.1** (主题相似度)
主题 $t_1$ 和 $t_2$ 的相似度函数 $sim: T \times T \rightarrow [0,1]$ 定义为：

$$sim(t_1, t_2) = \frac{|t_1.content \cap t_2.content|}{|t_1.content \cup t_2.content|}$$

**定义 1.2** (主题距离)
主题距离函数 $dist: T \times T \rightarrow \mathbb{R}^+$ 定义为：

$$dist(t_1, t_2) = 1 - sim(t_1, t_2)$$

#### Python实现

```python
from typing import Set, List, Dict, Tuple, Optional
from dataclasses import dataclass
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import seaborn as sns

@dataclass
class Topic:
    """主题定义"""
    id: str
    name: str
    content: Set[str]
    keywords: List[str]
    weight: float = 1.0
    
    def __init__(self, name: str, content: Set[str], keywords: List[str]):
        self.id = str(uuid.uuid4())
        self.name = name
        self.content = content
        self.keywords = keywords

class TopicSimilarityCalculator:
    """主题相似度计算器"""
    
    def __init__(self, method: str = 'jaccard'):
        self.method = method
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        
    def jaccard_similarity(self, topic1: Topic, topic2: Topic) -> float:
        """Jaccard相似度"""
        intersection = len(topic1.content.intersection(topic2.content))
        union = len(topic1.content.union(topic2.content))
        return intersection / union if union > 0 else 0.0
        
    def cosine_similarity(self, topic1: Topic, topic2: Topic) -> float:
        """余弦相似度"""
        # 合并关键词
        all_keywords = list(set(topic1.keywords + topic2.keywords))
        
        # 创建向量
        vec1 = [topic1.keywords.count(kw) for kw in all_keywords]
        vec2 = [topic2.keywords.count(kw) for kw in all_keywords]
        
        # 计算余弦相似度
        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        norm1 = sum(a * a for a in vec1) ** 0.5
        norm2 = sum(b * b for b in vec2) ** 0.5
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
            
        return dot_product / (norm1 * norm2)
        
    def tfidf_similarity(self, topics: List[Topic]) -> np.ndarray:
        """TF-IDF相似度矩阵"""
        # 准备文档
        documents = [' '.join(topic.keywords) for topic in topics]
        
        # 计算TF-IDF
        tfidf_matrix = self.vectorizer.fit_transform(documents)
        
        # 计算相似度矩阵
        similarity_matrix = cosine_similarity(tfidf_matrix)
        
        return similarity_matrix
        
    def calculate_similarity(self, topic1: Topic, topic2: Topic) -> float:
        """计算主题相似度"""
        if self.method == 'jaccard':
            return self.jaccard_similarity(topic1, topic2)
        elif self.method == 'cosine':
            return self.cosine_similarity(topic1, topic2)
        else:
            raise ValueError(f"不支持的相似度方法: {self.method}")

# 示例：主题相似度计算
def demonstrate_topic_similarity():
    """演示主题相似度计算"""
    # 创建主题
    topics = [
        Topic("机器学习", {"算法", "模型", "训练", "预测"}, ["机器学习", "算法", "模型", "训练", "预测"]),
        Topic("深度学习", {"神经网络", "模型", "训练", "优化"}, ["深度学习", "神经网络", "模型", "训练", "优化"]),
        Topic("数据科学", {"数据分析", "统计", "可视化", "挖掘"}, ["数据科学", "数据分析", "统计", "可视化", "挖掘"]),
        Topic("自然语言处理", {"文本", "语言", "模型", "理解"}, ["自然语言处理", "文本", "语言", "模型", "理解"])
    ]
    
    # 计算相似度
    calculator = TopicSimilarityCalculator(method='jaccard')
    
    print("主题相似度矩阵 (Jaccard):")
    for i, topic1 in enumerate(topics):
        for j, topic2 in enumerate(topics):
            similarity = calculator.calculate_similarity(topic1, topic2)
            print(f"{topic1.name} - {topic2.name}: {similarity:.3f}")
    
    # 计算TF-IDF相似度矩阵
    tfidf_calculator = TopicSimilarityCalculator(method='tfidf')
    similarity_matrix = tfidf_calculator.tfidf_similarity(topics)
    
    print("\nTF-IDF相似度矩阵:")
    print(similarity_matrix)
    
    # 可视化相似度矩阵
    plt.figure(figsize=(10, 8))
    sns.heatmap(similarity_matrix, 
                xticklabels=[t.name for t in topics],
                yticklabels=[t.name for t in topics],
                annot=True, cmap='viridis')
    plt.title('主题相似度矩阵')
    plt.tight_layout()
    plt.show()
```

### 1.2 主题聚类算法

#### 数学定义

**定义 1.3** (主题聚类)
主题聚类是一个函数 $C: T^* \rightarrow \mathcal{P}(T)^*$，将主题集合划分为 $k$ 个簇：

$$C(T) = \{C_1, C_2, ..., C_k\}$$

其中 $\bigcup_{i=1}^k C_i = T$ 且 $C_i \cap C_j = \emptyset$ 对于 $i \neq j$。

**定义 1.4** (聚类质量)
聚类质量函数 $Q: \mathcal{P}(T)^* \rightarrow \mathbb{R}$ 定义为：

$$Q(C) = \frac{1}{k} \sum_{i=1}^k \frac{1}{|C_i|} \sum_{t_1, t_2 \in C_i} sim(t_1, t_2)$$

#### Python实现

```python
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.metrics import silhouette_score, calinski_harabasz_score
import numpy as np
from typing import List, Tuple, Dict

class TopicClusterer:
    """主题聚类器"""
    
    def __init__(self, method: str = 'kmeans', n_clusters: int = 3):
        self.method = method
        self.n_clusters = n_clusters
        self.similarity_calculator = TopicSimilarityCalculator()
        
    def kmeans_clustering(self, topics: List[Topic]) -> Tuple[List[int], Dict]:
        """K-means聚类"""
        # 计算相似度矩阵
        similarity_matrix = self.similarity_calculator.tfidf_similarity(topics)
        
        # 转换为距离矩阵
        distance_matrix = 1 - similarity_matrix
        
        # K-means聚类
        kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)
        cluster_labels = kmeans.fit_predict(distance_matrix)
        
        # 计算聚类质量
        quality_metrics = {
            'silhouette_score': silhouette_score(distance_matrix, cluster_labels),
            'calinski_harabasz_score': calinski_harabasz_score(distance_matrix, cluster_labels)
        }
        
        return cluster_labels, quality_metrics
        
    def hierarchical_clustering(self, topics: List[Topic]) -> Tuple[List[int], Dict]:
        """层次聚类"""
        # 计算相似度矩阵
        similarity_matrix = self.similarity_calculator.tfidf_similarity(topics)
        distance_matrix = 1 - similarity_matrix
        
        # 层次聚类
        hierarchical = AgglomerativeClustering(
            n_clusters=self.n_clusters,
            affinity='precomputed',
            linkage='ward'
        )
        cluster_labels = hierarchical.fit_predict(distance_matrix)
        
        # 计算聚类质量
        quality_metrics = {
            'silhouette_score': silhouette_score(distance_matrix, cluster_labels),
            'calinski_harabasz_score': calinski_harabasz_score(distance_matrix, cluster_labels)
        }
        
        return cluster_labels, quality_metrics
        
    def dbscan_clustering(self, topics: List[Topic], eps: float = 0.5) -> Tuple[List[int], Dict]:
        """DBSCAN聚类"""
        # 计算相似度矩阵
        similarity_matrix = self.similarity_calculator.tfidf_similarity(topics)
        distance_matrix = 1 - similarity_matrix
        
        # DBSCAN聚类
        dbscan = DBSCAN(eps=eps, min_samples=2, metric='precomputed')
        cluster_labels = dbscan.fit_predict(distance_matrix)
        
        # 计算聚类质量
        n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)
        quality_metrics = {
            'n_clusters': n_clusters,
            'n_noise': list(cluster_labels).count(-1)
        }
        
        if n_clusters > 1:
            quality_metrics['silhouette_score'] = silhouette_score(distance_matrix, cluster_labels)
            
        return cluster_labels, quality_metrics
        
    def cluster_topics(self, topics: List[Topic]) -> Tuple[List[int], Dict]:
        """聚类主题"""
        if self.method == 'kmeans':
            return self.kmeans_clustering(topics)
        elif self.method == 'hierarchical':
            return self.hierarchical_clustering(topics)
        elif self.method == 'dbscan':
            return self.dbscan_clustering(topics)
        else:
            raise ValueError(f"不支持的聚类方法: {self.method}")

class TopicClusterAnalyzer:
    """主题聚类分析器"""
    
    def __init__(self):
        self.clusterer = TopicClusterer()
        
    def analyze_clusters(self, topics: List[Topic], cluster_labels: List[int]) -> Dict:
        """分析聚类结果"""
        n_clusters = len(set(cluster_labels))
        analysis = {
            'n_clusters': n_clusters,
            'cluster_sizes': {},
            'cluster_topics': {},
            'cluster_keywords': {}
        }
        
        for i in range(n_clusters):
            cluster_topics = [topics[j] for j, label in enumerate(cluster_labels) if label == i]
            analysis['cluster_sizes'][i] = len(cluster_topics)
            analysis['cluster_topics'][i] = [t.name for t in cluster_topics]
            
            # 提取关键词
            all_keywords = []
            for topic in cluster_topics:
                all_keywords.extend(topic.keywords)
            
            # 计算关键词频率
            keyword_freq = {}
            for keyword in all_keywords:
                keyword_freq[keyword] = keyword_freq.get(keyword, 0) + 1
                
            # 排序并取前5个
            sorted_keywords = sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True)
            analysis['cluster_keywords'][i] = [kw for kw, freq in sorted_keywords[:5]]
            
        return analysis

# 示例：主题聚类
def demonstrate_topic_clustering():
    """演示主题聚类"""
    # 创建更多主题
    topics = [
        Topic("机器学习", {"算法", "模型", "训练", "预测"}, ["机器学习", "算法", "模型", "训练", "预测"]),
        Topic("深度学习", {"神经网络", "模型", "训练", "优化"}, ["深度学习", "神经网络", "模型", "训练", "优化"]),
        Topic("强化学习", {"智能体", "环境", "奖励", "策略"}, ["强化学习", "智能体", "环境", "奖励", "策略"]),
        Topic("数据科学", {"数据分析", "统计", "可视化", "挖掘"}, ["数据科学", "数据分析", "统计", "可视化", "挖掘"]),
        Topic("大数据", {"分布式", "存储", "处理", "分析"}, ["大数据", "分布式", "存储", "处理", "分析"]),
        Topic("自然语言处理", {"文本", "语言", "模型", "理解"}, ["自然语言处理", "文本", "语言", "模型", "理解"]),
        Topic("计算机视觉", {"图像", "视频", "识别", "检测"}, ["计算机视觉", "图像", "视频", "识别", "检测"]),
        Topic("语音识别", {"音频", "语音", "识别", "转换"}, ["语音识别", "音频", "语音", "识别", "转换"])
    ]
    
    # 测试不同聚类方法
    methods = ['kmeans', 'hierarchical', 'dbscan']
    
    for method in methods:
        print(f"\n=== {method.upper()} 聚类结果 ===")
        
        if method == 'dbscan':
            clusterer = TopicClusterer(method=method)
        else:
            clusterer = TopicClusterer(method=method, n_clusters=3)
            
        cluster_labels, quality_metrics = clusterer.cluster_topics(topics)
        
        print(f"聚类标签: {cluster_labels}")
        print(f"质量指标: {quality_metrics}")
        
        # 分析聚类结果
        analyzer = TopicClusterAnalyzer()
        analysis = analyzer.analyze_clusters(topics, cluster_labels)
        
        print("聚类分析:")
        for cluster_id in range(analysis['n_clusters']):
            print(f"  簇 {cluster_id}:")
            print(f"    大小: {analysis['cluster_sizes'][cluster_id]}")
            print(f"    主题: {analysis['cluster_topics'][cluster_id]}")
            print(f"    关键词: {analysis['cluster_keywords'][cluster_id]}")
```

## 2. 主题推荐算法

### 2.1 基于内容的推荐

#### 数学定义

**定义 2.1** (主题推荐分数)
主题推荐分数函数 $R: U \times T \rightarrow \mathbb{R}$ 定义为：

$$R(u, t) = \sum_{t' \in T_u} sim(t, t') \cdot w_{t'}$$

其中 $T_u$ 是用户 $u$ 感兴趣的主题集合，$w_{t'}$ 是主题 $t'$ 的权重。

**定义 2.2** (用户兴趣模型)
用户兴趣模型是一个三元组 $I_u = (T_u, W_u, H_u)$，其中：

- $T_u$ 为用户感兴趣的主题集合
- $W_u$ 为主题权重向量
- $H_u$ 为用户历史行为

#### Python实现

```python
from typing import Dict, List, Set, Tuple, Optional
import numpy as np
from collections import defaultdict
import heapq

@dataclass
class User:
    """用户定义"""
    id: str
    name: str
    interests: Set[str]
    history: List[str]
    
    def __init__(self, name: str, interests: Set[str]):
        self.id = str(uuid.uuid4())
        self.name = name
        self.interests = interests
        self.history = []

@dataclass
class TopicRecommendation:
    """主题推荐结果"""
    topic: Topic
    score: float
    reason: str

class ContentBasedRecommender:
    """基于内容的推荐器"""
    
    def __init__(self):
        self.similarity_calculator = TopicSimilarityCalculator()
        self.user_profiles: Dict[str, Dict[str, float]] = {}
        
    def build_user_profile(self, user: User, topics: List[Topic]) -> Dict[str, float]:
        """构建用户画像"""
        profile = defaultdict(float)
        
        # 基于用户兴趣
        for interest in user.interests:
            for topic in topics:
                if interest.lower() in topic.name.lower() or any(interest.lower() in kw.lower() for kw in topic.keywords):
                    profile[topic.id] += 1.0
                    
        # 基于历史行为
        for history_item in user.history:
            for topic in topics:
                if history_item in topic.name or history_item in topic.keywords:
                    profile[topic.id] += 0.5
                    
        # 归一化
        total_weight = sum(profile.values())
        if total_weight > 0:
            profile = {k: v / total_weight for k, v in profile.items()}
            
        return dict(profile)
        
    def recommend_topics(self, user: User, topics: List[Topic], n_recommendations: int = 5) -> List[TopicRecommendation]:
        """推荐主题"""
        # 构建用户画像
        user_profile = self.build_user_profile(user, topics)
        self.user_profiles[user.id] = user_profile
        
        # 计算推荐分数
        recommendations = []
        
        for topic in topics:
            if topic.id not in user_profile:  # 避免推荐已感兴趣的主题
                score = 0.0
                reasons = []
                
                # 基于用户画像计算分数
                for profile_topic_id, weight in user_profile.items():
                    profile_topic = next((t for t in topics if t.id == profile_topic_id), None)
                    if profile_topic:
                        similarity = self.similarity_calculator.calculate_similarity(topic, profile_topic)
                        score += similarity * weight
                        
                        if similarity > 0.3:
                            reasons.append(f"与'{profile_topic.name}'相似")
                            
                if score > 0:
                    reason = "、".join(reasons[:3]) if reasons else "基于内容相似性"
                    recommendations.append(TopicRecommendation(topic, score, reason))
                    
        # 排序并返回前N个推荐
        recommendations.sort(key=lambda x: x.score, reverse=True)
        return recommendations[:n_recommendations]

class CollaborativeFilteringRecommender:
    """协同过滤推荐器"""
    
    def __init__(self):
        self.user_topic_matrix: Dict[str, Dict[str, float]] = {}
        self.topic_user_matrix: Dict[str, Dict[str, float]] = {}
        
    def build_matrices(self, users: List[User], topics: List[Topic]):
        """构建用户-主题矩阵"""
        # 初始化矩阵
        for user in users:
            self.user_topic_matrix[user.id] = {}
            for topic in topics:
                self.user_topic_matrix[user.id][topic.id] = 0.0
                
        for topic in topics:
            self.topic_user_matrix[topic.id] = {}
            for user in users:
                self.topic_user_matrix[topic.id][user.id] = 0.0
                
        # 填充矩阵
        for user in users:
            for topic in topics:
                # 基于兴趣
                if any(interest.lower() in topic.name.lower() for interest in user.interests):
                    self.user_topic_matrix[user.id][topic.id] += 1.0
                    self.topic_user_matrix[topic.id][user.id] += 1.0
                    
                # 基于历史
                if topic.name in user.history:
                    self.user_topic_matrix[user.id][topic.id] += 0.5
                    self.topic_user_matrix[topic.id][user.id] += 0.5
                    
    def find_similar_users(self, user_id: str, n_similar: int = 5) -> List[Tuple[str, float]]:
        """找到相似用户"""
        if user_id not in self.user_topic_matrix:
            return []
            
        user_vector = list(self.user_topic_matrix[user_id].values())
        similarities = []
        
        for other_user_id, other_vector in self.user_topic_matrix.items():
            if other_user_id != user_id:
                other_vector_list = list(other_vector.values())
                
                # 计算余弦相似度
                dot_product = sum(a * b for a, b in zip(user_vector, other_vector_list))
                norm1 = sum(a * a for a in user_vector) ** 0.5
                norm2 = sum(b * b for b in other_vector_list) ** 0.5
                
                if norm1 > 0 and norm2 > 0:
                    similarity = dot_product / (norm1 * norm2)
                    similarities.append((other_user_id, similarity))
                    
        # 排序并返回前N个相似用户
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:n_similar]
        
    def recommend_topics(self, user: User, topics: List[Topic], n_recommendations: int = 5) -> List[TopicRecommendation]:
        """基于协同过滤推荐主题"""
        if user.id not in self.user_topic_matrix:
            return []
            
        # 找到相似用户
        similar_users = self.find_similar_users(user.id)
        
        # 计算推荐分数
        topic_scores = defaultdict(float)
        topic_reasons = defaultdict(list)
        
        for similar_user_id, similarity in similar_users:
            similar_user_vector = self.user_topic_matrix[similar_user_id]
            
            for topic in topics:
                if topic.id in similar_user_vector and similar_user_vector[topic.id] > 0:
                    score = similarity * similar_user_vector[topic.id]
                    topic_scores[topic.id] += score
                    topic_reasons[topic.id].append(f"用户{similar_user_id}的兴趣")
                    
        # 构建推荐结果
        recommendations = []
        for topic_id, score in topic_scores.items():
            if score > 0:
                topic = next((t for t in topics if t.id == topic_id), None)
                if topic:
                    reason = "、".join(topic_reasons[topic_id][:2])
                    recommendations.append(TopicRecommendation(topic, score, reason))
                    
        # 排序并返回
        recommendations.sort(key=lambda x: x.score, reverse=True)
        return recommendations[:n_recommendations]

# 示例：主题推荐
def demonstrate_topic_recommendation():
    """演示主题推荐"""
    # 创建主题
    topics = [
        Topic("机器学习", {"算法", "模型", "训练", "预测"}, ["机器学习", "算法", "模型", "训练", "预测"]),
        Topic("深度学习", {"神经网络", "模型", "训练", "优化"}, ["深度学习", "神经网络", "模型", "训练", "优化"]),
        Topic("数据科学", {"数据分析", "统计", "可视化", "挖掘"}, ["数据科学", "数据分析", "统计", "可视化", "挖掘"]),
        Topic("自然语言处理", {"文本", "语言", "模型", "理解"}, ["自然语言处理", "文本", "语言", "模型", "理解"]),
        Topic("计算机视觉", {"图像", "视频", "识别", "检测"}, ["计算机视觉", "图像", "视频", "识别", "检测"]),
        Topic("推荐系统", {"推荐", "算法", "用户", "物品"}, ["推荐系统", "推荐", "算法", "用户", "物品"]),
        Topic("图神经网络", {"图", "网络", "节点", "边"}, ["图神经网络", "图", "网络", "节点", "边"]),
        Topic("强化学习", {"智能体", "环境", "奖励", "策略"}, ["强化学习", "智能体", "环境", "奖励", "策略"])
    ]
    
    # 创建用户
    users = [
        User("张三", {"机器学习", "深度学习"}),
        User("李四", {"数据科学", "可视化"}),
        User("王五", {"推荐系统", "算法"}),
        User("赵六", {"自然语言处理", "文本"})
    ]
    
    # 基于内容的推荐
    print("=== 基于内容的推荐 ===")
    content_recommender = ContentBasedRecommender()
    
    for user in users:
        recommendations = content_recommender.recommend_topics(user, topics, n_recommendations=3)
        print(f"\n{user.name} 的推荐:")
        for rec in recommendations:
            print(f"  {rec.topic.name}: {rec.score:.3f} ({rec.reason})")
    
    # 协同过滤推荐
    print("\n=== 协同过滤推荐 ===")
    cf_recommender = CollaborativeFilteringRecommender()
    cf_recommender.build_matrices(users, topics)
    
    for user in users:
        recommendations = cf_recommender.recommend_topics(user, topics, n_recommendations=3)
        print(f"\n{user.name} 的推荐:")
        for rec in recommendations:
            print(f"  {rec.topic.name}: {rec.score:.3f} ({rec.reason})")
```

## 3. 主题演化算法

### 3.1 主题生命周期管理

#### 数学定义

**定义 3.1** (主题生命周期)
主题生命周期是一个五元组 $L_T = (birth, growth, maturity, decline, death)$，其中每个阶段都有对应的时间戳和特征。

**定义 3.2** (主题热度)
主题热度函数 $H: T \times \mathbb{R} \rightarrow \mathbb{R}^+$ 定义为：

$$H(t, \tau) = \alpha \cdot \text{popularity}(t, \tau) + \beta \cdot \text{relevance}(t, \tau) + \gamma \cdot \text{novelty}(t, \tau)$$

其中 $\alpha + \beta + \gamma = 1$ 是权重参数。

#### Python实现

```python
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import numpy as np
from enum import Enum

class TopicLifecycleStage(Enum):
    """主题生命周期阶段"""
    BIRTH = "birth"
    GROWTH = "growth"
    MATURITY = "maturity"
    DECLINE = "decline"
    DEATH = "death"

@dataclass
class TopicEvent:
    """主题事件"""
    timestamp: datetime
    event_type: str
    data: Dict[str, Any]
    
@dataclass
class TopicLifecycle:
    """主题生命周期"""
    topic_id: str
    stage: TopicLifecycleStage
    birth_time: datetime
    current_time: datetime
    events: List[TopicEvent]
    popularity_history: List[Tuple[datetime, float]]
    
    def __init__(self, topic_id: str):
        self.topic_id = topic_id
        self.stage = TopicLifecycleStage.BIRTH
        self.birth_time = datetime.now()
        self.current_time = datetime.now()
        self.events = []
        self.popularity_history = []

class TopicEvolutionTracker:
    """主题演化跟踪器"""
    
    def __init__(self, alpha: float = 0.4, beta: float = 0.4, gamma: float = 0.2):
        self.alpha = alpha  # 流行度权重
        self.beta = beta    # 相关性权重
        self.gamma = gamma  # 新颖性权重
        self.lifecycles: Dict[str, TopicLifecycle] = {}
        
    def add_topic_event(self, topic_id: str, event_type: str, data: Dict[str, Any]):
        """添加主题事件"""
        if topic_id not in self.lifecycles:
            self.lifecycles[topic_id] = TopicLifecycle(topic_id)
            
        lifecycle = self.lifecycles[topic_id]
        event = TopicEvent(datetime.now(), event_type, data)
        lifecycle.events.append(event)
        
    def calculate_popularity(self, topic_id: str, time_window: timedelta = timedelta(days=7)) -> float:
        """计算主题流行度"""
        if topic_id not in self.lifecycles:
            return 0.0
            
        lifecycle = self.lifecycles[topic_id]
        cutoff_time = datetime.now() - time_window
        
        # 统计时间窗口内的事件数量
        recent_events = [e for e in lifecycle.events if e.timestamp >= cutoff_time]
        return len(recent_events)
        
    def calculate_relevance(self, topic_id: str, current_topics: List[str]) -> float:
        """计算主题相关性"""
        if topic_id not in self.lifecycles:
            return 0.0
            
        # 基于当前热门主题计算相关性
        if topic_id in current_topics:
            return 1.0
        else:
            return 0.5
            
    def calculate_novelty(self, topic_id: str) -> float:
        """计算主题新颖性"""
        if topic_id not in self.lifecycles:
            return 1.0  # 新主题具有最高新颖性
            
        lifecycle = self.lifecycles[topic_id]
        age = datetime.now() - lifecycle.birth_time
        
        # 新颖性随时间衰减
        novelty = np.exp(-age.days / 30.0)  # 30天半衰期
        return novelty
        
    def calculate_heat(self, topic_id: str, current_topics: List[str]) -> float:
        """计算主题热度"""
        popularity = self.calculate_popularity(topic_id)
        relevance = self.calculate_relevance(topic_id, current_topics)
        novelty = self.calculate_novelty(topic_id)
        
        heat = (self.alpha * popularity + 
                self.beta * relevance + 
                self.gamma * novelty)
                
        return heat
        
    def update_lifecycle_stage(self, topic_id: str):
        """更新主题生命周期阶段"""
        if topic_id not in self.lifecycles:
            return
            
        lifecycle = self.lifecycles[topic_id]
        current_topics = [tid for tid in self.lifecycles.keys()]
        heat = self.calculate_heat(topic_id, current_topics)
        
        # 记录热度历史
        lifecycle.popularity_history.append((datetime.now(), heat))
        
        # 更新阶段
        if heat > 0.8:
            lifecycle.stage = TopicLifecycleStage.GROWTH
        elif heat > 0.6:
            lifecycle.stage = TopicLifecycleStage.MATURITY
        elif heat > 0.3:
            lifecycle.stage = TopicLifecycleStage.DECLINE
        else:
            lifecycle.stage = TopicLifecycleStage.DEATH
            
    def get_trending_topics(self, n_topics: int = 10) -> List[Tuple[str, float]]:
        """获取热门主题"""
        current_topics = [tid for tid in self.lifecycles.keys()]
        topic_heats = []
        
        for topic_id in current_topics:
            heat = self.calculate_heat(topic_id, current_topics)
            topic_heats.append((topic_id, heat))
            
        # 排序并返回前N个
        topic_heats.sort(key=lambda x: x[1], reverse=True)
        return topic_heats[:n_topics]

class TopicEvolutionAnalyzer:
    """主题演化分析器"""
    
    def __init__(self, tracker: TopicEvolutionTracker):
        self.tracker = tracker
        
    def analyze_topic_evolution(self, topic_id: str) -> Dict[str, Any]:
        """分析主题演化"""
        if topic_id not in self.tracker.lifecycles:
            return {}
            
        lifecycle = self.tracker.lifecycles[topic_id]
        
        analysis = {
            'topic_id': topic_id,
            'current_stage': lifecycle.stage.value,
            'age_days': (datetime.now() - lifecycle.birth_time).days,
            'total_events': len(lifecycle.events),
            'popularity_trend': self._calculate_trend(lifecycle.popularity_history),
            'stage_duration': self._calculate_stage_duration(lifecycle)
        }
        
        return analysis
        
    def _calculate_trend(self, history: List[Tuple[datetime, float]]) -> str:
        """计算趋势"""
        if len(history) < 2:
            return "stable"
            
        recent = history[-5:] if len(history) >= 5 else history
        values = [h[1] for h in recent]
        
        if len(values) < 2:
            return "stable"
            
        # 简单线性趋势
        x = np.arange(len(values))
        slope = np.polyfit(x, values, 1)[0]
        
        if slope > 0.01:
            return "increasing"
        elif slope < -0.01:
            return "decreasing"
        else:
            return "stable"
            
    def _calculate_stage_duration(self, lifecycle: TopicLifecycle) -> Dict[str, int]:
        """计算各阶段持续时间"""
        stage_durations = {}
        current_stage_start = lifecycle.birth_time
        
        for event in lifecycle.events:
            if 'stage_change' in event.event_type:
                stage_name = event.data.get('stage', 'unknown')
                duration = (event.timestamp - current_stage_start).days
                stage_durations[stage_name] = duration
                current_stage_start = event.timestamp
                
        return stage_durations

# 示例：主题演化
def demonstrate_topic_evolution():
    """演示主题演化"""
    # 创建演化跟踪器
    tracker = TopicEvolutionTracker()
    
    # 模拟主题事件
    topics = ["机器学习", "深度学习", "强化学习", "数据科学"]
    
    for i in range(20):
        for topic in topics:
            # 随机添加事件
            if np.random.random() > 0.7:
                event_data = {
                    'user_id': f"user_{np.random.randint(1, 100)}",
                    'action': np.random.choice(['view', 'like', 'share', 'comment'])
                }
                tracker.add_topic_event(topic, 'user_interaction', event_data)
                
        # 更新生命周期
        for topic in topics:
            tracker.update_lifecycle_stage(topic)
            
    # 获取热门主题
    trending = tracker.get_trending_topics()
    print("热门主题:")
    for topic_id, heat in trending:
        print(f"  {topic_id}: {heat:.3f}")
        
    # 分析主题演化
    analyzer = TopicEvolutionAnalyzer(tracker)
    
    for topic in topics:
        analysis = analyzer.analyze_topic_evolution(topic)
        print(f"\n{topic} 演化分析:")
        for key, value in analysis.items():
            print(f"  {key}: {value}")
```

## 4. 总结与展望

### 4.1 算法基础总结

主题相关的算法实现涵盖了：

1. **聚类算法**: 基于相似度的主题分组和分类
2. **推荐算法**: 基于内容和协同过滤的主题推荐
3. **演化算法**: 主题生命周期管理和热度跟踪

### 4.2 与后续章节的关联

本算法基础为后续章节提供了：

- [07-实践应用/01-主题驱动的工程实践](../07-实践应用/01-主题驱动的工程实践.md) 提供算法工具
- [04-行业领域/01-主题在金融科技中的应用](../04-行业领域/01-主题在金融科技中的应用.md) 提供技术支撑
- [08-项目进度/上下文提醒](../08-项目进度/上下文提醒.md) 提供实现参考

### 4.3 未来研究方向

1. **深度学习算法**: 基于神经网络的主题表示学习
2. **图算法**: 主题关系图的图算法应用
3. **量子算法**: 主题在量子计算中的算法实现
4. **联邦学习**: 分布式环境下的主题学习算法

---

**相关链接**:
- [返回目录](../../README.md)
- [上一章：主题驱动的系统架构](../05-架构领域/01-主题驱动的系统架构.md)
- [下一章：主题驱动的工程实践](../07-实践应用/01-主题驱动的工程实践.md) 