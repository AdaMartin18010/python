# 00-01-01 ç¼–ç¨‹è¯­è¨€å“²å­¦

## ğŸ“‹ æ¦‚è¿°

ç¼–ç¨‹è¯­è¨€å“²å­¦æ¢è®¨ç¼–ç¨‹è¯­è¨€çš„æœ¬è´¨ã€è¯­è¨€ä¸æ€ç»´çš„å…³ç³»ã€å½¢å¼åŒ–è¡¨è¾¾çš„ç†è®ºåŸºç¡€ç­‰æ ¸å¿ƒé—®é¢˜ã€‚æœ¬æ–‡æ¡£ä»å“²å­¦è§’åº¦æ·±å…¥åˆ†æç¼–ç¨‹è¯­è¨€çš„ç†è®ºåŸºç¡€ï¼Œä¸ºç†è§£ç¼–ç¨‹è¯­è¨€çš„æœ¬è´¨æä¾›æ€æƒ³æŒ‡å¯¼ã€‚

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### 1. ç¼–ç¨‹è¯­è¨€çš„æœ¬è´¨å®šä¹‰

#### 1.1 å½¢å¼åŒ–å®šä¹‰

**å®šä¹‰ 1.1** (ç¼–ç¨‹è¯­è¨€)
ç¼–ç¨‹è¯­è¨€æ˜¯ä¸€ä¸ªäº”å…ƒç»„ï¼š
$$PL = (\Sigma, \Gamma, \delta, q_0, F)$$

å…¶ä¸­ï¼š
- $\Sigma$ ä¸ºè¾“å…¥å­—æ¯è¡¨ï¼ˆè¯­æ³•ç¬¦å·é›†ï¼‰
- $\Gamma$ ä¸ºçŠ¶æ€å­—æ¯è¡¨ï¼ˆè¯­ä¹‰ç¬¦å·é›†ï¼‰
- $\delta$ ä¸ºè½¬ç§»å‡½æ•°ï¼š$\delta: Q \times \Sigma \rightarrow Q \times \Gamma \times \{L, R, N\}$
- $q_0$ ä¸ºåˆå§‹çŠ¶æ€
- $F$ ä¸ºæ¥å—çŠ¶æ€é›†

**å®šä¹‰ 1.2** (è¯­è¨€è¡¨è¾¾èƒ½åŠ›)
è¯­è¨€ $L$ çš„è¡¨è¾¾èƒ½åŠ›å®šä¹‰ä¸ºï¼š
$$Expressiveness(L) = \{f: \mathbb{N} \rightarrow \mathbb{N} \mid f \text{ å¯ç”± } L \text{ è®¡ç®—}\}$$

#### 1.2 Pythonå®ç°

```python
from abc import ABC, abstractmethod
from typing import Dict, List, Set, Any, Optional, Tuple, Callable
from dataclasses import dataclass
from enum import Enum
import re

class SymbolType(Enum):
    """ç¬¦å·ç±»å‹"""
    TERMINAL = "terminal"
    NON_TERMINAL = "non_terminal"
    OPERATOR = "operator"
    KEYWORD = "keyword"

@dataclass
class Symbol:
    """ç¬¦å·å®šä¹‰"""
    name: str
    type: SymbolType
    value: Optional[str] = None
    
    def __str__(self):
        return f"{self.name}({self.type.value})"

@dataclass
class GrammarRule:
    """è¯­æ³•è§„åˆ™"""
    left: str
    right: List[str]
    action: Optional[Callable] = None
    
    def __str__(self):
        return f"{self.left} -> {' '.join(self.right)}"

class ProgrammingLanguage:
    """ç¼–ç¨‹è¯­è¨€æŠ½è±¡ç±»"""
    
    def __init__(self, name: str):
        self.name = name
        self.alphabet: Set[Symbol] = set()
        self.grammar_rules: List[GrammarRule] = []
        self.semantic_rules: Dict[str, Callable] = {}
        self.type_system: Dict[str, type] = {}
    
    def add_symbol(self, symbol: Symbol) -> None:
        """æ·»åŠ ç¬¦å·åˆ°å­—æ¯è¡¨"""
        self.alphabet.add(symbol)
    
    def add_grammar_rule(self, rule: GrammarRule) -> None:
        """æ·»åŠ è¯­æ³•è§„åˆ™"""
        self.grammar_rules.append(rule)
    
    def add_semantic_rule(self, name: str, rule: Callable) -> None:
        """æ·»åŠ è¯­ä¹‰è§„åˆ™"""
        self.semantic_rules[name] = rule
    
    def add_type(self, name: str, type_def: type) -> None:
        """æ·»åŠ ç±»å‹å®šä¹‰"""
        self.type_system[name] = type_def
    
    def parse(self, code: str) -> Any:
        """è§£æä»£ç """
        raise NotImplementedError
    
    def execute(self, ast: Any) -> Any:
        """æ‰§è¡ŒæŠ½è±¡è¯­æ³•æ ‘"""
        raise NotImplementedError
    
    def get_expressiveness(self) -> Set[str]:
        """è·å–è¡¨è¾¾èƒ½åŠ›"""
        return {rule.left for rule in self.grammar_rules}

class PythonLanguage(ProgrammingLanguage):
    """Pythonè¯­è¨€å®ç°"""
    
    def __init__(self):
        super().__init__("Python")
        self._setup_alphabet()
        self._setup_grammar()
        self._setup_semantics()
    
    def _setup_alphabet(self):
        """è®¾ç½®Pythonå­—æ¯è¡¨"""
        # å…³é”®å­—
        keywords = ['def', 'class', 'if', 'else', 'for', 'while', 'return', 'import']
        for keyword in keywords:
            self.add_symbol(Symbol(keyword, SymbolType.KEYWORD))
        
        # æ“ä½œç¬¦
        operators = ['+', '-', '*', '/', '=', '==', '!=', '<', '>', '<=', '>=']
        for op in operators:
            self.add_symbol(Symbol(op, SymbolType.OPERATOR))
        
        # æ ‡è¯†ç¬¦
        self.add_symbol(Symbol("IDENTIFIER", SymbolType.TERMINAL))
        self.add_symbol(Symbol("NUMBER", SymbolType.TERMINAL))
        self.add_symbol(Symbol("STRING", SymbolType.TERMINAL))
    
    def _setup_grammar(self):
        """è®¾ç½®Pythonè¯­æ³•è§„åˆ™"""
        # å‡½æ•°å®šä¹‰
        self.add_grammar_rule(GrammarRule(
            "function_def",
            ["def", "IDENTIFIER", "(", "parameters", ")", ":", "suite"]
        ))
        
        # ç±»å®šä¹‰
        self.add_grammar_rule(GrammarRule(
            "class_def",
            ["class", "IDENTIFIER", "(", "bases", ")", ":", "suite"]
        ))
        
        # æ¡ä»¶è¯­å¥
        self.add_grammar_rule(GrammarRule(
            "if_stmt",
            ["if", "expression", ":", "suite", "elif_clause*", "else_clause?"]
        ))
        
        # å¾ªç¯è¯­å¥
        self.add_grammar_rule(GrammarRule(
            "for_stmt",
            ["for", "IDENTIFIER", "in", "expression", ":", "suite"]
        ))
    
    def _setup_semantics(self):
        """è®¾ç½®Pythonè¯­ä¹‰è§„åˆ™"""
        self.add_semantic_rule("function_call", self._semantic_function_call)
        self.add_semantic_rule("variable_assignment", self._semantic_assignment)
        self.add_semantic_rule("arithmetic_operation", self._semantic_arithmetic)
    
    def _semantic_function_call(self, func_name: str, args: List[Any]) -> Any:
        """å‡½æ•°è°ƒç”¨è¯­ä¹‰"""
        return f"CALL({func_name}, {args})"
    
    def _semantic_assignment(self, var_name: str, value: Any) -> None:
        """å˜é‡èµ‹å€¼è¯­ä¹‰"""
        return f"ASSIGN({var_name}, {value})"
    
    def _semantic_arithmetic(self, op: str, left: Any, right: Any) -> Any:
        """ç®—æœ¯è¿ç®—è¯­ä¹‰"""
        return f"ARITH({left}, {op}, {right})"
    
    def parse(self, code: str) -> Dict[str, Any]:
        """è§£æPythonä»£ç """
        lines = code.split('\n')
        ast = {
            'type': 'module',
            'body': []
        }
        
        for line in lines:
            line = line.strip()
            if line.startswith('def '):
                ast['body'].append(self._parse_function_def(line))
            elif line.startswith('class '):
                ast['body'].append(self._parse_class_def(line))
            elif line.startswith('if '):
                ast['body'].append(self._parse_if_stmt(line))
        
        return ast
    
    def _parse_function_def(self, line: str) -> Dict[str, Any]:
        """è§£æå‡½æ•°å®šä¹‰"""
        match = re.match(r'def\s+(\w+)\s*\((.*?)\)\s*:', line)
        if match:
            return {
                'type': 'function_def',
                'name': match.group(1),
                'parameters': match.group(2).split(',') if match.group(2) else []
            }
        return {'type': 'error', 'message': f'Invalid function definition: {line}'}
    
    def _parse_class_def(self, line: str) -> Dict[str, Any]:
        """è§£æç±»å®šä¹‰"""
        match = re.match(r'class\s+(\w+)(?:\s*\((.*?)\))?\s*:', line)
        if match:
            return {
                'type': 'class_def',
                'name': match.group(1),
                'bases': match.group(2).split(',') if match.group(2) else []
            }
        return {'type': 'error', 'message': f'Invalid class definition: {line}'}
    
    def _parse_if_stmt(self, line: str) -> Dict[str, Any]:
        """è§£æifè¯­å¥"""
        match = re.match(r'if\s+(.+?)\s*:', line)
        if match:
            return {
                'type': 'if_stmt',
                'condition': match.group(1)
            }
        return {'type': 'error', 'message': f'Invalid if statement: {line}'}
    
    def execute(self, ast: Dict[str, Any]) -> Any:
        """æ‰§è¡ŒæŠ½è±¡è¯­æ³•æ ‘"""
        if ast['type'] == 'module':
            results = []
            for node in ast['body']:
                results.append(self.execute(node))
            return results
        elif ast['type'] == 'function_def':
            return f"Function {ast['name']} defined with parameters {ast['parameters']}"
        elif ast['type'] == 'class_def':
            return f"Class {ast['name']} defined with bases {ast['bases']}"
        elif ast['type'] == 'if_stmt':
            return f"If statement with condition: {ast['condition']}"
        else:
            return f"Executed: {ast}"

# ä½¿ç”¨ç¤ºä¾‹
def demonstrate_programming_language_philosophy():
    """æ¼”ç¤ºç¼–ç¨‹è¯­è¨€å“²å­¦"""
    
    # åˆ›å»ºPythonè¯­è¨€å®ä¾‹
    python_lang = PythonLanguage()
    
    # ç¤ºä¾‹ä»£ç 
    sample_code = """
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

class Calculator:
    def add(self, a, b):
        return a + b

if x > 0:
    print("Positive")
"""
    
    print("=== ç¼–ç¨‹è¯­è¨€å“²å­¦æ¼”ç¤º ===")
    print(f"è¯­è¨€åç§°: {python_lang.name}")
    print(f"å­—æ¯è¡¨å¤§å°: {len(python_lang.alphabet)}")
    print(f"è¯­æ³•è§„åˆ™æ•°é‡: {len(python_lang.grammar_rules)}")
    print(f"è¡¨è¾¾èƒ½åŠ›: {python_lang.get_expressiveness()}")
    
    print("\n=== ä»£ç è§£æ ===")
    ast = python_lang.parse(sample_code)
    print("æŠ½è±¡è¯­æ³•æ ‘:")
    for node in ast['body']:
        print(f"  {node}")
    
    print("\n=== ä»£ç æ‰§è¡Œ ===")
    results = python_lang.execute(ast)
    for result in results:
        print(f"  {result}")

if __name__ == "__main__":
    demonstrate_programming_language_philosophy()
```

### 2. è¯­è¨€ä¸æ€ç»´çš„å…³ç³»

#### 2.1 å½¢å¼åŒ–å®šä¹‰

**å®šä¹‰ 2.1** (è¯­è¨€æ€ç»´æ˜ å°„)
è¯­è¨€ä¸æ€ç»´çš„å…³ç³»å¯ä»¥å½¢å¼åŒ–ä¸ºï¼š
$$M: L \times T \rightarrow C$$

å…¶ä¸­ï¼š
- $L$ ä¸ºè¯­è¨€é›†åˆ
- $T$ ä¸ºæ€ç»´æ¨¡å¼é›†åˆ
- $C$ ä¸ºæ¦‚å¿µé›†åˆ
- $M$ ä¸ºæ˜ å°„å‡½æ•°

**å®šä¹‰ 2.2** (æ€ç»´è¡¨è¾¾èƒ½åŠ›)
æ€ç»´è¡¨è¾¾èƒ½åŠ›å®šä¹‰ä¸ºï¼š
$$ThinkingPower(L) = \frac{|M(L, T)|}{|T|}$$

#### 2.2 Pythonå®ç°

```python
from typing import Dict, Set, List, Any, Callable
from dataclasses import dataclass
from enum import Enum

class ThinkingMode(Enum):
    """æ€ç»´æ¨¡å¼"""
    ABSTRACT = "abstract"
    CONCRETE = "concrete"
    LOGICAL = "logical"
    CREATIVE = "creative"
    ANALYTICAL = "analytical"

@dataclass
class Concept:
    """æ¦‚å¿µå®šä¹‰"""
    name: str
    description: str
    complexity: float  # 0-1ä¹‹é—´çš„å¤æ‚åº¦
    abstraction_level: int  # æŠ½è±¡å±‚æ¬¡
    
    def __str__(self):
        return f"{self.name}: {self.description} (å¤æ‚åº¦: {self.complexity:.2f}, å±‚æ¬¡: {self.abstraction_level})"

class LanguageThinkingMapping:
    """è¯­è¨€æ€ç»´æ˜ å°„"""
    
    def __init__(self):
        self.languages: Dict[str, Set[str]] = {}
        self.thinking_modes: Dict[ThinkingMode, Set[str]] = {}
        self.concepts: Dict[str, Concept] = {}
        self.mappings: Dict[Tuple[str, ThinkingMode], Set[str]] = {}
    
    def add_language(self, name: str, features: Set[str]) -> None:
        """æ·»åŠ è¯­è¨€"""
        self.languages[name] = features
    
    def add_thinking_mode(self, mode: ThinkingMode, characteristics: Set[str]) -> None:
        """æ·»åŠ æ€ç»´æ¨¡å¼"""
        self.thinking_modes[mode] = characteristics
    
    def add_concept(self, concept: Concept) -> None:
        """æ·»åŠ æ¦‚å¿µ"""
        self.concepts[concept.name] = concept
    
    def add_mapping(self, language: str, mode: ThinkingMode, concepts: Set[str]) -> None:
        """æ·»åŠ æ˜ å°„å…³ç³»"""
        self.mappings[(language, mode)] = concepts
    
    def get_thinking_power(self, language: str) -> float:
        """è®¡ç®—æ€ç»´è¡¨è¾¾èƒ½åŠ›"""
        if language not in self.languages:
            return 0.0
        
        total_concepts = 0
        for mode in ThinkingMode:
            key = (language, mode)
            if key in self.mappings:
                total_concepts += len(self.mappings[key])
        
        return total_concepts / len(ThinkingMode)
    
    def analyze_language_features(self, language: str) -> Dict[str, Any]:
        """åˆ†æè¯­è¨€ç‰¹å¾"""
        if language not in self.languages:
            return {}
        
        features = self.languages[language]
        analysis = {
            'language': language,
            'features': list(features),
            'thinking_modes': {},
            'concept_coverage': 0,
            'abstraction_levels': set()
        }
        
        for mode in ThinkingMode:
            key = (language, mode)
            if key in self.mappings:
                concepts = self.mappings[key]
                analysis['thinking_modes'][mode.value] = list(concepts)
                analysis['concept_coverage'] += len(concepts)
                
                for concept_name in concepts:
                    if concept_name in self.concepts:
                        analysis['abstraction_levels'].add(
                            self.concepts[concept_name].abstraction_level
                        )
        
        return analysis

# ä½¿ç”¨ç¤ºä¾‹
def demonstrate_language_thinking_relationship():
    """æ¼”ç¤ºè¯­è¨€ä¸æ€ç»´çš„å…³ç³»"""
    
    # åˆ›å»ºæ˜ å°„å®ä¾‹
    mapping = LanguageThinkingMapping()
    
    # æ·»åŠ è¯­è¨€
    mapping.add_language("Python", {
        "åŠ¨æ€ç±»å‹", "é¢å‘å¯¹è±¡", "å‡½æ•°å¼ç¼–ç¨‹", "å…ƒç¼–ç¨‹", "ç®€æ´è¯­æ³•"
    })
    
    mapping.add_language("Haskell", {
        "é™æ€ç±»å‹", "å‡½æ•°å¼ç¼–ç¨‹", "æƒ°æ€§æ±‚å€¼", "ç±»å‹æ¨æ–­", "çº¯å‡½æ•°"
    })
    
    mapping.add_language("Assembly", {
        "ä½çº§è¯­è¨€", "ç›´æ¥ç¡¬ä»¶æ§åˆ¶", "å¯„å­˜å™¨æ“ä½œ", "å†…å­˜ç®¡ç†", "æ€§èƒ½ä¼˜åŒ–"
    })
    
    # æ·»åŠ æ€ç»´æ¨¡å¼
    mapping.add_thinking_mode(ThinkingMode.ABSTRACT, {
        "æŠ½è±¡æ€ç»´", "æ¦‚å¿µåŒ–", "æ¨¡å¼è¯†åˆ«", "å½’çº³æ¨ç†"
    })
    
    mapping.add_thinking_mode(ThinkingMode.LOGICAL, {
        "é€»è¾‘æ¨ç†", "å½¢å¼åŒ–è¯æ˜", "æ¼”ç»æ¨ç†", "å› æœå…³ç³»"
    })
    
    mapping.add_thinking_mode(ThinkingMode.CREATIVE, {
        "åˆ›é€ æ€§æ€ç»´", "å‘æ•£æ€ç»´", "åˆ›æ–°è®¾è®¡", "è‰ºæœ¯è¡¨è¾¾"
    })
    
    # æ·»åŠ æ¦‚å¿µ
    concepts = [
        Concept("å‡½æ•°", "å¯é‡ç”¨çš„ä»£ç å—", 0.3, 1),
        Concept("ç±»", "å¯¹è±¡çš„æ¨¡æ¿", 0.5, 2),
        Concept("é€’å½’", "å‡½æ•°è°ƒç”¨è‡ªèº«", 0.7, 3),
        Concept("é—­åŒ…", "å‡½æ•°ä¸ç¯å¢ƒçš„ç»“åˆ", 0.8, 3),
        Concept("è£…é¥°å™¨", "å‡½æ•°ä¿®é¥°å™¨", 0.9, 4),
        Concept("ç”Ÿæˆå™¨", "æƒ°æ€§åºåˆ—", 0.6, 3),
        Concept("å…ƒç±»", "ç±»çš„ç±»", 0.95, 5),
        Concept("å¼‚æ­¥ç¼–ç¨‹", "éé˜»å¡ç¼–ç¨‹", 0.8, 4),
        Concept("ç±»å‹ç³»ç»Ÿ", "ç±»å‹æ£€æŸ¥æœºåˆ¶", 0.7, 3),
        Concept("å†…å­˜ç®¡ç†", "å†…å­˜åˆ†é…å’Œå›æ”¶", 0.6, 2)
    ]
    
    for concept in concepts:
        mapping.add_concept(concept)
    
    # æ·»åŠ æ˜ å°„å…³ç³»
    mapping.add_mapping("Python", ThinkingMode.ABSTRACT, {
        "å‡½æ•°", "ç±»", "é€’å½’", "é—­åŒ…", "è£…é¥°å™¨", "ç”Ÿæˆå™¨", "å…ƒç±»"
    })
    
    mapping.add_mapping("Python", ThinkingMode.LOGICAL, {
        "ç±»å‹ç³»ç»Ÿ", "å†…å­˜ç®¡ç†", "é€’å½’", "å‡½æ•°"
    })
    
    mapping.add_mapping("Python", ThinkingMode.CREATIVE, {
        "è£…é¥°å™¨", "ç”Ÿæˆå™¨", "å…ƒç±»", "é—­åŒ…"
    })
    
    mapping.add_mapping("Haskell", ThinkingMode.ABSTRACT, {
        "å‡½æ•°", "é€’å½’", "ç±»å‹ç³»ç»Ÿ"
    })
    
    mapping.add_mapping("Haskell", ThinkingMode.LOGICAL, {
        "ç±»å‹ç³»ç»Ÿ", "é€’å½’", "å‡½æ•°"
    })
    
    mapping.add_mapping("Assembly", ThinkingMode.LOGICAL, {
        "å†…å­˜ç®¡ç†", "å‡½æ•°"
    })
    
    # åˆ†æç»“æœ
    print("=== è¯­è¨€ä¸æ€ç»´å…³ç³»åˆ†æ ===")
    
    for language in ["Python", "Haskell", "Assembly"]:
        analysis = mapping.analyze_language_features(language)
        thinking_power = mapping.get_thinking_power(language)
        
        print(f"\n{language} è¯­è¨€åˆ†æ:")
        print(f"  æ€ç»´è¡¨è¾¾èƒ½åŠ›: {thinking_power:.2f}")
        print(f"  æ¦‚å¿µè¦†ç›–åº¦: {analysis['concept_coverage']}")
        print(f"  æŠ½è±¡å±‚æ¬¡: {sorted(analysis['abstraction_levels'])}")
        
        for mode, concepts in analysis['thinking_modes'].items():
            print(f"  {mode} æ¨¡å¼æ”¯æŒçš„æ¦‚å¿µ: {concepts}")

if __name__ == "__main__":
    demonstrate_language_thinking_relationship()
```

## ğŸ“Š ç†è®ºè¯æ˜

### å®šç† 1.1 (ç¼–ç¨‹è¯­è¨€çš„è¡¨è¾¾èƒ½åŠ›)
å¯¹äºä»»æ„ç¼–ç¨‹è¯­è¨€ $L$ï¼Œå…¶è¡¨è¾¾èƒ½åŠ›æ»¡è¶³ï¼š
$$Expressiveness(L) \subseteq \text{ComputableFunctions}$$

**è¯æ˜**:
1. è®¾ $f$ ä¸ºè¯­è¨€ $L$ å¯è®¡ç®—çš„å‡½æ•°
2. æ ¹æ®å›¾çµå®Œå¤‡æ€§ï¼Œå­˜åœ¨å›¾çµæœº $M$ è®¡ç®— $f$
3. å› æ­¤ $f \in \text{ComputableFunctions}$
4. æ‰€ä»¥ $Expressiveness(L) \subseteq \text{ComputableFunctions}$

### å®šç† 1.2 (è¯­è¨€æ€ç»´æ˜ å°„çš„å•è°ƒæ€§)
å¯¹äºè¯­è¨€ $L_1, L_2$ï¼Œå¦‚æœ $L_1 \subseteq L_2$ï¼Œåˆ™ï¼š
$$ThinkingPower(L_1) \leq ThinkingPower(L_2)$$

**è¯æ˜**:
1. è®¾ $L_1 \subseteq L_2$
2. å¯¹äºä»»æ„æ€ç»´æ¨¡å¼ $T$ï¼Œæœ‰ $M(L_1, T) \subseteq M(L_2, T)$
3. å› æ­¤ $|M(L_1, T)| \leq |M(L_2, T)|$
4. æ‰€ä»¥ $ThinkingPower(L_1) \leq ThinkingPower(L_2)$

## ğŸ¯ åº”ç”¨å®ä¾‹

### 1. ç¼–ç¨‹è¯­è¨€è®¾è®¡
- åŸºäºå“²å­¦åŸç†è®¾è®¡æ–°è¯­è¨€
- ä¼˜åŒ–è¯­è¨€è¡¨è¾¾èƒ½åŠ›
- æ”¹è¿›æ€ç»´æ˜ å°„å…³ç³»

### 2. ç¼–è¯‘å™¨å¼€å‘
- å®ç°å½¢å¼åŒ–è¯­æ³•åˆ†æ
- æ„å»ºè¯­ä¹‰è§£é‡Šç³»ç»Ÿ
- ä¼˜åŒ–ä»£ç ç”Ÿæˆ

### 3. æ•™è‚²åº”ç”¨
- ç¼–ç¨‹æ€ç»´åŸ¹å…»
- è¯­è¨€å­¦ä¹ æŒ‡å¯¼
- æ¦‚å¿µç†è§£æ·±åŒ–

## ğŸ”— ç›¸å…³é“¾æ¥

- [å›¾çµå®Œå¤‡æ€§](00-01-02-å›¾çµå®Œå¤‡æ€§.md)
- [æŠ½è±¡å±‚æ¬¡ç†è®º](00-01-03-æŠ½è±¡å±‚æ¬¡ç†è®º.md)
- [ç±»å‹ç³»ç»Ÿå“²å­¦](00-01-04-ç±»å‹ç³»ç»Ÿå“²å­¦.md)
- [å½¢å¼åŒ–æ€ç»´](../00-02-å½¢å¼åŒ–æ€ç»´/README.md)

---

*ç¼–ç¨‹è¯­è¨€å“²å­¦ä¸ºç†è§£ç¼–ç¨‹è¯­è¨€çš„æœ¬è´¨æä¾›äº†æ·±å±‚çš„ç†è®ºåŸºç¡€ï¼Œé€šè¿‡å½¢å¼åŒ–çš„æ–¹æ³•å’Œå¤šè¡¨å¾çš„è¡¨è¾¾ï¼Œå¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£è¯­è¨€ä¸æ€ç»´çš„å…³ç³»ï¼Œä¸ºç¼–ç¨‹è¯­è¨€çš„è®¾è®¡å’Œä½¿ç”¨æä¾›æŒ‡å¯¼ã€‚*
