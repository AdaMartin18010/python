# 数据架构设计

## 概述

数据架构是系统架构的核心组成部分，定义了数据的组织、存储、访问和处理方式。本文档从理论到实践，全面阐述数据架构的设计原理和方法。

## 1. 数据架构理论基础

### 1.1 数据架构定义

**定义 1.1.1 (数据架构)**
数据架构 $DA$ 是一个五元组 $(D, S, A, P, M)$，其中：

- $D = \{d_1, d_2, ..., d_n\}$ 是数据实体集合
- $S = \{s_1, s_2, ..., s_m\}$ 是存储系统集合
- $A = \{a_1, a_2, ..., a_k\}$ 是访问模式集合
- $P = \{p_1, p_2, ..., p_l\}$ 是处理流程集合
- $M = \{m_1, m_2, ..., m_q\}$ 是元数据集合

**定义 1.1.2 (数据实体)**
数据实体 $d$ 是一个三元组 $(N, A, R)$，其中：

- $N$ 是实体名称
- $A = \{a_1, a_2, ..., a_p\}$ 是属性集合
- $R = \{r_1, r_2, ..., r_q\}$ 是关系集合

### 1.2 数据模型理论

**定义 1.2.1 (关系模型)**
关系模型 $RM$ 是一个二元组 $(T, C)$，其中：

- $T = \{t_1, t_2, ..., t_n\}$ 是表集合
- $C = \{c_1, c_2, ..., c_m\}$ 是约束集合

**定义 1.2.2 (文档模型)**
文档模型 $DM$ 是一个三元组 $(C, S, I)$，其中：

- $C$ 是集合 (Collection)
- $S$ 是模式 (Schema)
- $I$ 是索引 (Index)

## 2. 数据架构设计方法

### 2.1 关系型数据架构

**Python实现**：

```python
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Set
from dataclasses import dataclass, field
from datetime import datetime
import asyncio
import sqlite3
from enum import Enum

class DataType(Enum):
    """数据类型枚举"""
    INTEGER = "INTEGER"
    TEXT = "TEXT"
    REAL = "REAL"
    BLOB = "BLOB"
    BOOLEAN = "BOOLEAN"
    DATETIME = "DATETIME"

class ConstraintType(Enum):
    """约束类型枚举"""
    PRIMARY_KEY = "PRIMARY KEY"
    FOREIGN_KEY = "FOREIGN KEY"
    UNIQUE = "UNIQUE"
    NOT_NULL = "NOT NULL"
    CHECK = "CHECK"

@dataclass
class Column:
    """列定义"""
    name: str
    data_type: DataType
    constraints: List[ConstraintType] = field(default_factory=list)
    default_value: Optional[Any] = None
    description: str = ""

@dataclass
class Table:
    """表定义"""
    name: str
    columns: List[Column]
    primary_key: Optional[str] = None
    foreign_keys: Dict[str, str] = field(default_factory=dict)
    indexes: List[str] = field(default_factory=list)
    description: str = ""

class RelationalDataArchitecture:
    """关系型数据架构"""
    
    def __init__(self, name: str):
        self.name = name
        self.tables: Dict[str, Table] = {}
        self.relationships: Dict[str, List[str]] = {}
        
    def add_table(self, table: Table) -> None:
        """添加表"""
        self.tables[table.name] = table
        
    def add_relationship(self, from_table: str, to_table: str, relationship_type: str) -> None:
        """添加关系"""
        if from_table not in self.relationships:
            self.relationships[from_table] = []
        self.relationships[from_table].append((to_table, relationship_type))
        
    def generate_sql_schema(self) -> str:
        """生成SQL模式"""
        sql_statements = []
        
        for table_name, table in self.tables.items():
            # 创建表语句
            columns = []
            for column in table.columns:
                column_def = f"{column.name} {column.data_type.value}"
                
                # 添加约束
                for constraint in column.constraints:
                    if constraint == ConstraintType.PRIMARY_KEY:
                        column_def += " PRIMARY KEY"
                    elif constraint == ConstraintType.NOT_NULL:
                        column_def += " NOT NULL"
                    elif constraint == ConstraintType.UNIQUE:
                        column_def += " UNIQUE"
                
                if column.default_value is not None:
                    column_def += f" DEFAULT {column.default_value}"
                
                columns.append(column_def)
            
            # 添加外键约束
            for fk_column, ref_table in table.foreign_keys.items():
                columns.append(f"FOREIGN KEY ({fk_column}) REFERENCES {ref_table}(id)")
            
            create_table_sql = f"""
            CREATE TABLE {table_name} (
                {', '.join(columns)}
            );
            """
            sql_statements.append(create_table_sql)
            
            # 创建索引
            for index_column in table.indexes:
                index_sql = f"CREATE INDEX idx_{table_name}_{index_column} ON {table_name}({index_column});"
                sql_statements.append(index_sql)
        
        return '\n'.join(sql_statements)
    
    def calculate_normalization_level(self) -> Dict[str, float]:
        """计算规范化级别"""
        normalization_scores = {}
        
        for table_name, table in self.tables.items():
            # 简化的规范化评估
            total_columns = len(table.columns)
            functional_dependencies = self._count_functional_dependencies(table)
            
            # 1NF: 确保原子性
            first_nf_score = self._check_first_nf(table)
            
            # 2NF: 消除部分依赖
            second_nf_score = self._check_second_nf(table)
            
            # 3NF: 消除传递依赖
            third_nf_score = self._check_third_nf(table)
            
            normalization_scores[table_name] = {
                '1NF': first_nf_score,
                '2NF': second_nf_score,
                '3NF': third_nf_score,
                'overall': (first_nf_score + second_nf_score + third_nf_score) / 3
            }
        
        return normalization_scores
    
    def _check_first_nf(self, table: Table) -> float:
        """检查1NF"""
        # 简化的1NF检查：确保所有列都是原子的
        atomic_columns = 0
        for column in table.columns:
            if column.data_type in [DataType.TEXT, DataType.INTEGER, DataType.REAL]:
                atomic_columns += 1
        
        return atomic_columns / len(table.columns) if table.columns else 0
    
    def _check_second_nf(self, table: Table) -> float:
        """检查2NF"""
        # 简化的2NF检查：检查是否有复合主键
        if table.primary_key and ',' in table.primary_key:
            # 有复合主键，需要检查部分依赖
            return 0.8
        else:
            # 单主键，满足2NF
            return 1.0
    
    def _check_third_nf(self, table: Table) -> float:
        """检查3NF"""
        # 简化的3NF检查：检查传递依赖
        # 这里假设没有明显的传递依赖
        return 0.9
    
    def _count_functional_dependencies(self, table: Table) -> int:
        """计算函数依赖数量"""
        # 简化的函数依赖计算
        return len(table.columns) - 1 if table.primary_key else len(table.columns)

# 使用示例
def create_ecommerce_relational_architecture() -> RelationalDataArchitecture:
    """创建电商关系型数据架构"""
    architecture = RelationalDataArchitecture("E-commerce Relational")
    
    # 用户表
    user_table = Table(
        name="users",
        columns=[
            Column("id", DataType.INTEGER, [ConstraintType.PRIMARY_KEY]),
            Column("username", DataType.TEXT, [ConstraintType.UNIQUE, ConstraintType.NOT_NULL]),
            Column("email", DataType.TEXT, [ConstraintType.UNIQUE, ConstraintType.NOT_NULL]),
            Column("password_hash", DataType.TEXT, [ConstraintType.NOT_NULL]),
            Column("created_at", DataType.DATETIME, [ConstraintType.NOT_NULL]),
            Column("updated_at", DataType.DATETIME, [ConstraintType.NOT_NULL])
        ],
        primary_key="id",
        indexes=["username", "email"],
        description="用户信息表"
    )
    
    # 产品表
    product_table = Table(
        name="products",
        columns=[
            Column("id", DataType.INTEGER, [ConstraintType.PRIMARY_KEY]),
            Column("name", DataType.TEXT, [ConstraintType.NOT_NULL]),
            Column("description", DataType.TEXT),
            Column("price", DataType.REAL, [ConstraintType.NOT_NULL]),
            Column("stock", DataType.INTEGER, [ConstraintType.NOT_NULL]),
            Column("category_id", DataType.INTEGER, [ConstraintType.NOT_NULL]),
            Column("created_at", DataType.DATETIME, [ConstraintType.NOT_NULL]),
            Column("updated_at", DataType.DATETIME, [ConstraintType.NOT_NULL])
        ],
        primary_key="id",
        foreign_keys={"category_id": "categories(id)"},
        indexes=["name", "category_id"],
        description="产品信息表"
    )
    
    # 订单表
    order_table = Table(
        name="orders",
        columns=[
            Column("id", DataType.INTEGER, [ConstraintType.PRIMARY_KEY]),
            Column("user_id", DataType.INTEGER, [ConstraintType.NOT_NULL]),
            Column("total_amount", DataType.REAL, [ConstraintType.NOT_NULL]),
            Column("status", DataType.TEXT, [ConstraintType.NOT_NULL]),
            Column("created_at", DataType.DATETIME, [ConstraintType.NOT_NULL]),
            Column("updated_at", DataType.DATETIME, [ConstraintType.NOT_NULL])
        ],
        primary_key="id",
        foreign_keys={"user_id": "users(id)"},
        indexes=["user_id", "status", "created_at"],
        description="订单表"
    )
    
    architecture.add_table(user_table)
    architecture.add_table(product_table)
    architecture.add_table(order_table)
    
    return architecture
```

### 2.2 NoSQL数据架构

**Python实现**：

```python
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, field
from datetime import datetime
import json
import asyncio
from enum import Enum

class NoSQLType(Enum):
    """NoSQL类型枚举"""
    DOCUMENT = "document"
    KEY_VALUE = "key_value"
    COLUMN_FAMILY = "column_family"
    GRAPH = "graph"

@dataclass
class DocumentSchema:
    """文档模式定义"""
    collection_name: str
    fields: Dict[str, Any]
    indexes: List[str] = field(default_factory=list)
    validation_rules: Dict[str, Any] = field(default_factory=dict)

@dataclass
class KeyValueStore:
    """键值存储定义"""
    name: str
    key_pattern: str
    value_type: str
    ttl: Optional[int] = None
    compression: bool = False

class NoSQLDataArchitecture:
    """NoSQL数据架构"""
    
    def __init__(self, name: str, nosql_type: NoSQLType):
        self.name = name
        self.nosql_type = nosql_type
        self.collections: Dict[str, DocumentSchema] = {}
        self.key_value_stores: Dict[str, KeyValueStore] = {}
        self.graph_nodes: Dict[str, List[str]] = {}
        self.graph_edges: Dict[str, List[str]] = {}
        
    def add_document_collection(self, schema: DocumentSchema) -> None:
        """添加文档集合"""
        if self.nosql_type == NoSQLType.DOCUMENT:
            self.collections[schema.collection_name] = schema
        else:
            raise ValueError("Only document databases support collections")
    
    def add_key_value_store(self, store: KeyValueStore) -> None:
        """添加键值存储"""
        if self.nosql_type == NoSQLType.KEY_VALUE:
            self.key_value_stores[store.name] = store
        else:
            raise ValueError("Only key-value databases support key-value stores")
    
    def add_graph_node(self, node_type: str, properties: List[str]) -> None:
        """添加图节点类型"""
        if self.nosql_type == NoSQLType.GRAPH:
            self.graph_nodes[node_type] = properties
        else:
            raise ValueError("Only graph databases support graph nodes")
    
    def add_graph_edge(self, edge_type: str, from_node: str, to_node: str, properties: List[str]) -> None:
        """添加图边类型"""
        if self.nosql_type == NoSQLType.GRAPH:
            edge_key = f"{edge_type}:{from_node}:{to_node}"
            self.graph_edges[edge_key] = properties
        else:
            raise ValueError("Only graph databases support graph edges")
    
    def generate_schema_definition(self) -> Dict[str, Any]:
        """生成模式定义"""
        schema = {
            "name": self.name,
            "type": self.nosql_type.value,
            "created_at": datetime.now().isoformat()
        }
        
        if self.nosql_type == NoSQLType.DOCUMENT:
            schema["collections"] = {
                name: {
                    "fields": collection.fields,
                    "indexes": collection.indexes,
                    "validation_rules": collection.validation_rules
                }
                for name, collection in self.collections.items()
            }
        elif self.nosql_type == NoSQLType.KEY_VALUE:
            schema["key_value_stores"] = {
                name: {
                    "key_pattern": store.key_pattern,
                    "value_type": store.value_type,
                    "ttl": store.ttl,
                    "compression": store.compression
                }
                for name, store in self.key_value_stores.items()
            }
        elif self.nosql_type == NoSQLType.GRAPH:
            schema["graph"] = {
                "nodes": self.graph_nodes,
                "edges": self.graph_edges
            }
        
        return schema
    
    def calculate_scalability_score(self) -> float:
        """计算可扩展性评分"""
        if self.nosql_type == NoSQLType.KEY_VALUE:
            return 0.95  # 键值存储通常具有最高的可扩展性
        elif self.nosql_type == NoSQLType.DOCUMENT:
            return 0.85  # 文档数据库具有良好的可扩展性
        elif self.nosql_type == NoSQLType.GRAPH:
            return 0.70  # 图数据库的可扩展性相对较低
        else:
            return 0.80
    
    def calculate_consistency_score(self) -> float:
        """计算一致性评分"""
        if self.nosql_type == NoSQLType.KEY_VALUE:
            return 0.90  # 键值存储通常提供强一致性
        elif self.nosql_type == NoSQLType.DOCUMENT:
            return 0.85  # 文档数据库提供良好的一致性
        elif self.nosql_type == NoSQLType.GRAPH:
            return 0.80  # 图数据库的一致性取决于实现
        else:
            return 0.75

# 使用示例
def create_document_database_architecture() -> NoSQLDataArchitecture:
    """创建文档数据库架构"""
    architecture = NoSQLDataArchitecture("E-commerce Document DB", NoSQLType.DOCUMENT)
    
    # 用户集合
    user_schema = DocumentSchema(
        collection_name="users",
        fields={
            "_id": "ObjectId",
            "username": "string",
            "email": "string",
            "profile": {
                "first_name": "string",
                "last_name": "string",
                "phone": "string",
                "address": {
                    "street": "string",
                    "city": "string",
                    "country": "string",
                    "postal_code": "string"
                }
            },
            "preferences": {
                "language": "string",
                "currency": "string",
                "notifications": {
                    "email": "boolean",
                    "sms": "boolean",
                    "push": "boolean"
                }
            },
            "created_at": "datetime",
            "updated_at": "datetime"
        },
        indexes=["username", "email", "profile.address.city"],
        validation_rules={
            "username": {"type": "string", "minLength": 3, "maxLength": 50},
            "email": {"type": "string", "format": "email"},
            "profile.first_name": {"type": "string", "required": True}
        }
    )
    
    # 产品集合
    product_schema = DocumentSchema(
        collection_name="products",
        fields={
            "_id": "ObjectId",
            "name": "string",
            "description": "string",
            "price": {
                "amount": "decimal",
                "currency": "string"
            },
            "category": {
                "id": "ObjectId",
                "name": "string",
                "path": "array"
            },
            "attributes": {
                "brand": "string",
                "model": "string",
                "color": "array",
                "size": "array"
            },
            "inventory": {
                "stock": "integer",
                "reserved": "integer",
                "available": "integer"
            },
            "images": "array",
            "tags": "array",
            "created_at": "datetime",
            "updated_at": "datetime"
        },
        indexes=["name", "category.id", "attributes.brand", "tags"],
        validation_rules={
            "name": {"type": "string", "required": True},
            "price.amount": {"type": "number", "minimum": 0},
            "inventory.stock": {"type": "integer", "minimum": 0}
        }
    )
    
    architecture.add_document_collection(user_schema)
    architecture.add_document_collection(product_schema)
    
    return architecture

def create_key_value_architecture() -> NoSQLDataArchitecture:
    """创建键值存储架构"""
    architecture = NoSQLDataArchitecture("E-commerce Cache", NoSQLType.KEY_VALUE)
    
    # 用户会话存储
    session_store = KeyValueStore(
        name="user_sessions",
        key_pattern="session:{user_id}",
        value_type="json",
        ttl=3600,  # 1小时过期
        compression=True
    )
    
    # 产品缓存
    product_cache = KeyValueStore(
        name="product_cache",
        key_pattern="product:{product_id}",
        value_type="json",
        ttl=1800,  # 30分钟过期
        compression=True
    )
    
    # 购物车存储
    cart_store = KeyValueStore(
        name="shopping_carts",
        key_pattern="cart:{user_id}",
        value_type="json",
        ttl=86400,  # 24小时过期
        compression=False
    )
    
    architecture.add_key_value_store(session_store)
    architecture.add_key_value_store(product_cache)
    architecture.add_key_value_store(cart_store)
    
    return architecture
```

### 2.3 数据仓库架构

**Python实现**：

```python
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import asyncio

class DataWarehouseLayer(Enum):
    """数据仓库层次枚举"""
    STAGING = "staging"
    DATA_WAREHOUSE = "data_warehouse"
    DATA_MART = "data_mart"
    ODS = "operational_data_store"

class ETLProcessType(Enum):
    """ETL过程类型枚举"""
    EXTRACT = "extract"
    TRANSFORM = "transform"
    LOAD = "load"

@dataclass
class DataSource:
    """数据源定义"""
    name: str
    type: str  # "database", "file", "api", "stream"
    connection_string: str
    schema: Dict[str, Any]
    refresh_frequency: timedelta
    last_refresh: Optional[datetime] = None

@dataclass
class DataTable:
    """数据表定义"""
    name: str
    layer: DataWarehouseLayer
    columns: List[Dict[str, Any]]
    primary_key: Optional[str] = None
    partition_key: Optional[str] = None
    clustering_keys: List[str] = field(default_factory=list)
    refresh_schedule: Optional[str] = None

@dataclass
class ETLProcess:
    """ETL过程定义"""
    name: str
    process_type: ETLProcessType
    source_tables: List[str]
    target_table: str
    transformation_rules: Dict[str, Any]
    schedule: str
    enabled: bool = True

class DataWarehouseArchitecture:
    """数据仓库架构"""
    
    def __init__(self, name: str):
        self.name = name
        self.data_sources: Dict[str, DataSource] = {}
        self.tables: Dict[str, DataTable] = {}
        self.etl_processes: Dict[str, ETLProcess] = {}
        self.data_flows: Dict[str, List[str]] = {}
        
    def add_data_source(self, source: DataSource) -> None:
        """添加数据源"""
        self.data_sources[source.name] = source
        
    def add_table(self, table: DataTable) -> None:
        """添加数据表"""
        self.tables[table.name] = table
        
    def add_etl_process(self, process: ETLProcess) -> None:
        """添加ETL过程"""
        self.etl_processes[process.name] = process
        
    def add_data_flow(self, from_table: str, to_table: str) -> None:
        """添加数据流"""
        if from_table not in self.data_flows:
            self.data_flows[from_table] = []
        self.data_flows[from_table].append(to_table)
        
    def generate_data_lineage(self) -> Dict[str, Any]:
        """生成数据血缘"""
        lineage = {
            "sources": {},
            "tables": {},
            "flows": self.data_flows
        }
        
        # 数据源血缘
        for source_name, source in self.data_sources.items():
            lineage["sources"][source_name] = {
                "type": source.type,
                "refresh_frequency": str(source.refresh_frequency),
                "last_refresh": source.last_refresh.isoformat() if source.last_refresh else None
            }
        
        # 表血缘
        for table_name, table in self.tables.items():
            lineage["tables"][table_name] = {
                "layer": table.layer.value,
                "columns": len(table.columns),
                "refresh_schedule": table.refresh_schedule
            }
        
        return lineage
    
    def calculate_data_freshness(self) -> Dict[str, float]:
        """计算数据新鲜度"""
        freshness_scores = {}
        
        for table_name, table in self.tables.items():
            # 简化的新鲜度计算
            if table.refresh_schedule:
                # 根据刷新频率计算新鲜度
                if "hourly" in table.refresh_schedule:
                    freshness_scores[table_name] = 0.95
                elif "daily" in table.refresh_schedule:
                    freshness_scores[table_name] = 0.85
                elif "weekly" in table.refresh_schedule:
                    freshness_scores[table_name] = 0.70
                else:
                    freshness_scores[table_name] = 0.60
            else:
                freshness_scores[table_name] = 0.50
        
        return freshness_scores
    
    def calculate_data_quality_score(self) -> Dict[str, float]:
        """计算数据质量评分"""
        quality_scores = {}
        
        for table_name, table in self.tables.items():
            # 简化的数据质量计算
            score = 0.0
            
            # 完整性检查
            if table.primary_key:
                score += 0.3
            
            # 规范化检查
            if table.layer == DataWarehouseLayer.DATA_WAREHOUSE:
                score += 0.3
            elif table.layer == DataWarehouseLayer.DATA_MART:
                score += 0.2
            
            # 索引检查
            if table.clustering_keys:
                score += 0.2
            
            # 分区检查
            if table.partition_key:
                score += 0.2
            
            quality_scores[table_name] = min(score, 1.0)
        
        return quality_scores

# 使用示例
def create_ecommerce_data_warehouse() -> DataWarehouseArchitecture:
    """创建电商数据仓库架构"""
    architecture = DataWarehouseArchitecture("E-commerce Data Warehouse")
    
    # 数据源
    order_source = DataSource(
        name="order_system",
        type="database",
        connection_string="postgresql://orders:5432/orders",
        schema={"orders": ["id", "user_id", "total_amount", "status", "created_at"]},
        refresh_frequency=timedelta(hours=1)
    )
    
    user_source = DataSource(
        name="user_system",
        type="database",
        connection_string="postgresql://users:5432/users",
        schema={"users": ["id", "username", "email", "created_at"]},
        refresh_frequency=timedelta(hours=2)
    )
    
    # 数据表
    staging_orders = DataTable(
        name="staging_orders",
        layer=DataWarehouseLayer.STAGING,
        columns=[
            {"name": "id", "type": "integer"},
            {"name": "user_id", "type": "integer"},
            {"name": "total_amount", "type": "decimal"},
            {"name": "status", "type": "string"},
            {"name": "created_at", "type": "datetime"}
        ],
        refresh_schedule="hourly"
    )
    
    dim_users = DataTable(
        name="dim_users",
        layer=DataWarehouseLayer.DATA_WAREHOUSE,
        columns=[
            {"name": "user_id", "type": "integer"},
            {"name": "username", "type": "string"},
            {"name": "email", "type": "string"},
            {"name": "registration_date", "type": "date"},
            {"name": "is_active", "type": "boolean"}
        ],
        primary_key="user_id",
        refresh_schedule="daily"
    )
    
    fact_orders = DataTable(
        name="fact_orders",
        layer=DataWarehouseLayer.DATA_WAREHOUSE,
        columns=[
            {"name": "order_id", "type": "integer"},
            {"name": "user_id", "type": "integer"},
            {"name": "order_date", "type": "date"},
            {"name": "total_amount", "type": "decimal"},
            {"name": "order_status", "type": "string"}
        ],
        primary_key="order_id",
        partition_key="order_date",
        clustering_keys=["user_id", "order_status"],
        refresh_schedule="hourly"
    )
    
    # ETL过程
    extract_orders = ETLProcess(
        name="extract_orders",
        process_type=ETLProcessType.EXTRACT,
        source_tables=["order_system.orders"],
        target_table="staging_orders",
        transformation_rules={},
        schedule="0 * * * *"  # 每小时
    )
    
    transform_orders = ETLProcess(
        name="transform_orders",
        process_type=ETLProcessType.TRANSFORM,
        source_tables=["staging_orders"],
        target_table="fact_orders",
        transformation_rules={
            "order_date": "DATE(created_at)",
            "order_status": "UPPER(status)"
        },
        schedule="15 * * * *"  # 每小时15分
    )
    
    architecture.add_data_source(order_source)
    architecture.add_data_source(user_source)
    architecture.add_table(staging_orders)
    architecture.add_table(dim_users)
    architecture.add_table(fact_orders)
    architecture.add_etl_process(extract_orders)
    architecture.add_etl_process(transform_orders)
    
    # 数据流
    architecture.add_data_flow("order_system.orders", "staging_orders")
    architecture.add_data_flow("staging_orders", "fact_orders")
    architecture.add_data_flow("user_system.users", "dim_users")
    
    return architecture
```

## 3. 数据架构评估

### 3.1 数据质量评估

**定义 3.1.1 (数据质量)**
数据质量 $DQ$ 是一个多维度的评估指标：
$$DQ = \sum_{i=1}^{n} w_i \cdot q_i$$
其中 $q_i$ 是第 $i$ 个质量维度，$w_i$ 是权重。

**Python实现**：

```python
from typing import Dict, List, Any
import numpy as np
from dataclasses import dataclass

@dataclass
class DataQualityMetric:
    """数据质量指标"""
    name: str
    weight: float
    score: float
    description: str

class DataQualityEvaluator:
    """数据质量评估器"""
    
    def __init__(self):
        self.metrics: Dict[str, DataQualityMetric] = {}
        
    def add_metric(self, metric: DataQualityMetric) -> None:
        """添加质量指标"""
        self.metrics[metric.name] = metric
        
    def calculate_overall_quality(self) -> float:
        """计算总体质量评分"""
        total_score = 0.0
        total_weight = 0.0
        
        for metric in self.metrics.values():
            total_score += metric.weight * metric.score
            total_weight += metric.weight
        
        return total_score / total_weight if total_weight > 0 else 0.0
    
    def generate_quality_report(self) -> Dict[str, Any]:
        """生成质量报告"""
        report = {
            "overall_score": self.calculate_overall_quality(),
            "metrics": {},
            "recommendations": []
        }
        
        for name, metric in self.metrics.items():
            report["metrics"][name] = {
                "score": metric.score,
                "weight": metric.weight,
                "description": metric.description
            }
            
            # 生成建议
            if metric.score < 0.7:
                report["recommendations"].append(
                    f"Improve {name}: {metric.description}"
                )
        
        return report

# 使用示例
def evaluate_data_quality():
    """评估数据质量示例"""
    evaluator = DataQualityEvaluator()
    
    # 添加质量指标
    evaluator.add_metric(DataQualityMetric(
        name="completeness",
        weight=0.3,
        score=0.85,
        description="数据完整性"
    ))
    
    evaluator.add_metric(DataQualityMetric(
        name="accuracy",
        weight=0.25,
        score=0.92,
        description="数据准确性"
    ))
    
    evaluator.add_metric(DataQualityMetric(
        name="consistency",
        weight=0.2,
        score=0.78,
        description="数据一致性"
    ))
    
    evaluator.add_metric(DataQualityMetric(
        name="timeliness",
        weight=0.15,
        score=0.88,
        description="数据及时性"
    ))
    
    evaluator.add_metric(DataQualityMetric(
        name="validity",
        weight=0.1,
        score=0.95,
        description="数据有效性"
    ))
    
    # 生成报告
    report = evaluator.generate_quality_report()
    
    print("数据质量评估报告:")
    print(f"总体评分: {report['overall_score']:.4f}")
    print("\n详细指标:")
    for name, metric in report['metrics'].items():
        print(f"{name}: {metric['score']:.4f} (权重: {metric['weight']})")
    
    if report['recommendations']:
        print("\n改进建议:")
        for recommendation in report['recommendations']:
            print(f"- {recommendation}")
    
    return report
```

## 4. 总结

数据架构设计是系统架构的核心组成部分。本文档从理论到实践，提供了完整的数据架构设计方法：

1. **理论基础**：建立了数据架构的形式化定义和模型理论
2. **设计方法**：提供了关系型、NoSQL、数据仓库等架构模式的具体实现
3. **评估方法**：建立了数据质量评估框架

通过这种系统化的方法，可以设计出高质量、高性能、可扩展的数据架构。

---

**相关文档**：

- [01-系统架构.md](./01-系统架构.md)
- [02-应用架构.md](./02-应用架构.md)
- [04-行业领域/01-金融科技领域.md](../04-行业领域/01-金融科技领域.md)
