# CI/CD基础

## 📋 概述

CI/CD（持续集成/持续部署）是现代软件开发的核心理念，通过自动化流程实现代码的快速、可靠、频繁的集成和部署。

## 🎯 核心概念

### 持续集成 (Continuous Integration)

**定义**：持续集成是一种开发实践，要求开发人员频繁地将代码集成到主干分支，每次集成都通过自动化构建和测试验证。

**数学表示**：
$$CI(S, T, B) = \{s \in S | \forall t \in T, B(s, t) = \text{success}\}$$

其中：

- $S$ 是代码提交集合
- $T$ 是测试集合
- $B$ 是构建函数

### 持续部署 (Continuous Deployment)

**定义**：持续部署是持续集成的延伸，将通过所有测试的代码自动部署到生产环境。

**数学表示**：
$$CD(CI\_Result, E) = \begin{cases}
\text{deploy} & \text{if } CI\_Result = \text{success} \land E = \text{ready} \\
\text{hold} & \text{otherwise}
\end{cases}$$

其中 $E$ 是环境就绪状态。

## 🔧 Python实现

### CI/CD流水线框架

```python
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, field
from enum import Enum
import asyncio
import json
import logging
from datetime import datetime
import subprocess
import os
import yaml

# 流水线状态
class PipelineStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILED = "failed"
    CANCELLED = "cancelled"

# 阶段状态
class StageStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILED = "failed"
    SKIPPED = "skipped"

# 流水线配置
@dataclass
class PipelineConfig:
    name: str
    version: str
    stages: List[str]
    triggers: List[str] = field(default_factory=list)
    timeout: int = 3600  # 1小时
    parallel_stages: List[str] = field(default_factory=list)
    environment_variables: Dict[str, str] = field(default_factory=dict)

# 流水线执行上下文
@dataclass
class PipelineContext:
    pipeline_id: str
    commit_hash: str
    branch: str
    author: str
    timestamp: datetime
    variables: Dict[str, Any] = field(default_factory=dict)
    artifacts: Dict[str, str] = field(default_factory=dict)

# 流水线阶段
class PipelineStage(ABC):
    """流水线阶段抽象基类"""

    def __init__(self, name: str, config: Dict[str, Any]):
        self.name = name
        self.config = config
        self.status = StageStatus.PENDING
        self.start_time: Optional[datetime] = None
        self.end_time: Optional[datetime] = None
        self.logger = logging.getLogger(f"pipeline.stage.{name}")

    @abstractmethod
    async def execute(self, context: PipelineContext) -> bool:
        """执行阶段"""
        pass

    def get_duration(self) -> Optional[float]:
        """获取执行时长"""
        if self.start_time and self.end_time:
            return (self.end_time - self.start_time).total_seconds()
        return None

# 代码检出阶段
class CheckoutStage(PipelineStage):
    """代码检出阶段"""

    async def execute(self, context: PipelineContext) -> bool:
        """执行代码检出"""
        self.status = StageStatus.RUNNING
        self.start_time = datetime.now()

        try:
            repo_url = self.config.get("repository_url")
            branch = context.branch

            # 执行git clone
            cmd = f"git clone -b {branch} {repo_url} ."
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)

            if result.returncode == 0:
                self.status = StageStatus.SUCCESS
                self.logger.info(f"Code checkout successful: {branch}")
                return True
            else:
                self.status = StageStatus.FAILED
                self.logger.error(f"Code checkout failed: {result.stderr}")
                return False

        except Exception as e:
            self.status = StageStatus.FAILED
            self.logger.error(f"Code checkout error: {e}")
            return False
        finally:
            self.end_time = datetime.now()

# 构建阶段
class BuildStage(PipelineStage):
    """构建阶段"""

    async def execute(self, context: PipelineContext) -> bool:
        """执行构建"""
        self.status = StageStatus.RUNNING
        self.start_time = datetime.now()

        try:
            build_command = self.config.get("build_command", "make build")
            build_args = self.config.get("build_args", [])

            # 执行构建命令
            cmd = [build_command] + build_args
            result = subprocess.run(cmd, capture_output=True, text=True)

            if result.returncode == 0:
                self.status = StageStatus.SUCCESS
                self.logger.info("Build successful")

                # 保存构建产物
                artifact_path = self.config.get("artifact_path")
                if artifact_path and os.path.exists(artifact_path):
                    context.artifacts["build"] = artifact_path

                return True
            else:
                self.status = StageStatus.FAILED
                self.logger.error(f"Build failed: {result.stderr}")
                return False

        except Exception as e:
            self.status = StageStatus.FAILED
            self.logger.error(f"Build error: {e}")
            return False
        finally:
            self.end_time = datetime.now()

# 测试阶段
class TestStage(PipelineStage):
    """测试阶段"""

    async def execute(self, context: PipelineContext) -> bool:
        """执行测试"""
        self.status = StageStatus.RUNNING
        self.start_time = datetime.now()

        try:
            test_command = self.config.get("test_command", "pytest")
            test_args = self.config.get("test_args", [])
            coverage_threshold = self.config.get("coverage_threshold", 80.0)

            # 执行测试命令
            cmd = [test_command] + test_args
            result = subprocess.run(cmd, capture_output=True, text=True)

            if result.returncode == 0:
                # 检查覆盖率
                coverage_result = self._check_coverage(coverage_threshold)
                if coverage_result:
                    self.status = StageStatus.SUCCESS
                    self.logger.info("Tests passed with coverage threshold")
                    return True
                else:
                    self.status = StageStatus.FAILED
                    self.logger.error("Coverage threshold not met")
                    return False
            else:
                self.status = StageStatus.FAILED
                self.logger.error(f"Tests failed: {result.stderr}")
                return False

        except Exception as e:
            self.status = StageStatus.FAILED
            self.logger.error(f"Test error: {e}")
            return False
        finally:
            self.end_time = datetime.now()

    def _check_coverage(self, threshold: float) -> bool:
        """检查测试覆盖率"""
        try:
            # 这里应该实现具体的覆盖率检查逻辑
            # 例如解析coverage.xml文件
            return True  # 简化实现
        except Exception as e:
            self.logger.error(f"Coverage check error: {e}")
            return False

# 代码质量检查阶段
class CodeQualityStage(PipelineStage):
    """代码质量检查阶段"""

    async def execute(self, context: PipelineContext) -> bool:
        """执行代码质量检查"""
        self.status = StageStatus.RUNNING
        self.start_time = datetime.now()

        try:
            quality_tools = self.config.get("tools", ["flake8", "pylint"])
            max_score = self.config.get("max_score", 8.0)

            all_passed = True

            for tool in quality_tools:
                if tool == "flake8":
                    result = subprocess.run(["flake8", "."], capture_output=True, text=True)
                    if result.returncode != 0:
                        self.logger.warning(f"Flake8 issues found: {result.stdout}")
                        all_passed = False

                elif tool == "pylint":
                    result = subprocess.run(["pylint", "--score=y", "."], capture_output=True, text=True)
                    if result.returncode != 0:
                        # 解析pylint分数
                        score_line = [line for line in result.stdout.split('\n') if 'Your code has been rated at' in line]
                        if score_line:
                            score = float(score_line[0].split()[-2])
                            if score < max_score:
                                self.logger.warning(f"Pylint score {score} below threshold {max_score}")
                                all_passed = False

            if all_passed:
                self.status = StageStatus.SUCCESS
                self.logger.info("Code quality checks passed")
                return True
            else:
                self.status = StageStatus.FAILED
                self.logger.error("Code quality checks failed")
                return False

        except Exception as e:
            self.status = StageStatus.FAILED
            self.logger.error(f"Code quality check error: {e}")
            return False
        finally:
            self.end_time = datetime.now()

# 部署阶段
class DeployStage(PipelineStage):
    """部署阶段"""

    async def execute(self, context: PipelineContext) -> bool:
        """执行部署"""
        self.status = StageStatus.RUNNING
        self.start_time = datetime.now()

        try:
            environment = self.config.get("environment", "staging")
            deployment_strategy = self.config.get("strategy", "rolling")

            if deployment_strategy == "rolling":
                success = await self._rolling_deploy(environment, context)
            elif deployment_strategy == "blue_green":
                success = await self._blue_green_deploy(environment, context)
            else:
                success = await self._simple_deploy(environment, context)

            if success:
                self.status = StageStatus.SUCCESS
                self.logger.info(f"Deployment to {environment} successful")
                return True
            else:
                self.status = StageStatus.FAILED
                self.logger.error(f"Deployment to {environment} failed")
                return False

        except Exception as e:
            self.status = StageStatus.FAILED
            self.logger.error(f"Deployment error: {e}")
            return False
        finally:
            self.end_time = datetime.now()

    async def _rolling_deploy(self, environment: str, context: PipelineContext) -> bool:
        """滚动部署"""
        # 实现滚动部署逻辑
        self.logger.info(f"Performing rolling deployment to {environment}")
        await asyncio.sleep(5)  # 模拟部署时间
        return True

    async def _blue_green_deploy(self, environment: str, context: PipelineContext) -> bool:
        """蓝绿部署"""
        # 实现蓝绿部署逻辑
        self.logger.info(f"Performing blue-green deployment to {environment}")
        await asyncio.sleep(10)  # 模拟部署时间
        return True

    async def _simple_deploy(self, environment: str, context: PipelineContext) -> bool:
        """简单部署"""
        # 实现简单部署逻辑
        self.logger.info(f"Performing simple deployment to {environment}")
        await asyncio.sleep(3)  # 模拟部署时间
        return True

# 流水线执行器
class PipelineExecutor:
    """流水线执行器"""

    def __init__(self):
        self.stages: Dict[str, PipelineStage] = {}
        self.logger = logging.getLogger("pipeline_executor")

    def register_stage(self, stage: PipelineStage) -> None:
        """注册流水线阶段"""
        self.stages[stage.name] = stage
        self.logger.info(f"Stage registered: {stage.name}")

    async def execute_pipeline(self, config: PipelineConfig, context: PipelineContext) -> bool:
        """执行完整流水线"""
        self.logger.info(f"Starting pipeline: {config.name}")

        # 创建阶段实例
        stage_instances = self._create_stage_instances(config)

        # 执行阶段
        for stage_name in config.stages:
            if stage_name not in stage_instances:
                self.logger.error(f"Stage not found: {stage_name}")
                return False

            stage = stage_instances[stage_name]
            self.logger.info(f"Executing stage: {stage_name}")

            success = await stage.execute(context)
            if not success:
                self.logger.error(f"Stage failed: {stage_name}")
                return False

        self.logger.info(f"Pipeline completed successfully: {config.name}")
        return True

    def _create_stage_instances(self, config: PipelineConfig) -> Dict[str, PipelineStage]:
        """创建阶段实例"""
        instances = {}

        # 这里应该根据配置创建具体的阶段实例
        # 简化实现，实际应该从配置文件或数据库加载
        stage_configs = {
            "checkout": {"repository_url": "https://github.com/example/repo.git"},
            "build": {"build_command": "make", "build_args": ["build"]},
            "test": {"test_command": "pytest", "coverage_threshold": 80.0},
            "quality": {"tools": ["flake8", "pylint"], "max_score": 8.0},
            "deploy": {"environment": "staging", "strategy": "rolling"}
        }

        for stage_name in config.stages:
            if stage_name == "checkout":
                instances[stage_name] = CheckoutStage(stage_name, stage_configs.get(stage_name, {}))
            elif stage_name == "build":
                instances[stage_name] = BuildStage(stage_name, stage_configs.get(stage_name, {}))
            elif stage_name == "test":
                instances[stage_name] = TestStage(stage_name, stage_configs.get(stage_name, {}))
            elif stage_name == "quality":
                instances[stage_name] = CodeQualityStage(stage_name, stage_configs.get(stage_name, {}))
            elif stage_name == "deploy":
                instances[stage_name] = DeployStage(stage_name, stage_configs.get(stage_name, {}))

        return instances
```

### 流水线配置管理

```python
import yaml
from typing import Dict, Any, List
from pathlib import Path

class PipelineConfigManager:
    """流水线配置管理器"""

    def __init__(self, config_dir: str = "pipelines"):
        self.config_dir = Path(config_dir)
        self.config_dir.mkdir(exist_ok=True)

    def load_pipeline_config(self, pipeline_name: str) -> PipelineConfig:
        """加载流水线配置"""
        config_file = self.config_dir / f"{pipeline_name}.yml"

        if not config_file.exists():
            raise FileNotFoundError(f"Pipeline config not found: {config_file}")

        with open(config_file, 'r') as f:
            config_data = yaml.safe_load(f)

        return PipelineConfig(
            name=config_data["name"],
            version=config_data["version"],
            stages=config_data["stages"],
            triggers=config_data.get("triggers", []),
            timeout=config_data.get("timeout", 3600),
            parallel_stages=config_data.get("parallel_stages", []),
            environment_variables=config_data.get("environment_variables", {})
        )

    def save_pipeline_config(self, config: PipelineConfig) -> None:
        """保存流水线配置"""
        config_file = self.config_dir / f"{config.name}.yml"

        config_data = {
            "name": config.name,
            "version": config.version,
            "stages": config.stages,
            "triggers": config.triggers,
            "timeout": config.timeout,
            "parallel_stages": config.parallel_stages,
            "environment_variables": config.environment_variables
        }

        with open(config_file, 'w') as f:
            yaml.dump(config_data, f, default_flow_style=False)

    def list_pipelines(self) -> List[str]:
        """列出所有流水线"""
        return [f.stem for f in self.config_dir.glob("*.yml")]

# 示例配置文件
SAMPLE_PIPELINE_CONFIG = """
name: python-app-pipeline
version: "1.0"
stages:
  - checkout
  - build
  - test
  - quality
  - deploy
triggers:
  - push
  - pull_request
timeout: 3600
parallel_stages:
  - test
  - quality
environment_variables:
  PYTHON_VERSION: "3.11"
  NODE_VERSION: "18"
"""

# 创建示例配置
def create_sample_pipeline():
    """创建示例流水线配置"""
    config_manager = PipelineConfigManager()

    config = PipelineConfig(
        name="python-app-pipeline",
        version="1.0",
        stages=["checkout", "build", "test", "quality", "deploy"],
        triggers=["push", "pull_request"],
        timeout=3600,
        parallel_stages=["test", "quality"],
        environment_variables={
            "PYTHON_VERSION": "3.11",
            "NODE_VERSION": "18"
        }
    )

    config_manager.save_pipeline_config(config)
    print("Sample pipeline config created")
```

### 流水线监控和报告

```python
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import json

# 流水线执行记录
@dataclass
class PipelineExecution:
    pipeline_id: str
    pipeline_name: str
    status: PipelineStatus
    start_time: datetime
    end_time: Optional[datetime] = None
    duration: Optional[float] = None
    stages: List[Dict[str, Any]] = None
    variables: Dict[str, Any] = None

    def __post_init__(self):
        if self.stages is None:
            self.stages = []
        if self.variables is None:
            self.variables = {}

# 流水线监控器
class PipelineMonitor:
    """流水线监控器"""

    def __init__(self):
        self.executions: List[PipelineExecution] = []
        self.logger = logging.getLogger("pipeline_monitor")

    def record_execution(self, execution: PipelineExecution) -> None:
        """记录流水线执行"""
        self.executions.append(execution)
        self.logger.info(f"Pipeline execution recorded: {execution.pipeline_id}")

    def get_execution(self, pipeline_id: str) -> Optional[PipelineExecution]:
        """获取执行记录"""
        for execution in self.executions:
            if execution.pipeline_id == pipeline_id:
                return execution
        return None

    def get_recent_executions(self, hours: int = 24) -> List[PipelineExecution]:
        """获取最近的执行记录"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        return [
            execution for execution in self.executions
            if execution.start_time >= cutoff_time
        ]

    def get_success_rate(self, pipeline_name: Optional[str] = None, hours: int = 24) -> float:
        """获取成功率"""
        recent_executions = self.get_recent_executions(hours)

        if pipeline_name:
            recent_executions = [
                e for e in recent_executions
                if e.pipeline_name == pipeline_name
            ]

        if not recent_executions:
            return 0.0

        successful = sum(1 for e in recent_executions if e.status == PipelineStatus.SUCCESS)
        return successful / len(recent_executions)

    def get_average_duration(self, pipeline_name: Optional[str] = None, hours: int = 24) -> float:
        """获取平均执行时长"""
        recent_executions = self.get_recent_executions(hours)

        if pipeline_name:
            recent_executions = [
                e for e in recent_executions
                if e.pipeline_name == pipeline_name
            ]

        completed_executions = [
            e for e in recent_executions
            if e.duration is not None
        ]

        if not completed_executions:
            return 0.0

        return sum(e.duration for e in completed_executions) / len(completed_executions)

# 流水线报告生成器
class PipelineReporter:
    """流水线报告生成器"""

    def __init__(self, monitor: PipelineMonitor):
        self.monitor = monitor

    def generate_execution_report(self, pipeline_id: str) -> Dict[str, Any]:
        """生成执行报告"""
        execution = self.monitor.get_execution(pipeline_id)
        if not execution:
            return {"error": "Execution not found"}

        return {
            "pipeline_id": execution.pipeline_id,
            "pipeline_name": execution.pipeline_name,
            "status": execution.status.value,
            "start_time": execution.start_time.isoformat(),
            "end_time": execution.end_time.isoformat() if execution.end_time else None,
            "duration": execution.duration,
            "stages": execution.stages,
            "variables": execution.variables
        }

    def generate_summary_report(self, hours: int = 24) -> Dict[str, Any]:
        """生成汇总报告"""
        recent_executions = self.monitor.get_recent_executions(hours)

        if not recent_executions:
            return {"message": "No executions found"}

        # 按状态统计
        status_counts = {}
        for execution in recent_executions:
            status = execution.status.value
            status_counts[status] = status_counts.get(status, 0) + 1

        # 按流水线统计
        pipeline_stats = {}
        for execution in recent_executions:
            name = execution.pipeline_name
            if name not in pipeline_stats:
                pipeline_stats[name] = {
                    "total": 0,
                    "successful": 0,
                    "failed": 0,
                    "total_duration": 0
                }

            pipeline_stats[name]["total"] += 1
            if execution.status == PipelineStatus.SUCCESS:
                pipeline_stats[name]["successful"] += 1
            elif execution.status == PipelineStatus.FAILED:
                pipeline_stats[name]["failed"] += 1

            if execution.duration:
                pipeline_stats[name]["total_duration"] += execution.duration

        # 计算平均时长
        for name, stats in pipeline_stats.items():
            if stats["total"] > 0:
                stats["avg_duration"] = stats["total_duration"] / stats["total"]
                stats["success_rate"] = stats["successful"] / stats["total"]

        return {
            "period_hours": hours,
            "total_executions": len(recent_executions),
            "status_distribution": status_counts,
            "pipeline_statistics": pipeline_stats,
            "overall_success_rate": self.monitor.get_success_rate(hours=hours),
            "overall_avg_duration": self.monitor.get_average_duration(hours=hours)
        }
```

## 📊 性能指标

### 流水线效率

**构建时间**：$BuildTime = \sum_{i=1}^{n} t_i$，其中 $t_i$ 是第 $i$ 个阶段的执行时间。

**成功率**：$SuccessRate = \frac{Successful\_Builds}{Total\_Builds}$

**平均恢复时间**：$MTTR = \frac{\sum_{i=1}^{n} RecoveryTime_i}{n}$

### 部署频率

**部署频率**：$DeploymentFrequency = \frac{Deployments}{TimePeriod}$

**变更前置时间**：$LeadTime = CommitTime - DeploymentTime$

## 🛡️ 安全考虑

### 密钥管理

```python
import os
from cryptography.fernet import Fernet
import base64

class SecretManager:
    """密钥管理器"""

    def __init__(self, key_file: str = ".ci_secrets"):
        self.key_file = key_file
        self.cipher_suite = self._load_or_create_key()

    def _load_or_create_key(self) -> Fernet:
        """加载或创建加密密钥"""
        if os.path.exists(self.key_file):
            with open(self.key_file, 'rb') as f:
                key = f.read()
        else:
            key = Fernet.generate_key()
            with open(self.key_file, 'wb') as f:
                f.write(key)
        return Fernet(key)

    def encrypt_secret(self, secret: str) -> str:
        """加密密钥"""
        return self.cipher_suite.encrypt(secret.encode()).decode()

    def decrypt_secret(self, encrypted_secret: str) -> str:
        """解密密钥"""
        return self.cipher_suite.decrypt(encrypted_secret.encode()).decode()

    def get_environment_secret(self, secret_name: str) -> str:
        """获取环境变量中的密钥"""
        encrypted_value = os.environ.get(secret_name)
        if encrypted_value:
            return self.decrypt_secret(encrypted_value)
        return os.environ.get(secret_name, "")
```

### 访问控制

```python
class AccessControl:
    """访问控制"""

    def __init__(self):
        self.permissions = {
            "admin": ["read", "write", "execute", "delete"],
            "developer": ["read", "write", "execute"],
            "viewer": ["read"]
        }

    def check_permission(self, user_role: str, action: str) -> bool:
        """检查权限"""
        if user_role not in self.permissions:
            return False
        return action in self.permissions[user_role]

    def can_deploy(self, user_role: str, environment: str) -> bool:
        """检查部署权限"""
        if environment == "production":
            return user_role == "admin"
        return self.check_permission(user_role, "execute")
```

## 📋 最佳实践

### 1. 流水线设计原则

- **快速反馈**：确保构建和测试快速完成
- **失败快速**：在早期阶段发现并报告问题
- **可重复性**：确保流水线在不同环境中可重复执行
- **可观测性**：提供详细的日志和监控信息

### 2. 安全最佳实践

- **最小权限原则**：只授予必要的权限
- **密钥轮换**：定期更新密钥和证书
- **审计日志**：记录所有操作和访问
- **环境隔离**：严格分离不同环境的资源

### 3. 性能优化

```python
class PipelineOptimizer:
    """流水线优化器"""

    def __init__(self):
        self.cache_dir = ".pipeline_cache"
        os.makedirs(self.cache_dir, exist_ok=True)

    def should_skip_stage(self, stage_name: str, context: PipelineContext) -> bool:
        """判断是否应该跳过阶段"""
        # 检查缓存
        cache_key = f"{stage_name}_{context.commit_hash}"
        cache_file = os.path.join(self.cache_dir, cache_key)

        if os.path.exists(cache_file):
            # 检查缓存是否有效
            cache_time = os.path.getmtime(cache_file)
            if datetime.now().timestamp() - cache_time < 3600:  # 1小时缓存
                return True
        return False

    def cache_stage_result(self, stage_name: str, context: PipelineContext, result: Any) -> None:
        """缓存阶段结果"""
        cache_key = f"{stage_name}_{context.commit_hash}"
        cache_file = os.path.join(self.cache_dir, cache_key)

        with open(cache_file, 'w') as f:
            json.dump(result, f)
```

## 🔗 相关链接

- [05-架构领域/05-02-微服务架构/05-02-01-微服务基础.md](../05-02-微服务架构/05-02-01-微服务基础.md) - 微服务架构基础
- [02-理论基础/02-01-算法理论/02-01-01-算法基础.md](../../02-理论基础/02-01-算法理论/02-01-01-算法基础.md) - 算法理论基础
- [03-具体科学/03-01-设计模式科学.md](../../03-具体科学/03-01-设计模式科学.md) - 设计模式科学

---

*本文档提供了CI/CD的完整理论基础和Python实现，包括流水线框架、配置管理、监控报告等核心组件。*
