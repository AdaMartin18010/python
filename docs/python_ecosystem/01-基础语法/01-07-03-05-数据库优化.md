# 数据库优化

## 📋 概述

数据库优化是提高数据库应用性能的关键技术，通过优化查询、索引、连接池等环节，实现数据库的高效运行。

## 1. 理论基础

### 1.1 数据库性能模型

**定义 1.1** (查询响应时间)
查询响应时间是查询从提交到返回结果的时间：
$$T_{response} = T_{parsing} + T_{optimization} + T_{execution} + T_{network}$$

**定义 1.2** (数据库吞吐量)
数据库吞吐量是单位时间内处理的查询数量：
$$\text{Throughput} = \frac{\text{Query Count}}{\text{Time Period}}$$

**定义 1.3** (查询效率)
查询效率是实际执行时间与理论最优时间的比值：
$$\text{Efficiency} = \frac{T_{optimal}}{T_{actual}} \times 100\%$$

### 1.2 索引优化理论

**定义 1.4** (索引选择性)
索引选择性是不同值的数量与总记录数的比值：
$$\text{Selectivity} = \frac{\text{Distinct Values}}{\text{Total Records}}$$

**定义 1.5** (索引效率)
索引效率是使用索引的查询时间与全表扫描时间的比值：
$$\text{Index Efficiency} = \frac{T_{full_scan}}{T_{index_scan}}$$

## 2. Python实现

### 2.1 数据库连接优化

```python
from typing import Dict, List, Optional, Tuple, Any, Callable
from dataclasses import dataclass
from abc import ABC, abstractmethod
import sqlite3
import psycopg2
import mysql.connector
import time
import threading
import queue
from concurrent.futures import ThreadPoolExecutor
from enum import Enum
import logging
import json
from contextlib import contextmanager

# 配置日志
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DatabaseType(Enum):
    """数据库类型枚举"""
    SQLITE = "sqlite"
    POSTGRESQL = "postgresql"
    MYSQL = "mysql"

class QueryType(Enum):
    """查询类型枚举"""
    SELECT = "select"
    INSERT = "insert"
    UPDATE = "update"
    DELETE = "delete"

@dataclass
class QueryMetrics:
    """查询性能指标"""
    query_type: QueryType
    execution_time: float = 0.0
    rows_affected: int = 0
    memory_usage: float = 0.0
    cpu_usage: float = 0.0
    cache_hits: int = 0
    cache_misses: int = 0
    
    def __post_init__(self):
        self.start_time = time.time()
        self.end_time = None
    
    @property
    def duration(self) -> float:
        """查询持续时间"""
        if self.end_time:
            return self.end_time - self.start_time
        return time.time() - self.start_time

class DatabaseOptimizer(ABC):
    """数据库优化器抽象基类"""
    
    @abstractmethod
    def optimize_query(self, query: str, params: tuple = None) -> QueryMetrics:
        """优化查询"""
        pass
    
    @abstractmethod
    def optimize_connection(self) -> Dict[str, Any]:
        """优化连接"""
        pass
    
    @abstractmethod
    def get_metrics(self) -> Dict[str, Any]:
        """获取性能指标"""
        pass

class SQLiteOptimizer(DatabaseOptimizer):
    """SQLite数据库优化器"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.connection = None
        self.metrics_history: List[QueryMetrics] = []
        self.lock = threading.Lock()
    
    def _get_connection(self):
        """获取数据库连接"""
        if self.connection is None:
            self.connection = sqlite3.connect(self.db_path)
            # 启用WAL模式提高并发性能
            self.connection.execute("PRAGMA journal_mode=WAL")
            # 设置缓存大小
            self.connection.execute("PRAGMA cache_size=10000")
            # 启用外键约束
            self.connection.execute("PRAGMA foreign_keys=ON")
        return self.connection
    
    def optimize_query(self, query: str, params: tuple = None) -> QueryMetrics:
        """优化SQLite查询"""
        metrics = QueryMetrics(QueryType.SELECT)
        
        try:
            conn = self._get_connection()
            cursor = conn.cursor()
            
            # 执行查询
            start_time = time.time()
            if params:
                cursor.execute(query, params)
            else:
                cursor.execute(query)
            
            # 获取结果
            results = cursor.fetchall()
            metrics.execution_time = time.time() - start_time
            metrics.rows_affected = len(results)
            
            cursor.close()
            
        except Exception as e:
            logger.error(f"SQLite查询失败: {e}")
            metrics.execution_time = -1
        
        with self.lock:
            self.metrics_history.append(metrics)
        
        return metrics
    
    def optimize_connection(self) -> Dict[str, Any]:
        """优化SQLite连接"""
        conn = self._get_connection()
        
        # 获取数据库统计信息
        cursor = conn.cursor()
        cursor.execute("PRAGMA database_list")
        databases = cursor.fetchall()
        
        cursor.execute("PRAGMA table_info(sqlite_master)")
        tables = cursor.fetchall()
        
        cursor.execute("PRAGMA cache_size")
        cache_size = cursor.fetchone()[0]
        
        cursor.close()
        
        return {
            'database_count': len(databases),
            'table_count': len(tables),
            'cache_size': cache_size,
            'connection_status': 'connected'
        }
    
    def get_metrics(self) -> Dict[str, Any]:
        """获取SQLite性能指标"""
        with self.lock:
            if not self.metrics_history:
                return {}
            
            total_queries = len(self.metrics_history)
            avg_execution_time = sum(m.execution_time for m in self.metrics_history) / total_queries
            total_rows = sum(m.rows_affected for m in self.metrics_history)
            
            return {
                'total_queries': total_queries,
                'average_execution_time': avg_execution_time,
                'total_rows_affected': total_rows,
                'queries_per_second': total_queries / sum(m.execution_time for m in self.metrics_history) if sum(m.execution_time for m in self.metrics_history) > 0 else 0
            }

class ConnectionPool:
    """数据库连接池"""
    
    def __init__(self, db_type: DatabaseType, max_connections: int = 10, **kwargs):
        self.db_type = db_type
        self.max_connections = max_connections
        self.connection_params = kwargs
        self.connections: queue.Queue = queue.Queue(maxsize=max_connections)
        self.active_connections = 0
        self.lock = threading.Lock()
    
    def get_connection(self):
        """获取连接"""
        try:
            # 尝试从池中获取连接
            connection = self.connections.get_nowait()
            if self._is_connection_valid(connection):
                return connection
        except queue.Empty:
            pass
        
        # 创建新连接
        with self.lock:
            if self.active_connections < self.max_connections:
                connection = self._create_connection()
                if connection:
                    self.active_connections += 1
                    return connection
        
        return None
    
    def return_connection(self, connection) -> None:
        """归还连接"""
        try:
            if self._is_connection_valid(connection):
                self.connections.put_nowait(connection)
            else:
                self._close_connection(connection)
        except queue.Full:
            self._close_connection(connection)
        finally:
            with self.lock:
                self.active_connections -= 1
    
    def _create_connection(self):
        """创建新连接"""
        try:
            if self.db_type == DatabaseType.SQLITE:
                return sqlite3.connect(self.connection_params.get('db_path', ':memory:'))
            elif self.db_type == DatabaseType.POSTGRESQL:
                return psycopg2.connect(**self.connection_params)
            elif self.db_type == DatabaseType.MYSQL:
                return mysql.connector.connect(**self.connection_params)
        except Exception as e:
            logger.error(f"创建数据库连接失败: {e}")
            return None
    
    def _is_connection_valid(self, connection) -> bool:
        """检查连接是否有效"""
        try:
            if self.db_type == DatabaseType.SQLITE:
                connection.execute("SELECT 1")
            elif self.db_type == DatabaseType.POSTGRESQL:
                connection.cursor().execute("SELECT 1")
            elif self.db_type == DatabaseType.MYSQL:
                connection.cursor().execute("SELECT 1")
            return True
        except:
            return False
    
    def _close_connection(self, connection) -> None:
        """关闭连接"""
        try:
            connection.close()
        except:
            pass
    
    def close_all(self) -> None:
        """关闭所有连接"""
        while not self.connections.empty():
            try:
                connection = self.connections.get_nowait()
                self._close_connection(connection)
            except queue.Empty:
                break

class QueryOptimizer:
    """查询优化器"""
    
    def __init__(self, db_optimizer: DatabaseOptimizer):
        self.db_optimizer = db_optimizer
        self.query_cache: Dict[str, Any] = {}
        self.cache_hits = 0
        self.cache_misses = 0
    
    def optimize_select_query(self, query: str, params: tuple = None, 
                            use_cache: bool = True) -> QueryMetrics:
        """优化SELECT查询"""
        # 查询缓存
        if use_cache:
            cache_key = f"{query}_{hash(params) if params else 0}"
            if cache_key in self.query_cache:
                self.cache_hits += 1
                return self.query_cache[cache_key]
            else:
                self.cache_misses += 1
        
        # 执行查询
        metrics = self.db_optimizer.optimize_query(query, params)
        
        # 缓存结果
        if use_cache and metrics.execution_time > 0:
            self.query_cache[cache_key] = metrics
        
        return metrics
    
    def optimize_batch_query(self, queries: List[Tuple[str, tuple]]) -> List[QueryMetrics]:
        """优化批量查询"""
        metrics_list = []
        
        for query, params in queries:
            metrics = self.optimize_select_query(query, params)
            metrics_list.append(metrics)
        
        return metrics_list
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """获取缓存统计"""
        total_requests = self.cache_hits + self.cache_misses
        hit_rate = self.cache_hits / total_requests if total_requests > 0 else 0
        
        return {
            'cache_hits': self.cache_hits,
            'cache_misses': self.cache_misses,
            'hit_rate': hit_rate,
            'cache_size': len(self.query_cache)
        }
    
    def clear_cache(self) -> None:
        """清空缓存"""
        self.query_cache.clear()
        self.cache_hits = 0
        self.cache_misses = 0

class IndexOptimizer:
    """索引优化器"""
    
    def __init__(self, db_optimizer: DatabaseOptimizer):
        self.db_optimizer = db_optimizer
    
    def analyze_query_performance(self, query: str, params: tuple = None) -> Dict[str, Any]:
        """分析查询性能"""
        # 执行查询并记录性能
        metrics = self.db_optimizer.optimize_query(query, params)
        
        # 分析查询计划（这里简化处理）
        analysis = {
            'execution_time': metrics.execution_time,
            'rows_affected': metrics.rows_affected,
            'query_complexity': self._analyze_complexity(query),
            'index_recommendations': self._generate_index_recommendations(query)
        }
        
        return analysis
    
    def _analyze_complexity(self, query: str) -> str:
        """分析查询复杂度"""
        query_lower = query.lower()
        
        if 'join' in query_lower:
            return 'high'
        elif 'where' in query_lower and 'order by' in query_lower:
            return 'medium'
        elif 'where' in query_lower:
            return 'low'
        else:
            return 'very_low'
    
    def _generate_index_recommendations(self, query: str) -> List[str]:
        """生成索引建议"""
        recommendations = []
        query_lower = query.lower()
        
        # 简单的索引建议逻辑
        if 'where' in query_lower:
            recommendations.append("考虑为WHERE子句中的列创建索引")
        
        if 'order by' in query_lower:
            recommendations.append("考虑为ORDER BY子句中的列创建索引")
        
        if 'join' in query_lower:
            recommendations.append("考虑为JOIN条件中的列创建索引")
        
        return recommendations

class DatabaseMonitor:
    """数据库监控器"""
    
    def __init__(self):
        self.performance_history: List[Dict[str, Any]] = []
        self.lock = threading.Lock()
    
    def record_performance(self, metrics: QueryMetrics) -> None:
        """记录性能指标"""
        with self.lock:
            self.performance_history.append({
                'timestamp': time.time(),
                'execution_time': metrics.execution_time,
                'rows_affected': metrics.rows_affected,
                'query_type': metrics.query_type.value
            })
    
    def get_performance_report(self) -> Dict[str, Any]:
        """获取性能报告"""
        with self.lock:
            if not self.performance_history:
                return {}
            
            execution_times = [p['execution_time'] for p in self.performance_history]
            avg_execution_time = sum(execution_times) / len(execution_times)
            max_execution_time = max(execution_times)
            min_execution_time = min(execution_times)
            
            return {
                'total_queries': len(self.performance_history),
                'average_execution_time': avg_execution_time,
                'max_execution_time': max_execution_time,
                'min_execution_time': min_execution_time,
                'queries_per_second': len(self.performance_history) / sum(execution_times) if sum(execution_times) > 0 else 0
            }
```

### 2.2 实际应用示例

```python
# 示例1: SQLite数据库优化
def sqlite_optimization_example():
    """SQLite数据库优化示例"""
    import tempfile
    import os
    
    # 创建临时数据库
    with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as tmp:
        db_path = tmp.name
    
    try:
        # 初始化数据库
        optimizer = SQLiteOptimizer(db_path)
        conn = optimizer._get_connection()
        cursor = conn.cursor()
        
        # 创建测试表
        cursor.execute("""
            CREATE TABLE users (
                id INTEGER PRIMARY KEY,
                name TEXT NOT NULL,
                email TEXT UNIQUE,
                age INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # 插入测试数据
        for i in range(1000):
            cursor.execute(
                "INSERT INTO users (name, email, age) VALUES (?, ?, ?)",
                (f"User{i}", f"user{i}@example.com", 20 + i % 50)
            )
        
        conn.commit()
        
        # 查询优化测试
        query_optimizer = QueryOptimizer(optimizer)
        
        # 简单查询
        metrics1 = query_optimizer.optimize_select_query(
            "SELECT * FROM users WHERE age > 30"
        )
        print(f"简单查询执行时间: {metrics1.execution_time:.4f}s")
        
        # 复杂查询
        metrics2 = query_optimizer.optimize_select_query(
            "SELECT name, COUNT(*) as count FROM users GROUP BY age ORDER BY count DESC"
        )
        print(f"复杂查询执行时间: {metrics2.execution_time:.4f}s")
        
        # 批量查询
        batch_queries = [
            ("SELECT * FROM users WHERE age = ?", (25,)),
            ("SELECT * FROM users WHERE name LIKE ?", ("User%",)),
            ("SELECT COUNT(*) FROM users", ())
        ]
        
        batch_metrics = query_optimizer.optimize_batch_query(batch_queries)
        total_time = sum(m.execution_time for m in batch_metrics)
        print(f"批量查询总时间: {total_time:.4f}s")
        
        # 获取性能报告
        performance_report = optimizer.get_metrics()
        print(f"性能报告: {performance_report}")
        
        # 获取缓存统计
        cache_stats = query_optimizer.get_cache_stats()
        print(f"缓存统计: {cache_stats}")
        
    finally:
        # 清理临时文件
        os.unlink(db_path)

# 示例2: 连接池优化
def connection_pool_example():
    """连接池优化示例"""
    # SQLite连接池示例
    pool = ConnectionPool(
        DatabaseType.SQLITE,
        max_connections=5,
        db_path=':memory:'
    )
    
    # 模拟并发查询
    def worker(worker_id: int):
        """工作线程"""
        connection = pool.get_connection()
        if connection:
            try:
                cursor = connection.cursor()
                cursor.execute("SELECT 1")
                result = cursor.fetchone()
                print(f"Worker {worker_id}: {result}")
            finally:
                pool.return_connection(connection)
        else:
            print(f"Worker {worker_id}: 无法获取连接")
    
    # 创建多个线程
    threads = []
    for i in range(10):
        thread = threading.Thread(target=worker, args=(i,))
        threads.append(thread)
        thread.start()
    
    # 等待所有线程完成
    for thread in threads:
        thread.join()
    
    # 关闭连接池
    pool.close_all()

# 示例3: 索引优化分析
def index_optimization_example():
    """索引优化分析示例"""
    import tempfile
    import os
    
    with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as tmp:
        db_path = tmp.name
    
    try:
        optimizer = SQLiteOptimizer(db_path)
        index_optimizer = IndexOptimizer(optimizer)
        
        # 创建测试表
        conn = optimizer._get_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            CREATE TABLE products (
                id INTEGER PRIMARY KEY,
                name TEXT NOT NULL,
                category TEXT,
                price REAL,
                stock INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # 插入测试数据
        categories = ['Electronics', 'Books', 'Clothing', 'Food']
        for i in range(1000):
            cursor.execute(
                "INSERT INTO products (name, category, price, stock) VALUES (?, ?, ?, ?)",
                (f"Product{i}", categories[i % 4], 10.0 + i, 100 - i % 50)
            )
        
        conn.commit()
        
        # 分析不同查询的性能
        queries = [
            ("SELECT * FROM products WHERE category = 'Electronics'", None),
            ("SELECT * FROM products WHERE price > 50 ORDER BY price DESC", None),
            ("SELECT category, COUNT(*) FROM products GROUP BY category", None),
            ("SELECT * FROM products WHERE name LIKE 'Product%' AND stock > 50", None)
        ]
        
        print("=== 查询性能分析 ===")
        for i, (query, params) in enumerate(queries):
            analysis = index_optimizer.analyze_query_performance(query, params)
            print(f"\n查询 {i+1}:")
            print(f"  执行时间: {analysis['execution_time']:.4f}s")
            print(f"  复杂度: {analysis['query_complexity']}")
            print(f"  索引建议: {analysis['index_recommendations']}")
        
    finally:
        os.unlink(db_path)

# 示例4: 数据库监控
def database_monitoring_example():
    """数据库监控示例"""
    import tempfile
    import os
    
    with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as tmp:
        db_path = tmp.name
    
    try:
        optimizer = SQLiteOptimizer(db_path)
        monitor = DatabaseMonitor()
        
        # 创建测试表和数据
        conn = optimizer._get_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            CREATE TABLE orders (
                id INTEGER PRIMARY KEY,
                customer_id INTEGER,
                amount REAL,
                status TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # 插入测试数据
        for i in range(500):
            cursor.execute(
                "INSERT INTO orders (customer_id, amount, status) VALUES (?, ?, ?)",
                (i % 100, 10.0 + i, 'completed' if i % 2 == 0 else 'pending')
            )
        
        conn.commit()
        
        # 执行多个查询并监控性能
        queries = [
            "SELECT * FROM orders WHERE status = 'completed'",
            "SELECT customer_id, SUM(amount) FROM orders GROUP BY customer_id",
            "SELECT * FROM orders WHERE amount > 100 ORDER BY created_at DESC",
            "SELECT COUNT(*) FROM orders WHERE status = 'pending'"
        ]
        
        for query in queries:
            metrics = optimizer.optimize_query(query)
            monitor.record_performance(metrics)
            print(f"查询: {query[:50]}...")
            print(f"执行时间: {metrics.execution_time:.4f}s")
        
        # 获取性能报告
        report = monitor.get_performance_report()
        print(f"\n=== 性能报告 ===")
        print(f"总查询数: {report['total_queries']}")
        print(f"平均执行时间: {report['average_execution_time']:.4f}s")
        print(f"最大执行时间: {report['max_execution_time']:.4f}s")
        print(f"最小执行时间: {report['min_execution_time']:.4f}s")
        print(f"每秒查询数: {report['queries_per_second']:.2f}")
        
    finally:
        os.unlink(db_path)

if __name__ == "__main__":
    print("=== 数据库优化示例 ===")
    
    print("\n1. SQLite数据库优化")
    sqlite_optimization_example()
    
    print("\n2. 连接池优化")
    connection_pool_example()
    
    print("\n3. 索引优化分析")
    index_optimization_example()
    
    print("\n4. 数据库监控")
    database_monitoring_example()
```

## 3. 性能分析

### 3.1 理论分析

**定理 3.1** (查询优化)
对于查询优化，最优执行计划的时间复杂度为：
$$T_{optimal} = O(\log n + k)$$
其中 $n$ 是记录数，$k$ 是结果集大小。

**定理 3.2** (索引效率)
索引的效率提升为：
$$\text{Index Speedup} = \frac{T_{full_scan}}{T_{index_scan}} = \frac{n}{\log n}$$

### 3.2 实际性能测试

```python
def database_performance_benchmark():
    """数据库性能基准测试"""
    import tempfile
    import os
    import time
    
    print("=== 数据库性能基准测试 ===")
    
    with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as tmp:
        db_path = tmp.name
    
    try:
        optimizer = SQLiteOptimizer(db_path)
        query_optimizer = QueryOptimizer(optimizer)
        
        # 创建测试数据
        conn = optimizer._get_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            CREATE TABLE benchmark (
                id INTEGER PRIMARY KEY,
                value1 INTEGER,
                value2 TEXT,
                value3 REAL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # 插入大量测试数据
        print("插入测试数据...")
        start_time = time.time()
        for i in range(10000):
            cursor.execute(
                "INSERT INTO benchmark (value1, value2, value3) VALUES (?, ?, ?)",
                (i, f"text_{i}", i * 1.5)
            )
        insert_time = time.time() - start_time
        print(f"插入10000条记录时间: {insert_time:.3f}s")
        
        conn.commit()
        
        # 测试不同查询性能
        queries = [
            ("SELECT * FROM benchmark WHERE value1 = 5000", None),
            ("SELECT * FROM benchmark WHERE value2 LIKE 'text_5%'", None),
            ("SELECT value1, COUNT(*) FROM benchmark GROUP BY value1 % 100", None),
            ("SELECT * FROM benchmark ORDER BY value3 DESC LIMIT 100", None)
        ]
        
        print("\n查询性能测试:")
        for i, (query, params) in enumerate(queries):
            start_time = time.time()
            metrics = query_optimizer.optimize_select_query(query, params, use_cache=False)
            query_time = time.time() - start_time
            print(f"查询 {i+1}: {query_time:.4f}s (影响行数: {metrics.rows_affected})")
        
        # 测试缓存效果
        print("\n缓存效果测试:")
        query = "SELECT * FROM benchmark WHERE value1 = 1000"
        
        # 第一次查询（无缓存）
        start_time = time.time()
        metrics1 = query_optimizer.optimize_select_query(query, use_cache=True)
        first_time = time.time() - start_time
        
        # 第二次查询（有缓存）
        start_time = time.time()
        metrics2 = query_optimizer.optimize_select_query(query, use_cache=True)
        second_time = time.time() - start_time
        
        print(f"首次查询时间: {first_time:.4f}s")
        print(f"缓存查询时间: {second_time:.4f}s")
        print(f"缓存加速比: {first_time/second_time:.2f}x")
        
        # 获取性能统计
        cache_stats = query_optimizer.get_cache_stats()
        print(f"缓存统计: {cache_stats}")
        
    finally:
        os.unlink(db_path)

if __name__ == "__main__":
    database_performance_benchmark()
```

## 4. 最佳实践

### 4.1 数据库设计原则

1. **规范化设计**
   - 遵循数据库范式
   - 避免数据冗余
   - 保持数据一致性

2. **索引策略**
   - 为经常查询的列创建索引
   - 避免过多索引影响写入性能
   - 定期分析索引使用情况

3. **查询优化**
   - 使用参数化查询
   - 避免SELECT *
   - 合理使用LIMIT

### 4.2 性能优化技巧

1. **连接池管理**
   - 合理设置连接池大小
   - 及时释放连接
   - 监控连接使用情况

2. **查询缓存**
   - 缓存频繁查询的结果
   - 设置合理的缓存过期时间
   - 监控缓存命中率

3. **批量操作**
   - 使用批量插入/更新
   - 减少数据库往返次数
   - 使用事务提高性能

### 4.3 监控和调试

```python
class DatabaseDebugger:
    """数据库调试器"""
    
    def __init__(self):
        self.query_log = []
        self.lock = threading.Lock()
    
    def log_query(self, query: str, params: tuple, 
                  execution_time: float, rows_affected: int) -> None:
        """记录查询日志"""
        with self.lock:
            self.query_log.append({
                'query': query,
                'params': params,
                'execution_time': execution_time,
                'rows_affected': rows_affected,
                'timestamp': time.time()
            })
    
    def get_slow_queries(self, threshold: float = 1.0) -> List[Dict[str, Any]]:
        """获取慢查询"""
        with self.lock:
            return [q for q in self.query_log if q['execution_time'] > threshold]
    
    def get_query_statistics(self) -> Dict[str, Any]:
        """获取查询统计"""
        with self.lock:
            if not self.query_log:
                return {}
            
            execution_times = [q['execution_time'] for q in self.query_log]
            return {
                'total_queries': len(self.query_log),
                'average_execution_time': sum(execution_times) / len(execution_times),
                'max_execution_time': max(execution_times),
                'slow_queries': len([q for q in self.query_log if q['execution_time'] > 1.0])
            }
```

## 5. 总结

数据库优化是提高应用性能的关键技术。通过合理设计数据库结构、优化查询、使用连接池和缓存，可以显著提升数据库应用的性能。

### 关键要点

1. **理论基础**: 理解数据库性能模型和优化原理
2. **实现技术**: 掌握连接池、查询优化、索引等技术
3. **优化策略**: 根据应用特性选择合适的优化策略
4. **最佳实践**: 遵循数据库设计和优化的原则
5. **监控调试**: 建立完善的数据库监控和调试机制

### 应用场景

- **Web应用**: 优化数据库查询性能
- **数据分析**: 提高大数据处理效率
- **实时系统**: 减少数据库响应时间
- **高并发系统**: 优化数据库并发性能
- **企业应用**: 提升业务系统性能

---

**相关文档**:

- [性能优化最佳实践](../07-02-最佳实践/07-02-04-性能优化最佳实践.md)
- [并发优化](./07-03-03-并发优化.md)
- [网络优化](./07-03-04-网络优化.md)
