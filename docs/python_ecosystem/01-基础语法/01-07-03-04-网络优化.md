# ç½‘ç»œä¼˜åŒ–

## ğŸ“‹ æ¦‚è¿°

ç½‘ç»œä¼˜åŒ–æ˜¯æé«˜ç½‘ç»œåº”ç”¨æ€§èƒ½çš„å…³é”®æŠ€æœ¯ï¼Œé€šè¿‡ä¼˜åŒ–ç½‘ç»œåè®®ã€è¿æ¥ç®¡ç†ã€æ•°æ®ä¼ è¾“ç­‰ç¯èŠ‚ï¼Œå®ç°ç½‘ç»œåº”ç”¨çš„é«˜æ•ˆè¿è¡Œã€‚

## 1. ç†è®ºåŸºç¡€

### 1.1 ç½‘ç»œæ€§èƒ½æ¨¡å‹

**å®šä¹‰ 1.1** (ç½‘ç»œå»¶è¿Ÿ)
ç½‘ç»œå»¶è¿Ÿæ˜¯æ•°æ®åŒ…ä»æºåˆ°ç›®çš„åœ°æ‰€éœ€çš„æ—¶é—´ï¼š
$$\text{Latency} = T_{propagation} + T_{transmission} + T_{processing} + T_{queuing}$$

**å®šä¹‰ 1.2** (ç½‘ç»œååé‡)
ç½‘ç»œååé‡æ˜¯å•ä½æ—¶é—´å†…ä¼ è¾“çš„æ•°æ®é‡ï¼š
$$\text{Throughput} = \frac{\text{Data Size}}{\text{Total Time}}$$

**å®šä¹‰ 1.3** (ç½‘ç»œå¸¦å®½åˆ©ç”¨ç‡)
å¸¦å®½åˆ©ç”¨ç‡æ˜¯å®é™…ä¼ è¾“é€Ÿç‡ä¸ç†è®ºå¸¦å®½çš„æ¯”å€¼ï¼š
$$\text{Bandwidth Utilization} = \frac{\text{Actual Throughput}}{\text{Theoretical Bandwidth}} \times 100\%$$

### 1.2 ç½‘ç»œåè®®ä¼˜åŒ–

#### 1.2.1 TCPä¼˜åŒ–

**å®šä¹‰ 1.4** (TCPçª—å£å¤§å°)
TCPçª—å£å¤§å°å†³å®šäº†æœªç¡®è®¤æ•°æ®çš„æœ€å¤§æ•°é‡ï¼š
$$\text{Window Size} = \min(\text{CWND}, \text{RWND})$$

**å®šä¹‰ 1.5** (TCPæ‹¥å¡æ§åˆ¶)
æ‹¥å¡çª—å£å¤§å°æ ¹æ®ç½‘ç»œçŠ¶å†µåŠ¨æ€è°ƒæ•´ï¼š
$$\text{CWND}_{new} = \text{CWND}_{old} + \frac{\text{MSS}^2}{\text{CWND}_{old}}$$

#### 1.2.2 HTTPä¼˜åŒ–

**å®šä¹‰ 1.6** (HTTPè¿æ¥å¤ç”¨)
è¿æ¥å¤ç”¨ç‡æ˜¯å¤ç”¨è¿æ¥æ•°ä¸æ€»è¿æ¥æ•°çš„æ¯”å€¼ï¼š
$$\text{Connection Reuse Rate} = \frac{\text{Reused Connections}}{\text{Total Connections}} \times 100\%$$

## 2. Pythonå®ç°

### 2.1 ç½‘ç»œç¼–ç¨‹åŸºç¡€

```python
from typing import Dict, List, Optional, Tuple, Any, Callable
from dataclasses import dataclass
from abc import ABC, abstractmethod
import socket
import asyncio
import aiohttp
import requests
import time
import threading
import queue
from concurrent.futures import ThreadPoolExecutor
from enum import Enum
import logging
import json
import ssl
from urllib.parse import urlparse

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ProtocolType(Enum):
    """åè®®ç±»å‹æšä¸¾"""
    HTTP = "http"
    HTTPS = "https"
    TCP = "tcp"
    UDP = "udp"
    WEBSOCKET = "websocket"

class ConnectionState(Enum):
    """è¿æ¥çŠ¶æ€æšä¸¾"""
    IDLE = "idle"
    CONNECTING = "connecting"
    CONNECTED = "connected"
    DISCONNECTED = "disconnected"
    ERROR = "error"

@dataclass
class NetworkMetrics:
    """ç½‘ç»œæ€§èƒ½æŒ‡æ ‡"""
    latency: float = 0.0
    throughput: float = 0.0
    bandwidth_utilization: float = 0.0
    packet_loss: float = 0.0
    connection_count: int = 0
    error_count: int = 0
    
    def __post_init__(self):
        self.start_time = time.time()
        self.end_time = None
    
    @property
    def duration(self) -> float:
        """æŒç»­æ—¶é—´"""
        if self.end_time:
            return self.end_time - self.start_time
        return time.time() - self.start_time

class NetworkOptimizer(ABC):
    """ç½‘ç»œä¼˜åŒ–å™¨æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def optimize_connection(self, host: str, port: int) -> NetworkMetrics:
        """ä¼˜åŒ–è¿æ¥"""
        pass
    
    @abstractmethod
    def optimize_transfer(self, data: bytes) -> NetworkMetrics:
        """ä¼˜åŒ–ä¼ è¾“"""
        pass
    
    @abstractmethod
    def get_metrics(self) -> NetworkMetrics:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        pass

class TCPOptimizer(NetworkOptimizer):
    """TCPè¿æ¥ä¼˜åŒ–å™¨"""
    
    def __init__(self, buffer_size: int = 8192, timeout: float = 30.0):
        self.buffer_size = buffer_size
        self.timeout = timeout
        self.socket_options = {
            socket.SO_KEEPALIVE: 1,
            socket.SO_REUSEADDR: 1,
            socket.TCP_NODELAY: 1,
            socket.SO_RCVBUF: buffer_size * 2,
            socket.SO_SNDBUF: buffer_size * 2
        }
        self.metrics = NetworkMetrics()
    
    def optimize_connection(self, host: str, port: int) -> NetworkMetrics:
        """ä¼˜åŒ–TCPè¿æ¥"""
        start_time = time.time()
        
        try:
            # åˆ›å»ºsocket
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            
            # è®¾ç½®socketé€‰é¡¹
            for option, value in self.socket_options.items():
                sock.setsockopt(socket.SOL_SOCKET, option, value)
            
            # è®¾ç½®è¶…æ—¶
            sock.settimeout(self.timeout)
            
            # è¿æ¥
            sock.connect((host, port))
            
            # è®°å½•è¿æ¥æ—¶é—´
            connection_time = time.time() - start_time
            self.metrics.latency = connection_time
            self.metrics.connection_count = 1
            
            sock.close()
            
        except Exception as e:
            self.metrics.error_count += 1
            logger.error(f"TCPè¿æ¥å¤±è´¥: {e}")
        
        return self.metrics
    
    def optimize_transfer(self, data: bytes) -> NetworkMetrics:
        """ä¼˜åŒ–æ•°æ®ä¼ è¾“"""
        start_time = time.time()
        
        try:
            # æ¨¡æ‹Ÿæ•°æ®ä¼ è¾“
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            
            # è®¾ç½®socketé€‰é¡¹
            for option, value in self.socket_options.items():
                sock.setsockopt(socket.SOL_SOCKET, option, value)
            
            # æ¨¡æ‹Ÿä¼ è¾“
            total_sent = 0
            while total_sent < len(data):
                sent = sock.send(data[total_sent:])
                if sent == 0:
                    break
                total_sent += sent
            
            # è®¡ç®—ååé‡
            transfer_time = time.time() - start_time
            self.metrics.throughput = len(data) / transfer_time if transfer_time > 0 else 0
            
            sock.close()
            
        except Exception as e:
            self.metrics.error_count += 1
            logger.error(f"æ•°æ®ä¼ è¾“å¤±è´¥: {e}")
        
        return self.metrics
    
    def get_metrics(self) -> NetworkMetrics:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        self.metrics.end_time = time.time()
        return self.metrics

class HTTPOptimizer(NetworkOptimizer):
    """HTTPè¿æ¥ä¼˜åŒ–å™¨"""
    
    def __init__(self, max_connections: int = 100, keep_alive: bool = True):
        self.max_connections = max_connections
        self.keep_alive = keep_alive
        self.session = requests.Session()
        self.metrics = NetworkMetrics()
        
        # é…ç½®session
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=max_connections,
            pool_maxsize=max_connections,
            max_retries=3
        )
        self.session.mount('http://', adapter)
        self.session.mount('https://', adapter)
    
    def optimize_connection(self, url: str) -> NetworkMetrics:
        """ä¼˜åŒ–HTTPè¿æ¥"""
        start_time = time.time()
        
        try:
            # å‘é€HEADè¯·æ±‚æµ‹è¯•è¿æ¥
            response = self.session.head(url, timeout=30)
            
            # è®°å½•è¿æ¥æ—¶é—´
            connection_time = time.time() - start_time
            self.metrics.latency = connection_time
            self.metrics.connection_count = 1
            
        except Exception as e:
            self.metrics.error_count += 1
            logger.error(f"HTTPè¿æ¥å¤±è´¥: {e}")
        
        return self.metrics
    
    def optimize_transfer(self, url: str) -> NetworkMetrics:
        """ä¼˜åŒ–HTTPä¼ è¾“"""
        start_time = time.time()
        
        try:
            # å‘é€GETè¯·æ±‚
            response = self.session.get(url, timeout=30)
            
            # è®¡ç®—ååé‡
            transfer_time = time.time() - start_time
            content_length = len(response.content)
            self.metrics.throughput = content_length / transfer_time if transfer_time > 0 else 0
            
        except Exception as e:
            self.metrics.error_count += 1
            logger.error(f"HTTPä¼ è¾“å¤±è´¥: {e}")
        
        return self.metrics
    
    def get_metrics(self) -> NetworkMetrics:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        self.metrics.end_time = time.time()
        return self.metrics
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.session.close()

class AsyncHTTPOptimizer(NetworkOptimizer):
    """å¼‚æ­¥HTTPä¼˜åŒ–å™¨"""
    
    def __init__(self, max_connections: int = 100):
        self.max_connections = max_connections
        self.connector = aiohttp.TCPConnector(
            limit=max_connections,
            limit_per_host=max_connections,
            keepalive_timeout=30,
            enable_cleanup_closed=True
        )
        self.session = None
        self.metrics = NetworkMetrics()
    
    async def _get_session(self):
        """è·å–å¼‚æ­¥session"""
        if self.session is None:
            self.session = aiohttp.ClientSession(connector=self.connector)
        return self.session
    
    async def optimize_connection(self, url: str) -> NetworkMetrics:
        """ä¼˜åŒ–å¼‚æ­¥HTTPè¿æ¥"""
        start_time = time.time()
        
        try:
            session = await self._get_session()
            
            # å‘é€HEADè¯·æ±‚æµ‹è¯•è¿æ¥
            async with session.head(url, timeout=30) as response:
                connection_time = time.time() - start_time
                self.metrics.latency = connection_time
                self.metrics.connection_count = 1
            
        except Exception as e:
            self.metrics.error_count += 1
            logger.error(f"å¼‚æ­¥HTTPè¿æ¥å¤±è´¥: {e}")
        
        return self.metrics
    
    async def optimize_transfer(self, url: str) -> NetworkMetrics:
        """ä¼˜åŒ–å¼‚æ­¥HTTPä¼ è¾“"""
        start_time = time.time()
        
        try:
            session = await self._get_session()
            
            # å‘é€GETè¯·æ±‚
            async with session.get(url, timeout=30) as response:
                content = await response.read()
                
                # è®¡ç®—ååé‡
                transfer_time = time.time() - start_time
                content_length = len(content)
                self.metrics.throughput = content_length / transfer_time if transfer_time > 0 else 0
            
        except Exception as e:
            self.metrics.error_count += 1
            logger.error(f"å¼‚æ­¥HTTPä¼ è¾“å¤±è´¥: {e}")
        
        return self.metrics
    
    def get_metrics(self) -> NetworkMetrics:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        self.metrics.end_time = time.time()
        return self.metrics
    
    async def close(self):
        """å…³é—­session"""
        if self.session:
            await self.session.close()

class ConnectionPool:
    """è¿æ¥æ± å®ç°"""
    
    def __init__(self, max_connections: int = 100, timeout: float = 30.0):
        self.max_connections = max_connections
        self.timeout = timeout
        self.connections: queue.Queue = queue.Queue(maxsize=max_connections)
        self.active_connections = 0
        self.lock = threading.Lock()
    
    def get_connection(self, host: str, port: int) -> Optional[socket.socket]:
        """è·å–è¿æ¥"""
        try:
            # å°è¯•ä»æ± ä¸­è·å–è¿æ¥
            connection = self.connections.get_nowait()
            if self._is_connection_valid(connection):
                return connection
        except queue.Empty:
            pass
        
        # åˆ›å»ºæ–°è¿æ¥
        with self.lock:
            if self.active_connections < self.max_connections:
                connection = self._create_connection(host, port)
                if connection:
                    self.active_connections += 1
                    return connection
        
        return None
    
    def return_connection(self, connection: socket.socket) -> None:
        """å½’è¿˜è¿æ¥"""
        try:
            if self._is_connection_valid(connection):
                self.connections.put_nowait(connection)
            else:
                self._close_connection(connection)
        except queue.Full:
            self._close_connection(connection)
        finally:
            with self.lock:
                self.active_connections -= 1
    
    def _create_connection(self, host: str, port: int) -> Optional[socket.socket]:
        """åˆ›å»ºæ–°è¿æ¥"""
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(self.timeout)
            sock.connect((host, port))
            return sock
        except Exception as e:
            logger.error(f"åˆ›å»ºè¿æ¥å¤±è´¥: {e}")
            return None
    
    def _is_connection_valid(self, connection: socket.socket) -> bool:
        """æ£€æŸ¥è¿æ¥æ˜¯å¦æœ‰æ•ˆ"""
        try:
            # å‘é€ç©ºæ•°æ®åŒ…æ£€æŸ¥è¿æ¥
            connection.send(b'')
            return True
        except:
            return False
    
    def _close_connection(self, connection: socket.socket) -> None:
        """å…³é—­è¿æ¥"""
        try:
            connection.close()
        except:
            pass
    
    def close_all(self) -> None:
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        while not self.connections.empty():
            try:
                connection = self.connections.get_nowait()
                self._close_connection(connection)
            except queue.Empty:
                break

class NetworkMonitor:
    """ç½‘ç»œç›‘æ§å™¨"""
    
    def __init__(self):
        self.metrics_history: List[NetworkMetrics] = []
        self.lock = threading.Lock()
    
    def record_metrics(self, metrics: NetworkMetrics) -> None:
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        with self.lock:
            self.metrics_history.append(metrics)
    
    def get_average_metrics(self) -> NetworkMetrics:
        """è·å–å¹³å‡æ€§èƒ½æŒ‡æ ‡"""
        with self.lock:
            if not self.metrics_history:
                return NetworkMetrics()
            
            avg_metrics = NetworkMetrics()
            count = len(self.metrics_history)
            
            avg_metrics.latency = sum(m.latency for m in self.metrics_history) / count
            avg_metrics.throughput = sum(m.throughput for m in self.metrics_history) / count
            avg_metrics.bandwidth_utilization = sum(m.bandwidth_utilization for m in self.metrics_history) / count
            avg_metrics.packet_loss = sum(m.packet_loss for m in self.metrics_history) / count
            avg_metrics.connection_count = sum(m.connection_count for m in self.metrics_history)
            avg_metrics.error_count = sum(m.error_count for m in self.metrics_history)
            
            return avg_metrics
    
    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        avg_metrics = self.get_average_metrics()
        
        return {
            'average_latency': avg_metrics.latency,
            'average_throughput': avg_metrics.throughput,
            'bandwidth_utilization': avg_metrics.bandwidth_utilization,
            'packet_loss_rate': avg_metrics.packet_loss,
            'total_connections': avg_metrics.connection_count,
            'total_errors': avg_metrics.error_count,
            'error_rate': avg_metrics.error_count / max(avg_metrics.connection_count, 1),
            'sample_count': len(self.metrics_history)
        }
```

### 2.2 ç½‘ç»œä¼˜åŒ–ç­–ç•¥

```python
class NetworkOptimizationStrategy:
    """ç½‘ç»œä¼˜åŒ–ç­–ç•¥"""
    
    def __init__(self):
        self.tcp_optimizer = TCPOptimizer()
        self.http_optimizer = HTTPOptimizer()
        self.async_http_optimizer = AsyncHTTPOptimizer()
        self.connection_pool = ConnectionPool()
        self.monitor = NetworkMonitor()
    
    def optimize_tcp_connections(self, hosts: List[Tuple[str, int]]) -> Dict[str, Any]:
        """ä¼˜åŒ–TCPè¿æ¥"""
        results = {}
        
        for host, port in hosts:
            metrics = self.tcp_optimizer.optimize_connection(host, port)
            self.monitor.record_metrics(metrics)
            results[f"{host}:{port}"] = {
                'latency': metrics.latency,
                'connection_count': metrics.connection_count,
                'error_count': metrics.error_count
            }
        
        return results
    
    def optimize_http_connections(self, urls: List[str]) -> Dict[str, Any]:
        """ä¼˜åŒ–HTTPè¿æ¥"""
        results = {}
        
        with self.http_optimizer as optimizer:
            for url in urls:
                metrics = optimizer.optimize_connection(url)
                self.monitor.record_metrics(metrics)
                results[url] = {
                    'latency': metrics.latency,
                    'connection_count': metrics.connection_count,
                    'error_count': metrics.error_count
                }
        
        return results
    
    async def optimize_async_http_connections(self, urls: List[str]) -> Dict[str, Any]:
        """ä¼˜åŒ–å¼‚æ­¥HTTPè¿æ¥"""
        results = {}
        
        for url in urls:
            metrics = await self.async_http_optimizer.optimize_connection(url)
            self.monitor.record_metrics(metrics)
            results[url] = {
                'latency': metrics.latency,
                'connection_count': metrics.connection_count,
                'error_count': metrics.error_count
            }
        
        return results
    
    def optimize_connection_pool(self, host: str, port: int, 
                               request_count: int) -> Dict[str, Any]:
        """ä¼˜åŒ–è¿æ¥æ± """
        start_time = time.time()
        success_count = 0
        error_count = 0
        
        for _ in range(request_count):
            connection = self.connection_pool.get_connection(host, port)
            if connection:
                success_count += 1
                self.connection_pool.return_connection(connection)
            else:
                error_count += 1
        
        total_time = time.time() - start_time
        
        return {
            'total_requests': request_count,
            'success_count': success_count,
            'error_count': error_count,
            'success_rate': success_count / request_count,
            'total_time': total_time,
            'requests_per_second': request_count / total_time
        }
    
    def get_optimization_report(self) -> Dict[str, Any]:
        """è·å–ä¼˜åŒ–æŠ¥å‘Š"""
        performance_report = self.monitor.get_performance_report()
        
        return {
            'performance_metrics': performance_report,
            'optimization_recommendations': self._generate_recommendations(performance_report)
        }
    
    def _generate_recommendations(self, metrics: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        if metrics['average_latency'] > 1.0:
            recommendations.append("è€ƒè™‘ä½¿ç”¨CDNå‡å°‘å»¶è¿Ÿ")
        
        if metrics['bandwidth_utilization'] < 50:
            recommendations.append("ç½‘ç»œå¸¦å®½åˆ©ç”¨ç‡è¾ƒä½ï¼Œå¯ä»¥å¢åŠ å¹¶å‘è¿æ¥æ•°")
        
        if metrics['error_rate'] > 0.05:
            recommendations.append("é”™è¯¯ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒæœåŠ¡å™¨çŠ¶æ€")
        
        if metrics['packet_loss_rate'] > 0.01:
            recommendations.append("æ•°æ®åŒ…ä¸¢å¤±ç‡è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–ç½‘ç»œè·¯å¾„")
        
        return recommendations

class LoadBalancer:
    """è´Ÿè½½å‡è¡¡å™¨"""
    
    def __init__(self, servers: List[Tuple[str, int]]):
        self.servers = servers
        self.current_index = 0
        self.server_metrics: Dict[str, NetworkMetrics] = {}
        self.lock = threading.Lock()
    
    def round_robin(self) -> Tuple[str, int]:
        """è½®è¯¢è´Ÿè½½å‡è¡¡"""
        with self.lock:
            server = self.servers[self.current_index]
            self.current_index = (self.current_index + 1) % len(self.servers)
            return server
    
    def least_connections(self) -> Tuple[str, int]:
        """æœ€å°‘è¿æ¥è´Ÿè½½å‡è¡¡"""
        with self.lock:
            min_connections = float('inf')
            selected_server = self.servers[0]
            
            for server in self.servers:
                server_key = f"{server[0]}:{server[1]}"
                connections = self.server_metrics.get(server_key, NetworkMetrics()).connection_count
                if connections < min_connections:
                    min_connections = connections
                    selected_server = server
            
            return selected_server
    
    def weighted_round_robin(self, weights: List[int]) -> Tuple[str, int]:
        """åŠ æƒè½®è¯¢è´Ÿè½½å‡è¡¡"""
        with self.lock:
            if len(weights) != len(self.servers):
                weights = [1] * len(self.servers)
            
            # ç®€å•çš„åŠ æƒè½®è¯¢å®ç°
            total_weight = sum(weights)
            current_weight = self.current_index % total_weight
            
            for i, weight in enumerate(weights):
                if current_weight < weight:
                    server = self.servers[i]
                    self.current_index += 1
                    return server
                current_weight -= weight
            
            return self.servers[0]
    
    def update_server_metrics(self, server: Tuple[str, int], metrics: NetworkMetrics) -> None:
        """æ›´æ–°æœåŠ¡å™¨æŒ‡æ ‡"""
        server_key = f"{server[0]}:{server[1]}"
        with self.lock:
            self.server_metrics[server_key] = metrics
```

### 2.3 å®é™…åº”ç”¨ç¤ºä¾‹

```python
# ç¤ºä¾‹1: TCPè¿æ¥ä¼˜åŒ–
def tcp_connection_optimization():
    """TCPè¿æ¥ä¼˜åŒ–ç¤ºä¾‹"""
    hosts = [
        ("localhost", 8080),
        ("127.0.0.1", 8081),
        ("0.0.0.0", 8082)
    ]
    
    strategy = NetworkOptimizationStrategy()
    results = strategy.optimize_tcp_connections(hosts)
    
    print("=== TCPè¿æ¥ä¼˜åŒ–ç»“æœ ===")
    for host_port, metrics in results.items():
        print(f"æœåŠ¡å™¨ {host_port}:")
        print(f"  å»¶è¿Ÿ: {metrics['latency']:.3f}s")
        print(f"  è¿æ¥æ•°: {metrics['connection_count']}")
        print(f"  é”™è¯¯æ•°: {metrics['error_count']}")

# ç¤ºä¾‹2: HTTPè¿æ¥ä¼˜åŒ–
def http_connection_optimization():
    """HTTPè¿æ¥ä¼˜åŒ–ç¤ºä¾‹"""
    urls = [
        "http://httpbin.org/delay/1",
        "http://httpbin.org/delay/2",
        "http://httpbin.org/delay/3"
    ]
    
    strategy = NetworkOptimizationStrategy()
    results = strategy.optimize_http_connections(urls)
    
    print("=== HTTPè¿æ¥ä¼˜åŒ–ç»“æœ ===")
    for url, metrics in results.items():
        print(f"URL {url}:")
        print(f"  å»¶è¿Ÿ: {metrics['latency']:.3f}s")
        print(f"  è¿æ¥æ•°: {metrics['connection_count']}")
        print(f"  é”™è¯¯æ•°: {metrics['error_count']}")

# ç¤ºä¾‹3: å¼‚æ­¥HTTPä¼˜åŒ–
async def async_http_optimization():
    """å¼‚æ­¥HTTPä¼˜åŒ–ç¤ºä¾‹"""
    urls = [
        "http://httpbin.org/delay/1",
        "http://httpbin.org/delay/2",
        "http://httpbin.org/delay/3"
    ]
    
    strategy = NetworkOptimizationStrategy()
    results = await strategy.optimize_async_http_connections(urls)
    
    print("=== å¼‚æ­¥HTTPä¼˜åŒ–ç»“æœ ===")
    for url, metrics in results.items():
        print(f"URL {url}:")
        print(f"  å»¶è¿Ÿ: {metrics['latency']:.3f}s")
        print(f"  è¿æ¥æ•°: {metrics['connection_count']}")
        print(f"  é”™è¯¯æ•°: {metrics['error_count']}")

# ç¤ºä¾‹4: è¿æ¥æ± ä¼˜åŒ–
def connection_pool_optimization():
    """è¿æ¥æ± ä¼˜åŒ–ç¤ºä¾‹"""
    strategy = NetworkOptimizationStrategy()
    results = strategy.optimize_connection_pool("localhost", 8080, 100)
    
    print("=== è¿æ¥æ± ä¼˜åŒ–ç»“æœ ===")
    print(f"æ€»è¯·æ±‚æ•°: {results['total_requests']}")
    print(f"æˆåŠŸæ•°: {results['success_count']}")
    print(f"é”™è¯¯æ•°: {results['error_count']}")
    print(f"æˆåŠŸç‡: {results['success_rate']:.2%}")
    print(f"æ€»æ—¶é—´: {results['total_time']:.3f}s")
    print(f"æ¯ç§’è¯·æ±‚æ•°: {results['requests_per_second']:.2f}")

# ç¤ºä¾‹5: è´Ÿè½½å‡è¡¡
def load_balancing_example():
    """è´Ÿè½½å‡è¡¡ç¤ºä¾‹"""
    servers = [
        ("server1.example.com", 8080),
        ("server2.example.com", 8080),
        ("server3.example.com", 8080)
    ]
    
    balancer = LoadBalancer(servers)
    
    print("=== è´Ÿè½½å‡è¡¡ç¤ºä¾‹ ===")
    
    # è½®è¯¢è´Ÿè½½å‡è¡¡
    print("è½®è¯¢è´Ÿè½½å‡è¡¡:")
    for i in range(5):
        server = balancer.round_robin()
        print(f"  è¯·æ±‚ {i+1}: {server[0]}:{server[1]}")
    
    # åŠ æƒè½®è¯¢è´Ÿè½½å‡è¡¡
    weights = [3, 2, 1]  # æœåŠ¡å™¨æƒé‡
    print("\nåŠ æƒè½®è¯¢è´Ÿè½½å‡è¡¡:")
    for i in range(6):
        server = balancer.weighted_round_robin(weights)
        print(f"  è¯·æ±‚ {i+1}: {server[0]}:{server[1]}")

if __name__ == "__main__":
    # è¿è¡Œç¤ºä¾‹
    tcp_connection_optimization()
    http_connection_optimization()
    asyncio.run(async_http_optimization())
    connection_pool_optimization()
    load_balancing_example()
    
    # è·å–ä¼˜åŒ–æŠ¥å‘Š
    strategy = NetworkOptimizationStrategy()
    report = strategy.get_optimization_report()
    print("\n=== ç½‘ç»œä¼˜åŒ–æŠ¥å‘Š ===")
    print(json.dumps(report, indent=2))
```

## 3. æ€§èƒ½åˆ†æ

### 3.1 ç†è®ºåˆ†æ

**å®šç† 3.1** (ç½‘ç»œå»¶è¿Ÿä¼˜åŒ–)
å¯¹äºç½‘ç»œå»¶è¿Ÿä¼˜åŒ–ï¼Œæœ€å°å»¶è¿Ÿä¸ºï¼š
$$\text{Min Latency} = \sqrt{\frac{2 \times \text{Packet Size}}{\text{Bandwidth}}}$$

**è¯æ˜**:
æ ¹æ®ç½‘ç»œä¼ è¾“æ¨¡å‹ï¼Œå»¶è¿ŸåŒ…æ‹¬ä¼ æ’­å»¶è¿Ÿå’Œä¼ è¾“å»¶è¿Ÿï¼š
$$T = T_{prop} + T_{trans} = \frac{D}{v} + \frac{L}{B}$$
å…¶ä¸­ $D$ æ˜¯è·ç¦»ï¼Œ$v$ æ˜¯ä¼ æ’­é€Ÿåº¦ï¼Œ$L$ æ˜¯æ•°æ®åŒ…å¤§å°ï¼Œ$B$ æ˜¯å¸¦å®½ã€‚
å¯¹ $L$ æ±‚å¯¼å¹¶ä»¤å…¶ä¸ºé›¶ï¼š
$$\frac{dT}{dL} = \frac{1}{B} - \frac{D}{v \times L^2} = 0$$
è§£å¾—ï¼š
$$L = \sqrt{\frac{2 \times D \times B}{v}}$$

**å®šç† 3.2** (è¿æ¥æ± ä¼˜åŒ–)
è¿æ¥æ± çš„æœ€ä¼˜å¤§å°è¿‘ä¼¼ä¸ºï¼š
$$\text{Optimal Pool Size} = \sqrt{\frac{2 \times \text{Request Rate} \times \text{Connection Time}}{\text{Memory Cost}}}$$

### 3.2 å®é™…æ€§èƒ½æµ‹è¯•

```python
def network_performance_benchmark():
    """ç½‘ç»œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    import time
    import random
    
    print("=== ç½‘ç»œæ€§èƒ½åŸºå‡†æµ‹è¯• ===")
    
    # æµ‹è¯•æ•°æ®
    test_urls = [
        "http://httpbin.org/delay/1",
        "http://httpbin.org/delay/2",
        "http://httpbin.org/delay/3"
    ]
    
    strategy = NetworkOptimizationStrategy()
    
    # 1. HTTPè¿æ¥æ€§èƒ½æµ‹è¯•
    print("\n1. HTTPè¿æ¥æ€§èƒ½æµ‹è¯•")
    start_time = time.time()
    http_results = strategy.optimize_http_connections(test_urls)
    http_time = time.time() - start_time
    print(f"HTTPè¿æ¥æ—¶é—´: {http_time:.3f}s")
    print(f"ç»“æœ: {http_results}")
    
    # 2. å¼‚æ­¥HTTPæ€§èƒ½æµ‹è¯•
    print("\n2. å¼‚æ­¥HTTPæ€§èƒ½æµ‹è¯•")
    start_time = time.time()
    async_results = asyncio.run(strategy.optimize_async_http_connections(test_urls))
    async_time = time.time() - start_time
    print(f"å¼‚æ­¥HTTPæ—¶é—´: {async_time:.3f}s")
    print(f"ç»“æœ: {async_results}")
    
    # 3. è¿æ¥æ± æ€§èƒ½æµ‹è¯•
    print("\n3. è¿æ¥æ± æ€§èƒ½æµ‹è¯•")
    pool_results = strategy.optimize_connection_pool("localhost", 8080, 50)
    print(f"è¿æ¥æ± ç»“æœ: {pool_results}")
    
    # 4. æ€§èƒ½å¯¹æ¯”
    print("\n4. æ€§èƒ½å¯¹æ¯”")
    print(f"HTTP vs å¼‚æ­¥HTTP åŠ é€Ÿæ¯”: {http_time/async_time:.2f}x")
    
    # 5. ä¼˜åŒ–æŠ¥å‘Š
    print("\n5. ä¼˜åŒ–æŠ¥å‘Š")
    report = strategy.get_optimization_report()
    print(json.dumps(report, indent=2))

if __name__ == "__main__":
    network_performance_benchmark()
```

## 4. æœ€ä½³å®è·µ

### 4.1 ç½‘ç»œç¼–ç¨‹åŸåˆ™

1. **è¿æ¥å¤ç”¨**
   - ä½¿ç”¨è¿æ¥æ± å‡å°‘è¿æ¥å»ºç«‹å¼€é”€
   - å¯ç”¨HTTP Keep-Alive
   - åˆç†è®¾ç½®è¿æ¥è¶…æ—¶

2. **å¼‚æ­¥å¤„ç†**
   - ä½¿ç”¨å¼‚æ­¥I/Oæé«˜å¹¶å‘æ€§èƒ½
   - é¿å…é˜»å¡æ“ä½œ
   - åˆç†ä½¿ç”¨çº¿ç¨‹æ± 

3. **è´Ÿè½½å‡è¡¡**
   - å®ç°å¤šæœåŠ¡å™¨è´Ÿè½½å‡è¡¡
   - ä½¿ç”¨å¥åº·æ£€æŸ¥
   - åŠ¨æ€è°ƒæ•´æƒé‡

4. **é”™è¯¯å¤„ç†**
   - å®ç°é‡è¯•æœºåˆ¶
   - å¤„ç†ç½‘ç»œå¼‚å¸¸
   - è®°å½•è¯¦ç»†æ—¥å¿—

### 4.2 æ€§èƒ½ä¼˜åŒ–æŠ€å·§

1. **å‡å°‘ç½‘ç»œå¾€è¿”**
   - æ‰¹é‡å¤„ç†è¯·æ±‚
   - ä½¿ç”¨å‹ç¼©ä¼ è¾“
   - å®ç°è¯·æ±‚åˆå¹¶

2. **ä¼˜åŒ–æ•°æ®ä¼ è¾“**
   - é€‰æ‹©åˆé€‚çš„åè®®
   - ä¼˜åŒ–æ•°æ®æ ¼å¼
   - ä½¿ç”¨æµå¼ä¼ è¾“

3. **ç¼“å­˜ç­–ç•¥**
   - å®ç°DNSç¼“å­˜
   - ä½¿ç”¨HTTPç¼“å­˜
   - ç¼“å­˜è¿æ¥å¯¹è±¡

### 4.3 ç›‘æ§å’Œè°ƒè¯•

```python
class NetworkDebugger:
    """ç½‘ç»œè°ƒè¯•å™¨"""
    
    def __init__(self):
        self.traffic_log = []
        self.lock = threading.Lock()
    
    def log_request(self, method: str, url: str, 
                   start_time: float, end_time: float, 
                   status_code: int, error: str = None) -> None:
        """è®°å½•è¯·æ±‚æ—¥å¿—"""
        with self.lock:
            self.traffic_log.append({
                'method': method,
                'url': url,
                'start_time': start_time,
                'end_time': end_time,
                'duration': end_time - start_time,
                'status_code': status_code,
                'error': error
            })
    
    def get_traffic_summary(self) -> Dict[str, Any]:
        """è·å–æµé‡æ‘˜è¦"""
        with self.lock:
            if not self.traffic_log:
                return {}
            
            total_requests = len(self.traffic_log)
            successful_requests = len([r for r in self.traffic_log if r['status_code'] == 200])
            failed_requests = total_requests - successful_requests
            
            durations = [r['duration'] for r in self.traffic_log]
            avg_duration = sum(durations) / len(durations)
            max_duration = max(durations)
            min_duration = min(durations)
            
            return {
                'total_requests': total_requests,
                'successful_requests': successful_requests,
                'failed_requests': failed_requests,
                'success_rate': successful_requests / total_requests,
                'average_duration': avg_duration,
                'max_duration': max_duration,
                'min_duration': min_duration
            }
    
    def export_traffic_log(self, filename: str) -> None:
        """å¯¼å‡ºæµé‡æ—¥å¿—"""
        with self.lock:
            with open(filename, 'w') as f:
                json.dump(self.traffic_log, f, indent=2)
```

## 5. æ€»ç»“

ç½‘ç»œä¼˜åŒ–æ˜¯æé«˜ç½‘ç»œåº”ç”¨æ€§èƒ½çš„å…³é”®æŠ€æœ¯ã€‚é€šè¿‡åˆç†é€‰æ‹©ç½‘ç»œåè®®ã€ä¼˜åŒ–è¿æ¥ç®¡ç†ã€å®ç°è´Ÿè½½å‡è¡¡ï¼Œå¯ä»¥æ˜¾è‘—æå‡ç½‘ç»œåº”ç”¨çš„å“åº”é€Ÿåº¦å’Œååé‡ã€‚

### å…³é”®è¦ç‚¹

1. **ç†è®ºåŸºç¡€**: ç†è§£ç½‘ç»œæ€§èƒ½æ¨¡å‹å’Œä¼˜åŒ–åŸç†
2. **å®ç°æŠ€æœ¯**: æŒæ¡TCPã€HTTPã€å¼‚æ­¥ç­‰å¤šç§ç½‘ç»œç¼–ç¨‹æŠ€æœ¯
3. **ä¼˜åŒ–ç­–ç•¥**: æ ¹æ®åº”ç”¨ç‰¹æ€§é€‰æ‹©åˆé€‚çš„ç½‘ç»œä¼˜åŒ–ç­–ç•¥
4. **æœ€ä½³å®è·µ**: éµå¾ªç½‘ç»œç¼–ç¨‹çš„åŸåˆ™å’ŒæŠ€å·§
5. **ç›‘æ§è°ƒè¯•**: å»ºç«‹å®Œå–„çš„ç½‘ç»œç›‘æ§å’Œè°ƒè¯•æœºåˆ¶

### åº”ç”¨åœºæ™¯

- **Webåº”ç”¨**: ä¼˜åŒ–HTTPè¯·æ±‚å’Œå“åº”
- **APIæœåŠ¡**: æé«˜æ¥å£å“åº”é€Ÿåº¦
- **æ–‡ä»¶ä¼ è¾“**: ä¼˜åŒ–å¤§æ–‡ä»¶ä¼ è¾“æ€§èƒ½
- **å®æ—¶é€šä¿¡**: å‡å°‘ç½‘ç»œå»¶è¿Ÿ
- **åˆ†å¸ƒå¼ç³»ç»Ÿ**: ä¼˜åŒ–èŠ‚ç‚¹é—´é€šä¿¡

---

**ç›¸å…³æ–‡æ¡£**:

- [å¼‚æ­¥ç¼–ç¨‹](../06-ç»„ä»¶ç®—æ³•/06-05-å¼‚æ­¥ç¼–ç¨‹/06-05-01-å¼‚æ­¥ç¼–ç¨‹åŸºç¡€.md)
- [å¹¶å‘ä¼˜åŒ–](./07-03-03-å¹¶å‘ä¼˜åŒ–.md)
- [æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ](../07-02-æœ€ä½³å®è·µ/07-02-04-æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ.md)
