# 01. 机器学习基础

## 1.1 机器学习理论框架

### 1.1.1 机器学习定义

**机器学习**是人工智能的一个分支，通过算法使计算机系统能够从数据中学习和改进，而无需明确编程。

**形式化定义**：

```math
学习问题: (X, Y, P(x,y), H, L)
```

其中：

- $X$: 输入空间
- $Y$: 输出空间
- $P(x,y)$: 联合概率分布
- $H$: 假设空间
- $L$: 损失函数

### 1.1.2 学习类型

**监督学习**：

```python
from typing import TypeVar, Generic, List, Tuple, Callable
from abc import ABC, abstractmethod
import numpy as np
from dataclasses import dataclass

X = TypeVar('X')  # 输入类型
Y = TypeVar('Y')  # 输出类型

@dataclass
class TrainingExample(Generic[X, Y]):
    """训练样本"""
    features: X
    label: Y

class SupervisedLearner(ABC, Generic[X, Y]):
    """监督学习器抽象"""
    
    @abstractmethod
    def train(self, training_data: List[TrainingExample[X, Y]]) -> None:
        """训练模型"""
        pass
    
    @abstractmethod
    def predict(self, features: X) -> Y:
        """预测"""
        pass
    
    @abstractmethod
    def evaluate(self, test_data: List[TrainingExample[X, Y]]) -> float:
        """评估模型"""
        pass

class UnsupervisedLearner(ABC, Generic[X]):
    """无监督学习器抽象"""
    
    @abstractmethod
    def train(self, training_data: List[X]) -> None:
        """训练模型"""
        pass
    
    @abstractmethod
    def transform(self, data: X) -> np.ndarray:
        """转换数据"""
        pass

class SemiSupervisedLearner(ABC, Generic[X, Y]):
    """半监督学习器抽象"""
    
    @abstractmethod
    def train(self, 
              labeled_data: List[TrainingExample[X, Y]], 
              unlabeled_data: List[X]) -> None:
        """训练模型"""
        pass
```

### 1.1.3 学习理论

**PAC学习理论**：

```python
from typing import Set, Callable
import random

class PACLearning:
    """PAC学习理论实现"""
    
    def __init__(self, hypothesis_space: Set[Callable], target_concept: Callable):
        self.hypothesis_space = hypothesis_space
        self.target_concept = target_concept
    
    def sample_complexity(self, epsilon: float, delta: float) -> int:
        """计算样本复杂度"""
        # 简化的样本复杂度计算
        return int(np.ceil((1 / epsilon) * np.log(1 / delta)))
    
    def empirical_risk_minimization(self, 
                                  samples: List[TrainingExample], 
                                  hypothesis: Callable) -> float:
        """经验风险最小化"""
        errors = 0
        for sample in samples:
            if hypothesis(sample.features) != sample.label:
                errors += 1
        return errors / len(samples)
    
    def pac_learn(self, epsilon: float, delta: float) -> Callable:
        """PAC学习算法"""
        sample_size = self.sample_complexity(epsilon, delta)
        
        # 生成训练样本
        samples = self._generate_samples(sample_size)
        
        # 选择经验风险最小的假设
        best_hypothesis = None
        min_risk = float('inf')
        
        for hypothesis in self.hypothesis_space:
            risk = self.empirical_risk_minimization(samples, hypothesis)
            if risk < min_risk:
                min_risk = risk
                best_hypothesis = hypothesis
        
        return best_hypothesis
    
    def _generate_samples(self, sample_size: int) -> List[TrainingExample]:
        """生成训练样本"""
        samples = []
        for _ in range(sample_size):
            # 这里简化实现，实际应该从真实分布采样
            features = np.random.random(10)  # 10维特征
            label = self.target_concept(features)
            samples.append(TrainingExample(features, label))
        return samples
```

## 1.2 线性模型

### 1.2.1 线性回归

**线性回归模型**：

```math
y = w^T x + b
```

```python
import numpy as np
from typing import List, Tuple
from dataclasses import dataclass

@dataclass
class LinearRegression(SupervisedLearner[np.ndarray, float]):
    """线性回归模型"""
    
    def __init__(self, learning_rate: float = 0.01, max_iterations: int = 1000):
        self.learning_rate = learning_rate
        self.max_iterations = max_iterations
        self.weights: np.ndarray = None
        self.bias: float = 0.0
        self.training_history: List[float] = []
    
    def train(self, training_data: List[TrainingExample[np.ndarray, float]]) -> None:
        """训练线性回归模型"""
        if not training_data:
            raise ValueError("Training data cannot be empty")
        
        # 初始化参数
        feature_dim = len(training_data[0].features)
        self.weights = np.random.randn(feature_dim) * 0.01
        self.bias = 0.0
        
        # 梯度下降
        for iteration in range(self.max_iterations):
            gradients_w, gradient_b = self._compute_gradients(training_data)
            
            # 更新参数
            self.weights -= self.learning_rate * gradients_w
            self.bias -= self.learning_rate * gradient_b
            
            # 记录损失
            loss = self._compute_loss(training_data)
            self.training_history.append(loss)
            
            # 早停条件
            if iteration > 0 and abs(self.training_history[-1] - self.training_history[-2]) < 1e-6:
                break
    
    def predict(self, features: np.ndarray) -> float:
        """预测"""
        if self.weights is None:
            raise ValueError("Model not trained")
        return np.dot(self.weights, features) + self.bias
    
    def evaluate(self, test_data: List[TrainingExample[np.ndarray, float]]) -> float:
        """评估模型（使用MSE）"""
        if not test_data:
            return 0.0
        
        total_error = 0.0
        for example in test_data:
            prediction = self.predict(example.features)
            error = (prediction - example.label) ** 2
            total_error += error
        
        return total_error / len(test_data)
    
    def _compute_gradients(self, training_data: List[TrainingExample[np.ndarray, float]]) -> Tuple[np.ndarray, float]:
        """计算梯度"""
        gradients_w = np.zeros_like(self.weights)
        gradient_b = 0.0
        
        for example in training_data:
            prediction = self.predict(example.features)
            error = prediction - example.label
            
            gradients_w += error * example.features
            gradient_b += error
        
        # 平均梯度
        n = len(training_data)
        return gradients_w / n, gradient_b / n
    
    def _compute_loss(self, training_data: List[TrainingExample[np.ndarray, float]]) -> float:
        """计算损失"""
        return self.evaluate(training_data)

# 正则化线性回归
class RidgeRegression(LinearRegression):
    """岭回归（L2正则化）"""
    
    def __init__(self, learning_rate: float = 0.01, max_iterations: int = 1000, alpha: float = 1.0):
        super().__init__(learning_rate, max_iterations)
        self.alpha = alpha  # 正则化参数
    
    def _compute_gradients(self, training_data: List[TrainingExample[np.ndarray, float]]) -> Tuple[np.ndarray, float]:
        """计算梯度（包含L2正则化）"""
        gradients_w, gradient_b = super()._compute_gradients(training_data)
        
        # 添加L2正则化项
        gradients_w += self.alpha * self.weights
        
        return gradients_w, gradient_b

class LassoRegression(LinearRegression):
    """Lasso回归（L1正则化）"""
    
    def __init__(self, learning_rate: float = 0.01, max_iterations: int = 1000, alpha: float = 1.0):
        super().__init__(learning_rate, max_iterations)
        self.alpha = alpha  # 正则化参数
    
    def _compute_gradients(self, training_data: List[TrainingExample[np.ndarray, float]]) -> Tuple[np.ndarray, float]:
        """计算梯度（包含L1正则化）"""
        gradients_w, gradient_b = super()._compute_gradients(training_data)
        
        # 添加L1正则化项
        gradients_w += self.alpha * np.sign(self.weights)
        
        return gradients_w, gradient_b
```

### 1.2.2 逻辑回归

**逻辑回归模型**：

```math
P(y=1|x) = \frac{1}{1 + e^{-(w^T x + b)}}
```

```python
import numpy as np
from typing import List, Tuple
import math

class LogisticRegression(SupervisedLearner[np.ndarray, int]):
    """逻辑回归模型"""
    
    def __init__(self, learning_rate: float = 0.01, max_iterations: int = 1000):
        self.learning_rate = learning_rate
        self.max_iterations = max_iterations
        self.weights: np.ndarray = None
        self.bias: float = 0.0
        self.training_history: List[float] = []
    
    def train(self, training_data: List[TrainingExample[np.ndarray, int]]) -> None:
        """训练逻辑回归模型"""
        if not training_data:
            raise ValueError("Training data cannot be empty")
        
        # 初始化参数
        feature_dim = len(training_data[0].features)
        self.weights = np.random.randn(feature_dim) * 0.01
        self.bias = 0.0
        
        # 梯度下降
        for iteration in range(self.max_iterations):
            gradients_w, gradient_b = self._compute_gradients(training_data)
            
            # 更新参数
            self.weights -= self.learning_rate * gradients_w
            self.bias -= self.learning_rate * gradient_b
            
            # 记录损失
            loss = self._compute_loss(training_data)
            self.training_history.append(loss)
            
            # 早停条件
            if iteration > 0 and abs(self.training_history[-1] - self.training_history[-2]) < 1e-6:
                break
    
    def predict(self, features: np.ndarray) -> int:
        """预测类别"""
        probability = self.predict_proba(features)
        return 1 if probability >= 0.5 else 0
    
    def predict_proba(self, features: np.ndarray) -> float:
        """预测概率"""
        if self.weights is None:
            raise ValueError("Model not trained")
        
        z = np.dot(self.weights, features) + self.bias
        return self._sigmoid(z)
    
    def evaluate(self, test_data: List[TrainingExample[np.ndarray, int]]) -> float:
        """评估模型（使用准确率）"""
        if not test_data:
            return 0.0
        
        correct = 0
        for example in test_data:
            prediction = self.predict(example.features)
            if prediction == example.label:
                correct += 1
        
        return correct / len(test_data)
    
    def _sigmoid(self, z: float) -> float:
        """Sigmoid函数"""
        return 1 / (1 + math.exp(-z))
    
    def _compute_gradients(self, training_data: List[TrainingExample[np.ndarray, int]]) -> Tuple[np.ndarray, float]:
        """计算梯度"""
        gradients_w = np.zeros_like(self.weights)
        gradient_b = 0.0
        
        for example in training_data:
            prediction = self.predict_proba(example.features)
            error = prediction - example.label
            
            gradients_w += error * example.features
            gradient_b += error
        
        # 平均梯度
        n = len(training_data)
        return gradients_w / n, gradient_b / n
    
    def _compute_loss(self, training_data: List[TrainingExample[np.ndarray, int]]) -> float:
        """计算交叉熵损失"""
        total_loss = 0.0
        
        for example in training_data:
            prediction = self.predict_proba(example.features)
            
            if example.label == 1:
                loss = -math.log(prediction)
            else:
                loss = -math.log(1 - prediction)
            
            total_loss += loss
        
        return total_loss / len(training_data)
```

## 1.3 决策树

### 1.3.1 决策树基础

**决策树模型**：

```python
from typing import List, Tuple, Optional, Dict, Any
from dataclasses import dataclass
import numpy as np

@dataclass
class TreeNode:
    """决策树节点"""
    feature_index: Optional[int] = None
    threshold: Optional[float] = None
    left_child: Optional['TreeNode'] = None
    right_child: Optional['TreeNode'] = None
    is_leaf: bool = False
    prediction: Any = None
    samples_count: int = 0

class DecisionTree(SupervisedLearner[np.ndarray, Any]):
    """决策树模型"""
    
    def __init__(self, max_depth: int = 10, min_samples_split: int = 2):
        self.max_depth = max_depth
        self.min_samples_split = min_samples_split
        self.root: Optional[TreeNode] = None
    
    def train(self, training_data: List[TrainingExample[np.ndarray, Any]]) -> None:
        """训练决策树"""
        if not training_data:
            raise ValueError("Training data cannot be empty")
        
        features = np.array([example.features for example in training_data])
        labels = np.array([example.label for example in training_data])
        
        self.root = self._build_tree(features, labels, depth=0)
    
    def predict(self, features: np.ndarray) -> Any:
        """预测"""
        if self.root is None:
            raise ValueError("Model not trained")
        
        return self._predict_recursive(features, self.root)
    
    def evaluate(self, test_data: List[TrainingExample[np.ndarray, Any]]) -> float:
        """评估模型"""
        if not test_data:
            return 0.0
        
        correct = 0
        for example in test_data:
            prediction = self.predict(example.features)
            if prediction == example.label:
                correct += 1
        
        return correct / len(test_data)
    
    def _build_tree(self, features: np.ndarray, labels: np.ndarray, depth: int) -> TreeNode:
        """构建决策树"""
        n_samples, n_features = features.shape
        n_classes = len(np.unique(labels))
        
        # 停止条件
        if (depth >= self.max_depth or 
            n_samples < self.min_samples_split or 
            n_classes == 1):
            
            return TreeNode(
                is_leaf=True,
                prediction=self._most_common_label(labels),
                samples_count=n_samples
            )
        
        # 寻找最佳分割
        best_feature, best_threshold = self._find_best_split(features, labels)
        
        if best_feature is None:
            return TreeNode(
                is_leaf=True,
                prediction=self._most_common_label(labels),
                samples_count=n_samples
            )
        
        # 分割数据
        left_mask = features[:, best_feature] <= best_threshold
        right_mask = ~left_mask
        
        left_features = features[left_mask]
        left_labels = labels[left_mask]
        right_features = features[right_mask]
        right_labels = labels[right_mask]
        
        # 递归构建子树
        left_child = self._build_tree(left_features, left_labels, depth + 1)
        right_child = self._build_tree(right_features, right_labels, depth + 1)
        
        return TreeNode(
            feature_index=best_feature,
            threshold=best_threshold,
            left_child=left_child,
            right_child=right_child,
            samples_count=n_samples
        )
    
    def _find_best_split(self, features: np.ndarray, labels: np.ndarray) -> Tuple[Optional[int], Optional[float]]:
        """寻找最佳分割点"""
        n_samples, n_features = features.shape
        best_gain = -1
        best_feature = None
        best_threshold = None
        
        # 计算父节点的熵
        parent_entropy = self._entropy(labels)
        
        for feature_index in range(n_features):
            thresholds = np.unique(features[:, feature_index])
            
            for threshold in thresholds:
                left_mask = features[:, feature_index] <= threshold
                right_mask = ~left_mask
                
                if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:
                    continue
                
                left_labels = labels[left_mask]
                right_labels = labels[right_mask]
                
                # 计算信息增益
                left_entropy = self._entropy(left_labels)
                right_entropy = self._entropy(right_labels)
                
                left_weight = len(left_labels) / n_samples
                right_weight = len(right_labels) / n_samples
                
                gain = parent_entropy - (left_weight * left_entropy + right_weight * right_entropy)
                
                if gain > best_gain:
                    best_gain = gain
                    best_feature = feature_index
                    best_threshold = threshold
        
        return best_feature, best_threshold
    
    def _entropy(self, labels: np.ndarray) -> float:
        """计算熵"""
        unique_labels, counts = np.unique(labels, return_counts=True)
        probabilities = counts / len(labels)
        entropy = -np.sum(probabilities * np.log2(probabilities))
        return entropy
    
    def _most_common_label(self, labels: np.ndarray) -> Any:
        """获取最常见的标签"""
        unique_labels, counts = np.unique(labels, return_counts=True)
        return unique_labels[np.argmax(counts)]
    
    def _predict_recursive(self, features: np.ndarray, node: TreeNode) -> Any:
        """递归预测"""
        if node.is_leaf:
            return node.prediction
        
        if features[node.feature_index] <= node.threshold:
            return self._predict_recursive(features, node.left_child)
        else:
            return self._predict_recursive(features, node.right_child)
```

### 1.3.2 随机森林

**随机森林模型**：

```python
import random
from typing import List, Tuple

class RandomForest(SupervisedLearner[np.ndarray, Any]):
    """随机森林模型"""
    
    def __init__(self, n_trees: int = 100, max_depth: int = 10, min_samples_split: int = 2):
        self.n_trees = n_trees
        self.max_depth = max_depth
        self.min_samples_split = min_samples_split
        self.trees: List[DecisionTree] = []
    
    def train(self, training_data: List[TrainingExample[np.ndarray, Any]]) -> None:
        """训练随机森林"""
        if not training_data:
            raise ValueError("Training data cannot be empty")
        
        self.trees = []
        
        for _ in range(self.n_trees):
            # 生成bootstrap样本
            bootstrap_data = self._bootstrap_sample(training_data)
            
            # 训练决策树
            tree = DecisionTree(self.max_depth, self.min_samples_split)
            tree.train(bootstrap_data)
            
            self.trees.append(tree)
    
    def predict(self, features: np.ndarray) -> Any:
        """预测（多数投票）"""
        if not self.trees:
            raise ValueError("Model not trained")
        
        predictions = [tree.predict(features) for tree in self.trees]
        return self._majority_vote(predictions)
    
    def evaluate(self, test_data: List[TrainingExample[np.ndarray, Any]]) -> float:
        """评估模型"""
        if not test_data:
            return 0.0
        
        correct = 0
        for example in test_data:
            prediction = self.predict(example.features)
            if prediction == example.label:
                correct += 1
        
        return correct / len(test_data)
    
    def _bootstrap_sample(self, data: List[TrainingExample]) -> List[TrainingExample]:
        """生成bootstrap样本"""
        n_samples = len(data)
        indices = [random.randint(0, n_samples - 1) for _ in range(n_samples)]
        return [data[i] for i in indices]
    
    def _majority_vote(self, predictions: List[Any]) -> Any:
        """多数投票"""
        from collections import Counter
        counter = Counter(predictions)
        return counter.most_common(1)[0][0]
```

## 1.4 支持向量机

### 1.4.1 SVM基础

**支持向量机模型**：

```math
f(x) = \sum_{i=1}^{n} \alpha_i y_i K(x_i, x) + b
```

```python
import numpy as np
from typing import List, Tuple, Optional
from dataclasses import dataclass

@dataclass
class SVM(SupervisedLearner[np.ndarray, int]):
    """支持向量机模型"""
    
    def __init__(self, C: float = 1.0, kernel: str = 'linear', max_iterations: int = 1000):
        self.C = C  # 正则化参数
        self.kernel = kernel
        self.max_iterations = max_iterations
        self.alphas: np.ndarray = None
        self.support_vectors: np.ndarray = None
        self.support_vector_labels: np.ndarray = None
        self.bias: float = 0.0
    
    def train(self, training_data: List[TrainingExample[np.ndarray, int]]) -> None:
        """训练SVM（简化实现）"""
        if not training_data:
            raise ValueError("Training data cannot be empty")
        
        features = np.array([example.features for example in training_data])
        labels = np.array([example.label for example in training_data])
        
        n_samples = len(training_data)
        
        # 初始化拉格朗日乘子
        self.alphas = np.zeros(n_samples)
        
        # 简化的SMO算法
        for iteration in range(self.max_iterations):
            alpha_pairs_changed = 0
            
            for i in range(n_samples):
                Ei = self._predict_single(features[i]) - labels[i]
                
                if ((labels[i] * Ei < -0.001 and self.alphas[i] < self.C) or
                    (labels[i] * Ei > 0.001 and self.alphas[i] > 0)):
                    
                    # 选择第二个alpha
                    j = self._select_second_alpha(i, n_samples)
                    Ej = self._predict_single(features[j]) - labels[j]
                    
                    # 保存旧值
                    alpha_i_old = self.alphas[i]
                    alpha_j_old = self.alphas[j]
                    
                    # 计算边界
                    if labels[i] != labels[j]:
                        L = max(0, self.alphas[j] - self.alphas[i])
                        H = min(self.C, self.C + self.alphas[j] - self.alphas[i])
                    else:
                        L = max(0, self.alphas[i] + self.alphas[j] - self.C)
                        H = min(self.C, self.alphas[i] + self.alphas[j])
                    
                    if L == H:
                        continue
                    
                    # 计算eta
                    eta = 2 * self._kernel_function(features[i], features[j]) - \
                          self._kernel_function(features[i], features[i]) - \
                          self._kernel_function(features[j], features[j])
                    
                    if eta >= 0:
                        continue
                    
                    # 更新alpha_j
                    self.alphas[j] -= labels[j] * (Ei - Ej) / eta
                    self.alphas[j] = np.clip(self.alphas[j], L, H)
                    
                    if abs(self.alphas[j] - alpha_j_old) < 0.00001:
                        continue
                    
                    # 更新alpha_i
                    self.alphas[i] += labels[i] * labels[j] * (alpha_j_old - self.alphas[j])
                    
                    # 更新bias
                    b1 = self.bias - Ei - labels[i] * (self.alphas[i] - alpha_i_old) * \
                         self._kernel_function(features[i], features[i]) - \
                         labels[j] * (self.alphas[j] - alpha_j_old) * \
                         self._kernel_function(features[i], features[j])
                    
                    b2 = self.bias - Ej - labels[i] * (self.alphas[i] - alpha_i_old) * \
                         self._kernel_function(features[i], features[j]) - \
                         labels[j] * (self.alphas[j] - alpha_j_old) * \
                         self._kernel_function(features[j], features[j])
                    
                    self.bias = (b1 + b2) / 2
                    alpha_pairs_changed += 1
            
            if alpha_pairs_changed == 0:
                break
        
        # 保存支持向量
        support_vector_indices = self.alphas > 0.001
        self.support_vectors = features[support_vector_indices]
        self.support_vector_labels = labels[support_vector_indices]
        self.alphas = self.alphas[support_vector_indices]
    
    def predict(self, features: np.ndarray) -> int:
        """预测"""
        if self.support_vectors is None:
            raise ValueError("Model not trained")
        
        result = self._predict_single(features)
        return 1 if result >= 0 else -1
    
    def evaluate(self, test_data: List[TrainingExample[np.ndarray, int]]) -> float:
        """评估模型"""
        if not test_data:
            return 0.0
        
        correct = 0
        for example in test_data:
            prediction = self.predict(example.features)
            if prediction == example.label:
                correct += 1
        
        return correct / len(test_data)
    
    def _predict_single(self, features: np.ndarray) -> float:
        """单个样本预测"""
        if self.support_vectors is None:
            return 0.0
        
        result = 0.0
        for i, alpha in enumerate(self.alphas):
            result += alpha * self.support_vector_labels[i] * \
                      self._kernel_function(self.support_vectors[i], features)
        result += self.bias
        return result
    
    def _kernel_function(self, x1: np.ndarray, x2: np.ndarray) -> float:
        """核函数"""
        if self.kernel == 'linear':
            return np.dot(x1, x2)
        elif self.kernel == 'rbf':
            gamma = 1.0
            return np.exp(-gamma * np.linalg.norm(x1 - x2) ** 2)
        else:
            raise ValueError(f"Unknown kernel: {self.kernel}")
    
    def _select_second_alpha(self, i: int, n_samples: int) -> int:
        """选择第二个alpha（简化实现）"""
        j = i
        while j == i:
            j = np.random.randint(0, n_samples)
        return j
```

## 1.5 神经网络

### 1.5.1 前馈神经网络

**神经网络模型**：

```python
import numpy as np
from typing import List, Tuple, Optional
from dataclasses import dataclass
import math

@dataclass
class Layer:
    """神经网络层"""
    weights: np.ndarray
    biases: np.ndarray
    activation: str = 'relu'

class NeuralNetwork(SupervisedLearner[np.ndarray, np.ndarray]):
    """前馈神经网络"""
    
    def __init__(self, layer_sizes: List[int], learning_rate: float = 0.01):
        self.layer_sizes = layer_sizes
        self.learning_rate = learning_rate
        self.layers: List[Layer] = []
        self.training_history: List[float] = []
        
        # 初始化层
        for i in range(len(layer_sizes) - 1):
            weights = np.random.randn(layer_sizes[i + 1], layer_sizes[i]) * 0.01
            biases = np.zeros((layer_sizes[i + 1], 1))
            self.layers.append(Layer(weights, biases))
    
    def train(self, training_data: List[TrainingExample[np.ndarray, np.ndarray]]) -> None:
        """训练神经网络"""
        if not training_data:
            raise ValueError("Training data cannot be empty")
        
        for iteration in range(1000):  # 简化训练循环
            total_loss = 0.0
            
            for example in training_data:
                # 前向传播
                activations = self._forward_pass(example.features)
                
                # 反向传播
                gradients = self._backward_pass(example.features, example.label, activations)
                
                # 更新参数
                self._update_parameters(gradients)
                
                # 计算损失
                loss = self._compute_loss(activations[-1], example.label)
                total_loss += loss
            
            # 记录平均损失
            avg_loss = total_loss / len(training_data)
            self.training_history.append(avg_loss)
            
            # 早停条件
            if iteration > 0 and abs(self.training_history[-1] - self.training_history[-2]) < 1e-6:
                break
    
    def predict(self, features: np.ndarray) -> np.ndarray:
        """预测"""
        activations = self._forward_pass(features)
        return activations[-1]
    
    def evaluate(self, test_data: List[TrainingExample[np.ndarray, np.ndarray]]) -> float:
        """评估模型"""
        if not test_data:
            return 0.0
        
        total_loss = 0.0
        for example in test_data:
            prediction = self.predict(example.features)
            loss = self._compute_loss(prediction, example.label)
            total_loss += loss
        
        return total_loss / len(test_data)
    
    def _forward_pass(self, features: np.ndarray) -> List[np.ndarray]:
        """前向传播"""
        activations = [features.reshape(-1, 1)]
        
        for layer in self.layers:
            # 线性变换
            z = np.dot(layer.weights, activations[-1]) + layer.biases
            
            # 激活函数
            if layer.activation == 'relu':
                a = self._relu(z)
            elif layer.activation == 'sigmoid':
                a = self._sigmoid(z)
            elif layer.activation == 'tanh':
                a = self._tanh(z)
            else:
                a = z
            
            activations.append(a)
        
        return activations
    
    def _backward_pass(self, features: np.ndarray, target: np.ndarray, activations: List[np.ndarray]) -> List[Tuple[np.ndarray, np.ndarray]]:
        """反向传播"""
        gradients = []
        m = features.shape[0]
        
        # 计算输出层误差
        delta = activations[-1] - target.reshape(-1, 1)
        
        # 反向传播误差
        for i in range(len(self.layers) - 1, -1, -1):
            layer = self.layers[i]
            
            # 计算梯度
            weight_grad = np.dot(delta, activations[i].T) / m
            bias_grad = np.sum(delta, axis=1, keepdims=True) / m
            
            gradients.insert(0, (weight_grad, bias_grad))
            
            # 计算下一层的误差
            if i > 0:
                delta = np.dot(layer.weights.T, delta)
                if layer.activation == 'relu':
                    delta *= (activations[i] > 0).astype(float)
                elif layer.activation == 'sigmoid':
                    delta *= activations[i] * (1 - activations[i])
                elif layer.activation == 'tanh':
                    delta *= (1 - activations[i] ** 2)
        
        return gradients
    
    def _update_parameters(self, gradients: List[Tuple[np.ndarray, np.ndarray]]) -> None:
        """更新参数"""
        for i, (weight_grad, bias_grad) in enumerate(gradients):
            self.layers[i].weights -= self.learning_rate * weight_grad
            self.layers[i].biases -= self.learning_rate * bias_grad
    
    def _compute_loss(self, prediction: np.ndarray, target: np.ndarray) -> float:
        """计算损失（MSE）"""
        return np.mean((prediction - target.reshape(-1, 1)) ** 2)
    
    def _relu(self, x: np.ndarray) -> np.ndarray:
        """ReLU激活函数"""
        return np.maximum(0, x)
    
    def _sigmoid(self, x: np.ndarray) -> np.ndarray:
        """Sigmoid激活函数"""
        return 1 / (1 + np.exp(-x))
    
    def _tanh(self, x: np.ndarray) -> np.ndarray:
        """Tanh激活函数"""
        return np.tanh(x)
```

## 1.6 总结

机器学习基础为AI/ML领域提供了**核心理论框架**：

1. **学习理论**: PAC学习、经验风险最小化
2. **线性模型**: 线性回归、逻辑回归、正则化
3. **决策树**: 分类回归树、随机森林
4. **支持向量机**: 线性SVM、核方法
5. **神经网络**: 前馈网络、反向传播

这些基础算法和理论为深度学习、强化学习等高级技术奠定了坚实基础。
