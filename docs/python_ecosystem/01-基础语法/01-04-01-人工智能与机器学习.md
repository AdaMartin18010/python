# 04-01 人工智能与机器学习 (Artificial Intelligence & Machine Learning)

## 目录

1. [基本概念](#1-基本概念)
2. [机器学习基础](#2-机器学习基础)
3. [深度学习](#3-深度学习)
4. [强化学习](#4-强化学习)
5. [自然语言处理](#5-自然语言处理)
6. [计算机视觉](#6-计算机视觉)
7. [Python实现](#7-python实现)
8. [应用案例](#8-应用案例)
9. [总结与展望](#9-总结与展望)

## 1. 基本概念

### 1.1 人工智能定义

**人工智能**是使机器能够模拟人类智能行为的科学与技术。

**形式化定义**：

```math
\text{AI} = (S, A, T, R, \pi, V)
```

其中：

- $S$ 是状态空间
- $A$ 是动作空间
- $T: S \times A \rightarrow S$ 是状态转移函数
- $R: S \times A \rightarrow \mathbb{R}$ 是奖励函数
- $\pi: S \rightarrow A$ 是策略函数
- $V: S \rightarrow \mathbb{R}$ 是价值函数

### 1.2 机器学习分类

```math
\text{ML} = \begin{cases}
\text{Supervised Learning} & \text{监督学习} \\
\text{Unsupervised Learning} & \text{无监督学习} \\
\text{Semi-supervised Learning} & \text{半监督学习} \\
\text{Reinforcement Learning} & \text{强化学习}
\end{cases}
```

### 1.3 学习范式

**监督学习**：

```math
f: \mathcal{X} \rightarrow \mathcal{Y} \text{ where } (x_i, y_i) \in \mathcal{D}
```

**无监督学习**：

```math
f: \mathcal{X} \rightarrow \mathcal{Z} \text{ where } x_i \in \mathcal{X}
```

**强化学习**：

```math
\pi^* = \arg\max_\pi \mathbb{E}[\sum_{t=0}^{\infty} \gamma^t R(s_t, a_t)]
```

## 2. 机器学习基础

### 2.1 统计学习理论

**经验风险最小化**：

```math
\hat{f} = \arg\min_{f \in \mathcal{F}} \frac{1}{n} \sum_{i=1}^{n} L(f(x_i), y_i)
```

**结构风险最小化**：

```math
\hat{f} = \arg\min_{f \in \mathcal{F}} \frac{1}{n} \sum_{i=1}^{n} L(f(x_i), y_i) + \lambda \Omega(f)
```

### 2.2 泛化理论

**VC维**：

```math
\text{VC}(\mathcal{F}) = \max\{n: \mathcal{F} \text{ shatters } n \text{ points}\}
```

**泛化界**：

```math
P(\mathcal{R}(f) \leq \hat{\mathcal{R}}(f) + \sqrt{\frac{\log|\mathcal{F}| + \log(1/\delta)}{2n}}) \geq 1 - \delta
```

### 2.3 偏差-方差分解

```math
\mathbb{E}[(y - \hat{f}(x))^2] = \text{Bias}^2(\hat{f}) + \text{Var}(\hat{f}) + \sigma^2
```

其中：

- $\text{Bias}^2(\hat{f}) = \mathbb{E}[\hat{f}(x) - f^*(x)]^2$
- $\text{Var}(\hat{f}) = \mathbb{E}[(\hat{f}(x) - \mathbb{E}[\hat{f}(x)])^2]$
- $\sigma^2$ 是噪声方差

## 3. 深度学习

### 3.1 神经网络

**前馈神经网络**：

```math
f(x) = \sigma_n(W_n \sigma_{n-1}(W_{n-1} \cdots \sigma_1(W_1 x + b_1) \cdots + b_{n-1}) + b_n)
```

**反向传播**：

```math
\frac{\partial L}{\partial W_l} = \frac{\partial L}{\partial z_l} \frac{\partial z_l}{\partial W_l} = \delta_l a_{l-1}^T
```

其中 $\delta_l$ 是误差项：

```math
\delta_l = \begin{cases}
\nabla_{z_l} L & \text{if } l = n \\
W_{l+1}^T \delta_{l+1} \odot \sigma'(z_l) & \text{otherwise}
\end{cases}
```

### 3.2 卷积神经网络

**卷积操作**：

```math
(f * k)(i, j) = \sum_{m} \sum_{n} f(m, n) k(i-m, j-n)
```

**池化操作**：

```math
\text{MaxPool}(A)_{i,j} = \max_{m,n \in \text{window}} A_{i+m, j+n}
```

### 3.3 循环神经网络

**RNN状态更新**：

```math
h_t = \tanh(W_h h_{t-1} + W_x x_t + b_h)
```

**LSTM门控机制**：

```math
\begin{align}
f_t &= \sigma(W_f [h_{t-1}, x_t] + b_f) \\
i_t &= \sigma(W_i [h_{t-1}, x_t] + b_i) \\
\tilde{C}_t &= \tanh(W_C [h_{t-1}, x_t] + b_C) \\
C_t &= f_t \odot C_{t-1} + i_t \odot \tilde{C}_t \\
o_t &= \sigma(W_o [h_{t-1}, x_t] + b_o) \\
h_t &= o_t \odot \tanh(C_t)
\end{align}
```

## 4. 强化学习

### 4.1 马尔可夫决策过程

**MDP定义**：

```math
\mathcal{M} = (S, A, P, R, \gamma)
```

其中：

- $S$ 是状态空间
- $A$ 是动作空间
- $P: S \times A \times S \rightarrow [0,1]$ 是转移概率
- $R: S \times A \rightarrow \mathbb{R}$ 是奖励函数
- $\gamma \in [0,1]$ 是折扣因子

### 4.2 价值函数

**状态价值函数**：

```math
V^\pi(s) = \mathbb{E}_\pi[\sum_{t=0}^{\infty} \gamma^t R(s_t, a_t) | s_0 = s]
```

**动作价值函数**：

```math
Q^\pi(s, a) = \mathbb{E}_\pi[\sum_{t=0}^{\infty} \gamma^t R(s_t, a_t) | s_0 = s, a_0 = a]
```

### 4.3 Q-Learning

**Q-Learning更新**：

```math
Q(s, a) \leftarrow Q(s, a) + \alpha[r + \gamma \max_{a'} Q(s', a') - Q(s, a)]
```

### 4.4 策略梯度

**策略梯度定理**：

```math
\nabla_\theta J(\theta) = \mathbb{E}_{\pi_\theta}[\nabla_\theta \log \pi_\theta(a|s) Q^\pi(s, a)]
```

## 5. 自然语言处理

### 5.1 语言模型

**n-gram模型**：

```math
P(w_n | w_1^{n-1}) = \frac{\text{count}(w_1^n)}{\text{count}(w_1^{n-1})}
```

**神经语言模型**：

```math
P(w_t | w_{t-n+1}^{t-1}) = \text{softmax}(f(w_{t-n+1}^{t-1}))
```

### 5.2 词嵌入

**Word2Vec目标函数**：

```math
J = \frac{1}{T} \sum_{t=1}^{T} \sum_{-c \leq j \leq c, j \neq 0} \log P(w_{t+j} | w_t)
```

**注意力机制**：

```math
\text{Attention}(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V
```

### 5.3 Transformer

**多头注意力**：

```math
\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, ..., \text{head}_h)W^O
```

其中：

```math
\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)
```

## 6. 计算机视觉

### 6.1 图像处理基础

**卷积滤波**：

```math
I'(x, y) = \sum_{i=-k}^{k} \sum_{j=-k}^{k} I(x+i, y+j) \cdot K(i, j)
```

**边缘检测**：

```math
|\nabla I| = \sqrt{(\frac{\partial I}{\partial x})^2 + (\frac{\partial I}{\partial y})^2}
```

### 6.2 目标检测

**IoU (Intersection over Union)**：

```math
\text{IoU} = \frac{\text{Area of Intersection}}{\text{Area of Union}}
```

**非极大值抑制**：

```math
\text{NMS}(B, S, \tau) = \{b_i | S_i > \tau \land \max_{j \neq i} \text{IoU}(b_i, b_j) < \tau\}
```

### 6.3 图像分割

**语义分割损失**：

```math
L = -\sum_{i=1}^{N} \sum_{c=1}^{C} y_{ic} \log(\hat{y}_{ic})
```

## 7. Python实现

### 7.1 机器学习基础框架

```python
import numpy as np
import matplotlib.pyplot as plt
from typing import List, Tuple, Optional, Callable
from dataclasses import dataclass
from abc import ABC, abstractmethod
import random

@dataclass
class Dataset:
    """数据集"""
    X: np.ndarray
    y: np.ndarray
    
    def __post_init__(self):
        assert len(self.X) == len(self.y), "X and y must have same length"
    
    def __len__(self):
        return len(self.X)
    
    def split(self, ratio: float = 0.8) -> Tuple['Dataset', 'Dataset']:
        """分割数据集"""
        n = len(self)
        split_idx = int(n * ratio)
        
        train_X = self.X[:split_idx]
        train_y = self.y[:split_idx]
        test_X = self.X[split_idx:]
        test_y = self.y[split_idx:]
        
        return Dataset(train_X, train_y), Dataset(test_X, test_y)

class Model(ABC):
    """模型抽象基类"""
    
    @abstractmethod
    def fit(self, X: np.ndarray, y: np.ndarray):
        """训练模型"""
        pass
    
    @abstractmethod
    def predict(self, X: np.ndarray) -> np.ndarray:
        """预测"""
        pass
    
    def score(self, X: np.ndarray, y: np.ndarray) -> float:
        """评估模型"""
        y_pred = self.predict(X)
        return np.mean(y_pred == y)

class LinearRegression(Model):
    """线性回归"""
    
    def __init__(self, learning_rate: float = 0.01, max_iter: int = 1000):
        self.learning_rate = learning_rate
        self.max_iter = max_iter
        self.weights: Optional[np.ndarray] = None
        self.bias: Optional[float] = None
        self.history: List[float] = []
    
    def fit(self, X: np.ndarray, y: np.ndarray):
        """训练线性回归模型"""
        n_samples, n_features = X.shape
        
        # 初始化参数
        self.weights = np.random.randn(n_features)
        self.bias = 0.0
        
        for iteration in range(self.max_iter):
            # 前向传播
            y_pred = self._predict(X)
            
            # 计算梯度
            dw = (2/n_samples) * np.dot(X.T, (y_pred - y))
            db = (2/n_samples) * np.sum(y_pred - y)
            
            # 更新参数
            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db
            
            # 记录损失
            loss = np.mean((y_pred - y) ** 2)
            self.history.append(loss)
    
    def _predict(self, X: np.ndarray) -> np.ndarray:
        """内部预测函数"""
        return np.dot(X, self.weights) + self.bias
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """预测"""
        return self._predict(X)
    
    def plot_training_history(self):
        """绘制训练历史"""
        plt.figure(figsize=(10, 6))
        plt.plot(self.history)
        plt.title('Training Loss')
        plt.xlabel('Iteration')
        plt.ylabel('Loss')
        plt.grid(True)
        plt.show()

class LogisticRegression(Model):
    """逻辑回归"""
    
    def __init__(self, learning_rate: float = 0.01, max_iter: int = 1000):
        self.learning_rate = learning_rate
        self.max_iter = max_iter
        self.weights: Optional[np.ndarray] = None
        self.bias: Optional[float] = None
        self.history: List[float] = []
    
    def _sigmoid(self, z: np.ndarray) -> np.ndarray:
        """sigmoid函数"""
        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))
    
    def fit(self, X: np.ndarray, y: np.ndarray):
        """训练逻辑回归模型"""
        n_samples, n_features = X.shape
        
        # 初始化参数
        self.weights = np.random.randn(n_features)
        self.bias = 0.0
        
        for iteration in range(self.max_iter):
            # 前向传播
            z = np.dot(X, self.weights) + self.bias
            y_pred = self._sigmoid(z)
            
            # 计算梯度
            dw = (1/n_samples) * np.dot(X.T, (y_pred - y))
            db = (1/n_samples) * np.sum(y_pred - y)
            
            # 更新参数
            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db
            
            # 记录损失
            loss = -np.mean(y * np.log(y_pred + 1e-15) + (1 - y) * np.log(1 - y_pred + 1e-15))
            self.history.append(loss)
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """预测"""
        z = np.dot(X, self.weights) + self.bias
        y_pred = self._sigmoid(z)
        return (y_pred > 0.5).astype(int)

# 示例：线性回归
def generate_linear_data(n_samples: int = 100, noise: float = 0.1) -> Dataset:
    """生成线性数据"""
    X = np.random.randn(n_samples, 1)
    y = 2 * X.flatten() + 1 + noise * np.random.randn(n_samples)
    return Dataset(X, y)

def test_linear_regression():
    """测试线性回归"""
    print("=== 线性回归测试 ===")
    
    # 生成数据
    dataset = generate_linear_data(n_samples=100, noise=0.1)
    train_data, test_data = dataset.split(ratio=0.8)
    
    # 训练模型
    model = LinearRegression(learning_rate=0.01, max_iter=1000)
    model.fit(train_data.X, train_data.y)
    
    # 评估模型
    train_score = model.score(train_data.X, train_data.y)
    test_score = model.score(test_data.X, test_data.y)
    
    print(f"训练集准确率: {train_score:.4f}")
    print(f"测试集准确率: {test_score:.4f}")
    print(f"学习到的权重: {model.weights[0]:.4f}")
    print(f"学习到的偏置: {model.bias:.4f}")
    
    # 绘制结果
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    plt.scatter(train_data.X, train_data.y, alpha=0.6, label='训练数据')
    X_line = np.linspace(train_data.X.min(), train_data.X.max(), 100).reshape(-1, 1)
    y_line = model.predict(X_line)
    plt.plot(X_line, y_line, 'r-', label='预测线')
    plt.xlabel('X')
    plt.ylabel('y')
    plt.title('线性回归结果')
    plt.legend()
    
    plt.subplot(1, 2, 2)
    model.plot_training_history()
    
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    test_linear_regression()
```

### 7.2 神经网络实现

```python
class NeuralNetwork:
    """简单神经网络"""
    
    def __init__(self, layers: List[int], learning_rate: float = 0.01):
        self.layers = layers
        self.learning_rate = learning_rate
        self.weights = []
        self.biases = []
        self.history = []
        
        # 初始化权重和偏置
        for i in range(len(layers) - 1):
            w = np.random.randn(layers[i + 1], layers[i]) * 0.01
            b = np.zeros((layers[i + 1], 1))
            self.weights.append(w)
            self.biases.append(b)
    
    def _sigmoid(self, z: np.ndarray) -> np.ndarray:
        """sigmoid激活函数"""
        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))
    
    def _sigmoid_derivative(self, z: np.ndarray) -> np.ndarray:
        """sigmoid导数"""
        s = self._sigmoid(z)
        return s * (1 - s)
    
    def _relu(self, z: np.ndarray) -> np.ndarray:
        """ReLU激活函数"""
        return np.maximum(0, z)
    
    def _relu_derivative(self, z: np.ndarray) -> np.ndarray:
        """ReLU导数"""
        return np.where(z > 0, 1, 0)
    
    def forward(self, X: np.ndarray) -> Tuple[List[np.ndarray], List[np.ndarray]]:
        """前向传播"""
        activations = [X]
        z_values = []
        
        for i in range(len(self.weights)):
            z = np.dot(self.weights[i], activations[-1]) + self.biases[i]
            z_values.append(z)
            
            if i == len(self.weights) - 1:
                # 输出层使用sigmoid
                activation = self._sigmoid(z)
            else:
                # 隐藏层使用ReLU
                activation = self._relu(z)
            
            activations.append(activation)
        
        return activations, z_values
    
    def backward(self, X: np.ndarray, y: np.ndarray, activations: List[np.ndarray], z_values: List[np.ndarray]):
        """反向传播"""
        m = X.shape[1]
        delta = activations[-1] - y
        
        for i in range(len(self.weights) - 1, -1, -1):
            # 计算梯度
            dw = np.dot(delta, activations[i].T) / m
            db = np.sum(delta, axis=1, keepdims=True) / m
            
            # 更新参数
            self.weights[i] -= self.learning_rate * dw
            self.biases[i] -= self.learning_rate * db
            
            # 计算下一层的误差
            if i > 0:
                delta = np.dot(self.weights[i].T, delta) * self._relu_derivative(z_values[i - 1])
    
    def fit(self, X: np.ndarray, y: np.ndarray, epochs: int = 1000):
        """训练神经网络"""
        for epoch in range(epochs):
            # 前向传播
            activations, z_values = self.forward(X)
            
            # 反向传播
            self.backward(X, y, activations, z_values)
            
            # 计算损失
            if epoch % 100 == 0:
                loss = -np.mean(y * np.log(activations[-1] + 1e-15) + 
                               (1 - y) * np.log(1 - activations[-1] + 1e-15))
                self.history.append(loss)
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """预测"""
        activations, _ = self.forward(X)
        return (activations[-1] > 0.5).astype(int)
    
    def score(self, X: np.ndarray, y: np.ndarray) -> float:
        """评估模型"""
        y_pred = self.predict(X)
        return np.mean(y_pred == y)

# 示例：XOR问题
def generate_xor_data() -> Dataset:
    """生成XOR数据"""
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]).T
    y = np.array([[0, 1, 1, 0]])
    return Dataset(X.T, y.T)

def test_neural_network():
    """测试神经网络"""
    print("\n=== 神经网络测试 (XOR问题) ===")
    
    # 生成XOR数据
    dataset = generate_xor_data()
    
    # 创建神经网络 [2, 4, 1]
    nn = NeuralNetwork([2, 4, 1], learning_rate=0.1)
    
    # 训练模型
    nn.fit(dataset.X.T, dataset.y.T, epochs=10000)
    
    # 评估模型
    score = nn.score(dataset.X.T, dataset.y.T)
    print(f"XOR问题准确率: {score:.4f}")
    
    # 测试预测
    for i in range(len(dataset)):
        x = dataset.X[i:i+1].T
        y_true = dataset.y[i]
        y_pred = nn.predict(x)
        print(f"输入: {dataset.X[i]}, 真实值: {y_true[0]}, 预测值: {y_pred[0][0]}")
    
    # 绘制训练历史
    plt.figure(figsize=(10, 6))
    plt.plot(nn.history)
    plt.title('Neural Network Training Loss')
    plt.xlabel('Epoch (x100)')
    plt.ylabel('Loss')
    plt.grid(True)
    plt.show()

if __name__ == "__main__":
    test_neural_network()
```

### 7.3 强化学习实现

```python
class QLearningAgent:
    """Q-Learning智能体"""
    
    def __init__(self, state_size: int, action_size: int, learning_rate: float = 0.1, 
                 discount_factor: float = 0.95, epsilon: float = 0.1):
        self.state_size = state_size
        self.action_size = action_size
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.epsilon = epsilon
        
        # 初始化Q表
        self.q_table = np.zeros((state_size, action_size))
    
    def get_action(self, state: int) -> int:
        """选择动作（ε-贪婪策略）"""
        if random.random() < self.epsilon:
            return random.randint(0, self.action_size - 1)
        else:
            return np.argmax(self.q_table[state])
    
    def update(self, state: int, action: int, reward: float, next_state: int):
        """更新Q值"""
        old_value = self.q_table[state, action]
        next_max = np.max(self.q_table[next_state])
        
        new_value = (1 - self.learning_rate) * old_value + \
                   self.learning_rate * (reward + self.discount_factor * next_max)
        
        self.q_table[state, action] = new_value

class GridWorld:
    """网格世界环境"""
    
    def __init__(self, size: int = 4):
        self.size = size
        self.state = 0  # 起始状态
        self.goal = size * size - 1  # 目标状态
        
        # 定义动作：上、下、左、右
        self.actions = [(-1, 0), (1, 0), (0, -1), (0, 1)]
        self.action_names = ['上', '下', '左', '右']
    
    def reset(self) -> int:
        """重置环境"""
        self.state = 0
        return self.state
    
    def step(self, action: int) -> Tuple[int, float, bool]:
        """执行动作"""
        # 获取当前位置
        row = self.state // self.size
        col = self.state % self.size
        
        # 计算新位置
        new_row = row + self.actions[action][0]
        new_col = col + self.actions[action][1]
        
        # 检查边界
        if 0 <= new_row < self.size and 0 <= new_col < self.size:
            self.state = new_row * self.size + new_col
        
        # 计算奖励
        if self.state == self.goal:
            reward = 1.0
            done = True
        else:
            reward = -0.01  # 小的负奖励鼓励快速到达目标
            done = False
        
        return self.state, reward, done
    
    def render(self):
        """渲染环境"""
        grid = [[' ' for _ in range(self.size)] for _ in range(self.size)]
        
        # 标记智能体位置
        agent_row = self.state // self.size
        agent_col = self.state % self.size
        grid[agent_row][agent_col] = 'A'
        
        # 标记目标位置
        goal_row = self.goal // self.size
        goal_col = self.goal % self.size
        grid[goal_row][goal_col] = 'G'
        
        # 打印网格
        print('+' + '-' * (2 * self.size - 1) + '+')
        for row in grid:
            print('|' + '|'.join(row) + '|')
        print('+' + '-' * (2 * self.size - 1) + '+')

def test_q_learning():
    """测试Q-Learning"""
    print("\n=== Q-Learning测试 ===")
    
    # 创建环境和智能体
    env = GridWorld(size=4)
    agent = QLearningAgent(state_size=16, action_size=4)
    
    # 训练
    episodes = 1000
    episode_rewards = []
    
    for episode in range(episodes):
        state = env.reset()
        total_reward = 0
        steps = 0
        
        while steps < 100:  # 最大步数限制
            action = agent.get_action(state)
            next_state, reward, done = env.step(action)
            
            agent.update(state, action, reward, next_state)
            
            state = next_state
            total_reward += reward
            steps += 1
            
            if done:
                break
        
        episode_rewards.append(total_reward)
        
        if episode % 100 == 0:
            avg_reward = np.mean(episode_rewards[-100:])
            print(f"Episode {episode}, Average Reward: {avg_reward:.3f}")
    
    # 测试学习到的策略
    print("\n测试学习到的策略:")
    state = env.reset()
    env.render()
    
    for step in range(10):
        action = agent.get_action(state)
        print(f"步骤 {step + 1}: 选择动作 '{env.action_names[action]}'")
        
        state, reward, done = env.step(action)
        env.render()
        
        if done:
            print("到达目标!")
            break
    
    # 绘制训练曲线
    plt.figure(figsize=(10, 6))
    plt.plot(episode_rewards)
    plt.title('Q-Learning Training Progress')
    plt.xlabel('Episode')
    plt.ylabel('Total Reward')
    plt.grid(True)
    plt.show()

if __name__ == "__main__":
    test_q_learning()
```

## 8. 应用案例

### 8.1 图像分类

```python
import cv2
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

def load_mnist_data():
    """加载MNIST数据集"""
    print("加载MNIST数据集...")
    mnist = fetch_openml('mnist_784', version=1, as_frame=False)
    X, y = mnist.data, mnist.target.astype(int)
    
    # 只使用前1000个样本进行演示
    X = X[:1000] / 255.0  # 归一化
    y = y[:1000]
    
    return X, y

def test_image_classification():
    """测试图像分类"""
    print("\n=== 图像分类测试 ===")
    
    # 加载数据
    X, y = load_mnist_data()
    
    # 分割数据
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # 创建神经网络 [784, 128, 64, 10]
    nn = NeuralNetwork([784, 128, 64, 10], learning_rate=0.01)
    
    # 转换标签为one-hot编码
    y_train_onehot = np.zeros((len(y_train), 10))
    y_train_onehot[np.arange(len(y_train)), y_train] = 1
    
    # 训练模型
    print("训练神经网络...")
    nn.fit(X_train.T, y_train_onehot.T, epochs=1000)
    
    # 评估模型
    y_pred = nn.predict(X_test.T)
    accuracy = np.mean(y_pred.flatten() == y_test)
    print(f"测试集准确率: {accuracy:.4f}")
    
    # 显示一些预测结果
    plt.figure(figsize=(15, 5))
    for i in range(5):
        plt.subplot(1, 5, i + 1)
        plt.imshow(X_test[i].reshape(28, 28), cmap='gray')
        plt.title(f'真实: {y_test[i]}\n预测: {y_pred[0][i]}')
        plt.axis('off')
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    test_image_classification()
```

### 8.2 自然语言处理

```python
import re
from collections import Counter

class SimpleTokenizer:
    """简单分词器"""
    
    def __init__(self):
        self.word_to_idx = {}
        self.idx_to_word = {}
        self.vocab_size = 0
    
    def fit(self, texts: List[str]):
        """构建词汇表"""
        words = []
        for text in texts:
            words.extend(self._tokenize(text))
        
        # 构建词汇表
        word_counts = Counter(words)
        vocab = ['<PAD>', '<UNK>'] + [word for word, count in word_counts.most_common(1000)]
        
        self.word_to_idx = {word: idx for idx, word in enumerate(vocab)}
        self.idx_to_word = {idx: word for word, idx in self.word_to_idx.items()}
        self.vocab_size = len(vocab)
    
    def _tokenize(self, text: str) -> List[str]:
        """分词"""
        text = text.lower()
        text = re.sub(r'[^\w\s]', '', text)
        return text.split()
    
    def encode(self, text: str, max_length: int = 50) -> List[int]:
        """编码文本"""
        tokens = self._tokenize(text)
        encoded = [self.word_to_idx.get(token, self.word_to_idx['<UNK>']) for token in tokens]
        
        # 填充或截断
        if len(encoded) < max_length:
            encoded += [self.word_to_idx['<PAD>']] * (max_length - len(encoded))
        else:
            encoded = encoded[:max_length]
        
        return encoded

def test_nlp():
    """测试自然语言处理"""
    print("\n=== 自然语言处理测试 ===")
    
    # 示例文本
    texts = [
        "I love machine learning",
        "Deep learning is amazing",
        "Natural language processing is fun",
        "Artificial intelligence is the future",
        "Neural networks are powerful"
    ]
    
    # 创建分词器
    tokenizer = SimpleTokenizer()
    tokenizer.fit(texts)
    
    print(f"词汇表大小: {tokenizer.vocab_size}")
    print("词汇表前10个词:")
    for i in range(min(10, tokenizer.vocab_size)):
        print(f"  {i}: {tokenizer.idx_to_word[i]}")
    
    # 编码示例
    test_text = "I love deep learning"
    encoded = tokenizer.encode(test_text)
    print(f"\n文本: '{test_text}'")
    print(f"编码: {encoded}")
    
    # 解码
    decoded = [tokenizer.idx_to_word[idx] for idx in encoded if idx != tokenizer.word_to_idx['<PAD>']]
    print(f"解码: {decoded}")

if __name__ == "__main__":
    test_nlp()
```

## 9. 总结与展望

### 9.1 人工智能的优势

1. **自动化**：减少人工干预
2. **效率提升**：提高处理速度
3. **模式识别**：发现隐藏模式
4. **决策支持**：辅助决策制定

### 9.2 挑战与限制

1. **数据依赖**：需要大量高质量数据
2. **可解释性**：黑盒模型难以解释
3. **偏见问题**：可能继承数据偏见
4. **计算资源**：需要大量计算资源

### 9.3 未来发展方向

1. **可解释AI**：提高模型可解释性
2. **联邦学习**：保护隐私的分布式学习
3. **元学习**：学习如何学习
4. **量子机器学习**：结合量子计算

---

**相关链接**：

- [01-07-算法复杂度](./01-形式科学/01-07-算法复杂度.md)
- [03-03-算法设计](./03-具体科学/03-03-算法设计.md)
- [06-06-算法实现](./06-组件算法/06-06-算法实现.md)
- [07-01-项目案例](./07-实践应用/07-01-项目案例.md)
