# 机器学习基础

## 📋 概述

机器学习是人工智能的核心分支，通过算法让计算机从数据中学习模式和规律。本文档从形式化角度阐述机器学习的理论基础，并提供完整的Python实现。

## 1. 基本概念

### 1.1 机器学习定义

**定义 1.1** (机器学习)
机器学习是让计算机系统通过经验自动改进性能的算法集合。

**形式化定义**:
$$\text{ML} = (D, H, L, A)$$
其中：

- $D$ 是数据分布
- $H$ 是假设空间
- $L$ 是学习算法
- $A$ 是评估指标

### 1.2 学习类型

**定义 1.2** (监督学习)
监督学习是从标记数据中学习映射函数 $f: X \rightarrow Y$。

**定义 1.3** (无监督学习)
无监督学习是从未标记数据中发现隐藏模式。

**定义 1.4** (强化学习)
强化学习是通过与环境交互学习最优策略。

## 2. Python实现

### 2.1 基本数据结构

```python
from typing import Dict, List, Tuple, Optional, Any, Union, Callable
from dataclasses import dataclass, field
from enum import Enum
from abc import ABC, abstractmethod
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error
import matplotlib.pyplot as plt
import seaborn as sns

class LearningType(Enum):
    """学习类型"""
    SUPERVISED = "supervised"
    UNSUPERVISED = "unsupervised"
    REINFORCEMENT = "reinforcement"

class ModelType(Enum):
    """模型类型"""
    LINEAR_REGRESSION = "linear_regression"
    LOGISTIC_REGRESSION = "logistic_regression"
    DECISION_TREE = "decision_tree"
    RANDOM_FOREST = "random_forest"
    SVM = "svm"
    NEURAL_NETWORK = "neural_network"

@dataclass
class Dataset:
    """数据集"""
    X: np.ndarray
    y: Optional[np.ndarray] = None
    feature_names: Optional[List[str]] = None
    target_name: Optional[str] = None
    
    def __post_init__(self):
        if self.feature_names is None:
            self.feature_names = [f"feature_{i}" for i in range(self.X.shape[1])]
    
    def split(self, test_size: float = 0.2, random_state: int = 42) -> Tuple['Dataset', 'Dataset']:
        """分割数据集"""
        if self.y is None:
            raise ValueError("无监督学习数据集无法分割")
        
        X_train, X_test, y_train, y_test = train_test_split(
            self.X, self.y, test_size=test_size, random_state=random_state
        )
        
        train_dataset = Dataset(X_train, y_train, self.feature_names, self.target_name)
        test_dataset = Dataset(X_test, y_test, self.feature_names, self.target_name)
        
        return train_dataset, test_dataset
    
    def normalize(self) -> 'Dataset':
        """标准化数据"""
        mean = np.mean(self.X, axis=0)
        std = np.std(self.X, axis=0)
        X_normalized = (self.X - mean) / (std + 1e-8)
        
        return Dataset(X_normalized, self.y, self.feature_names, self.target_name)
    
    def __str__(self) -> str:
        return f"Dataset(shape={self.X.shape}, features={len(self.feature_names)})"

@dataclass
class Model:
    """模型基类"""
    model_type: ModelType
    parameters: Dict[str, Any] = field(default_factory=dict)
    is_trained: bool = False
    
    @abstractmethod
    def fit(self, dataset: Dataset) -> 'Model':
        """训练模型"""
        pass
    
    @abstractmethod
    def predict(self, X: np.ndarray) -> np.ndarray:
        """预测"""
        pass
    
    def evaluate(self, dataset: Dataset) -> Dict[str, float]:
        """评估模型"""
        if not self.is_trained:
            raise ValueError("模型尚未训练")
        
        predictions = self.predict(dataset.X)
        
        if dataset.y is None:
            return {"predictions": predictions}
        
        # 根据任务类型选择评估指标
        if len(np.unique(dataset.y)) <= 10:  # 分类任务
            accuracy = accuracy_score(dataset.y, predictions)
            return {"accuracy": accuracy}
        else:  # 回归任务
            mse = mean_squared_error(dataset.y, predictions)
            rmse = np.sqrt(mse)
            return {"mse": mse, "rmse": rmse}

class LinearRegression(Model):
    """线性回归模型"""
    
    def __init__(self, learning_rate: float = 0.01, max_iterations: int = 1000):
        super().__init__(ModelType.LINEAR_REGRESSION)
        self.learning_rate = learning_rate
        self.max_iterations = max_iterations
        self.weights = None
        self.bias = None
    
    def fit(self, dataset: Dataset) -> 'LinearRegression':
        """训练线性回归模型"""
        X, y = dataset.X, dataset.y
        if y is None:
            raise ValueError("线性回归需要标记数据")
        
        n_samples, n_features = X.shape
        
        # 初始化参数
        self.weights = np.zeros(n_features)
        self.bias = 0.0
        
        # 梯度下降
        for iteration in range(self.max_iterations):
            # 前向传播
            predictions = self._predict(X)
            
            # 计算梯度
            dw = (2 / n_samples) * np.dot(X.T, (predictions - y))
            db = (2 / n_samples) * np.sum(predictions - y)
            
            # 更新参数
            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db
            
            # 计算损失
            if iteration % 100 == 0:
                loss = np.mean((predictions - y) ** 2)
                print(f"Iteration {iteration}, Loss: {loss:.4f}")
        
        self.is_trained = True
        return self
    
    def _predict(self, X: np.ndarray) -> np.ndarray:
        """内部预测方法"""
        return np.dot(X, self.weights) + self.bias
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """预测"""
        if not self.is_trained:
            raise ValueError("模型尚未训练")
        return self._predict(X)
    
    def get_parameters(self) -> Dict[str, np.ndarray]:
        """获取模型参数"""
        return {
            "weights": self.weights,
            "bias": self.bias
        }

class LogisticRegression(Model):
    """逻辑回归模型"""
    
    def __init__(self, learning_rate: float = 0.01, max_iterations: int = 1000):
        super().__init__(ModelType.LOGISTIC_REGRESSION)
        self.learning_rate = learning_rate
        self.max_iterations = max_iterations
        self.weights = None
        self.bias = None
    
    def fit(self, dataset: Dataset) -> 'LogisticRegression':
        """训练逻辑回归模型"""
        X, y = dataset.X, dataset.y
        if y is None:
            raise ValueError("逻辑回归需要标记数据")
        
        n_samples, n_features = X.shape
        
        # 初始化参数
        self.weights = np.zeros(n_features)
        self.bias = 0.0
        
        # 梯度下降
        for iteration in range(self.max_iterations):
            # 前向传播
            predictions = self._predict_proba(X)
            
            # 计算梯度
            dw = (1 / n_samples) * np.dot(X.T, (predictions - y))
            db = (1 / n_samples) * np.sum(predictions - y)
            
            # 更新参数
            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db
            
            # 计算损失
            if iteration % 100 == 0:
                loss = self._compute_loss(y, predictions)
                print(f"Iteration {iteration}, Loss: {loss:.4f}")
        
        self.is_trained = True
        return self
    
    def _sigmoid(self, z: np.ndarray) -> np.ndarray:
        """Sigmoid函数"""
        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))
    
    def _predict_proba(self, X: np.ndarray) -> np.ndarray:
        """预测概率"""
        z = np.dot(X, self.weights) + self.bias
        return self._sigmoid(z)
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """预测"""
        if not self.is_trained:
            raise ValueError("模型尚未训练")
        probabilities = self._predict_proba(X)
        return (probabilities >= 0.5).astype(int)
    
    def _compute_loss(self, y: np.ndarray, predictions: np.ndarray) -> float:
        """计算交叉熵损失"""
        epsilon = 1e-15
        predictions = np.clip(predictions, epsilon, 1 - epsilon)
        return -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))

# 使用示例
def demonstrate_basic_ml():
    """演示基本机器学习"""
    print("=== 基本机器学习演示 ===\n")
    
    # 生成示例数据
    np.random.seed(42)
    n_samples = 1000
    n_features = 5
    
    # 生成特征
    X = np.random.randn(n_samples, n_features)
    
    # 生成线性回归目标
    true_weights = np.array([2.0, -1.5, 0.8, 1.2, -0.5])
    true_bias = 3.0
    y_regression = np.dot(X, true_weights) + true_bias + np.random.normal(0, 0.1, n_samples)
    
    # 生成分类目标
    y_classification = (np.dot(X, true_weights) + true_bias > 0).astype(int)
    
    # 创建数据集
    regression_dataset = Dataset(X, y_regression, 
                                [f"feature_{i}" for i in range(n_features)], "target")
    classification_dataset = Dataset(X, y_classification,
                                   [f"feature_{i}" for i in range(n_features)], "target")
    
    print(f"回归数据集: {regression_dataset}")
    print(f"分类数据集: {classification_dataset}")
    
    # 分割数据集
    train_reg, test_reg = regression_dataset.split()
    train_clf, test_clf = classification_dataset.split()
    
    # 训练线性回归模型
    print("\n=== 训练线性回归模型 ===")
    lr_model = LinearRegression(learning_rate=0.01, max_iterations=500)
    lr_model.fit(train_reg)
    
    # 评估线性回归模型
    lr_metrics = lr_model.evaluate(test_reg)
    print(f"线性回归评估结果: {lr_metrics}")
    
    # 训练逻辑回归模型
    print("\n=== 训练逻辑回归模型 ===")
    log_model = LogisticRegression(learning_rate=0.1, max_iterations=500)
    log_model.fit(train_clf)
    
    # 评估逻辑回归模型
    log_metrics = log_model.evaluate(test_clf)
    print(f"逻辑回归评估结果: {log_metrics}")

if __name__ == "__main__":
    demonstrate_basic_ml()
```

## 3. 决策树算法

### 3.1 决策树定义

**定义 3.1** (决策树)
决策树是一种树形结构，每个内部节点表示特征测试，每个叶节点表示预测结果。

**形式化定义**:
$$T = (N, E, F, L)$$
其中：

- $N$ 是节点集合
- $E$ 是边集合
- $F$ 是特征函数
- $L$ 是叶节点标签

### 3.2 Python实现

```python
@dataclass
class TreeNode:
    """决策树节点"""
    feature_index: Optional[int] = None
    threshold: Optional[float] = None
    left_child: Optional['TreeNode'] = None
    right_child: Optional['TreeNode'] = None
    is_leaf: bool = False
    prediction: Optional[Any] = None
    samples_count: int = 0

class DecisionTree(Model):
    """决策树模型"""
    
    def __init__(self, max_depth: int = 10, min_samples_split: int = 2):
        super().__init__(ModelType.DECISION_TREE)
        self.max_depth = max_depth
        self.min_samples_split = min_samples_split
        self.root = None
    
    def fit(self, dataset: Dataset) -> 'DecisionTree':
        """训练决策树"""
        X, y = dataset.X, dataset.y
        if y is None:
            raise ValueError("决策树需要标记数据")
        
        self.root = self._build_tree(X, y, depth=0)
        self.is_trained = True
        return self
    
    def _build_tree(self, X: np.ndarray, y: np.ndarray, depth: int) -> TreeNode:
        """构建决策树"""
        n_samples, n_features = X.shape
        n_classes = len(np.unique(y))
        
        # 停止条件
        if (depth >= self.max_depth or 
            n_samples < self.min_samples_split or 
            n_classes == 1):
            return self._create_leaf_node(y)
        
        # 寻找最佳分割
        best_feature, best_threshold, best_gain = self._find_best_split(X, y)
        
        if best_gain == 0:
            return self._create_leaf_node(y)
        
        # 创建分割
        left_mask = X[:, best_feature] <= best_threshold
        right_mask = ~left_mask
        
        # 创建节点
        node = TreeNode(
            feature_index=best_feature,
            threshold=best_threshold,
            samples_count=n_samples
        )
        
        # 递归构建子树
        node.left_child = self._build_tree(X[left_mask], y[left_mask], depth + 1)
        node.right_child = self._build_tree(X[right_mask], y[right_mask], depth + 1)
        
        return node
    
    def _find_best_split(self, X: np.ndarray, y: np.ndarray) -> Tuple[int, float, float]:
        """寻找最佳分割点"""
        n_samples, n_features = X.shape
        best_gain = 0
        best_feature = 0
        best_threshold = 0
        
        parent_entropy = self._compute_entropy(y)
        
        for feature in range(n_features):
            thresholds = np.unique(X[:, feature])
            
            for threshold in thresholds:
                left_mask = X[:, feature] <= threshold
                right_mask = ~left_mask
                
                if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:
                    continue
                
                # 计算信息增益
                left_entropy = self._compute_entropy(y[left_mask])
                right_entropy = self._compute_entropy(y[right_mask])
                
                left_weight = np.sum(left_mask) / n_samples
                right_weight = np.sum(right_mask) / n_samples
                
                gain = parent_entropy - (left_weight * left_entropy + right_weight * right_entropy)
                
                if gain > best_gain:
                    best_gain = gain
                    best_feature = feature
                    best_threshold = threshold
        
        return best_feature, best_threshold, best_gain
    
    def _compute_entropy(self, y: np.ndarray) -> float:
        """计算熵"""
        _, counts = np.unique(y, return_counts=True)
        probabilities = counts / len(y)
        entropy = -np.sum(probabilities * np.log2(probabilities + 1e-10))
        return entropy
    
    def _create_leaf_node(self, y: np.ndarray) -> TreeNode:
        """创建叶节点"""
        if len(np.unique(y)) <= 10:  # 分类任务
            prediction = np.argmax(np.bincount(y))
        else:  # 回归任务
            prediction = np.mean(y)
        
        return TreeNode(
            is_leaf=True,
            prediction=prediction,
            samples_count=len(y)
        )
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """预测"""
        if not self.is_trained:
            raise ValueError("模型尚未训练")
        
        predictions = []
        for sample in X:
            prediction = self._predict_single(sample, self.root)
            predictions.append(prediction)
        
        return np.array(predictions)
    
    def _predict_single(self, sample: np.ndarray, node: TreeNode) -> Any:
        """预测单个样本"""
        if node.is_leaf:
            return node.prediction
        
        if sample[node.feature_index] <= node.threshold:
            return self._predict_single(sample, node.left_child)
        else:
            return self._predict_single(sample, node.right_child)
    
    def print_tree(self, node: Optional[TreeNode] = None, depth: int = 0):
        """打印决策树"""
        if node is None:
            node = self.root
        
        indent = "  " * depth
        
        if node.is_leaf:
            print(f"{indent}预测: {node.prediction} (样本数: {node.samples_count})")
        else:
            print(f"{indent}特征{node.feature_index} <= {node.threshold:.3f}")
            print(f"{indent}├─ 左子树:")
            self.print_tree(node.left_child, depth + 1)
            print(f"{indent}└─ 右子树:")
            self.print_tree(node.right_child, depth + 1)

def demonstrate_decision_tree():
    """演示决策树"""
    print("=== 决策树演示 ===\n")
    
    # 生成分类数据
    np.random.seed(42)
    n_samples = 200
    
    # 创建两个类别的数据
    X1 = np.random.multivariate_normal([0, 0], [[1, 0], [0, 1]], n_samples // 2)
    X2 = np.random.multivariate_normal([2, 2], [[1, 0], [0, 1]], n_samples // 2)
    
    X = np.vstack([X1, X2])
    y = np.hstack([np.zeros(n_samples // 2), np.ones(n_samples // 2)])
    
    # 创建数据集
    dataset = Dataset(X, y, ["feature_1", "feature_2"], "class")
    train_dataset, test_dataset = dataset.split()
    
    # 训练决策树
    dt_model = DecisionTree(max_depth=5, min_samples_split=10)
    dt_model.fit(train_dataset)
    
    # 评估模型
    metrics = dt_model.evaluate(test_dataset)
    print(f"决策树评估结果: {metrics}")
    
    # 打印树结构
    print("\n决策树结构:")
    dt_model.print_tree()

if __name__ == "__main__":
    demonstrate_decision_tree()
```

## 4. 支持向量机

### 4.1 SVM定义

**定义 4.1** (支持向量机)
支持向量机是一种寻找最优超平面来分离数据的算法。

**形式化定义**:
$$\min_{w,b} \frac{1}{2}||w||^2 \text{ s.t. } y_i(w^T x_i + b) \geq 1, \forall i$$

### 4.2 Python实现

```python
class SVM(Model):
    """支持向量机模型"""
    
    def __init__(self, C: float = 1.0, learning_rate: float = 0.01, max_iterations: int = 1000):
        super().__init__(ModelType.SVM)
        self.C = C
        self.learning_rate = learning_rate
        self.max_iterations = max_iterations
        self.weights = None
        self.bias = None
        self.support_vectors = None
    
    def fit(self, dataset: Dataset) -> 'SVM':
        """训练SVM模型"""
        X, y = dataset.X, dataset.y
        if y is None:
            raise ValueError("SVM需要标记数据")
        
        # 将标签转换为{-1, 1}
        y_binary = 2 * y - 1
        
        n_samples, n_features = X.shape
        
        # 初始化参数
        self.weights = np.zeros(n_features)
        self.bias = 0.0
        
        # 梯度下降
        for iteration in range(self.max_iterations):
            # 计算梯度
            dw = np.zeros(n_features)
            db = 0
            
            for i in range(n_samples):
                margin = y_binary[i] * (np.dot(self.weights, X[i]) + self.bias)
                
                if margin < 1:
                    dw += -y_binary[i] * X[i]
                    db += -y_binary[i]
            
            # 添加正则化项
            dw += self.weights / self.C
            
            # 更新参数
            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db
            
            # 计算损失
            if iteration % 100 == 0:
                loss = self._compute_loss(X, y_binary)
                print(f"Iteration {iteration}, Loss: {loss:.4f}")
        
        # 找到支持向量
        self.support_vectors = self._find_support_vectors(X, y_binary)
        
        self.is_trained = True
        return self
    
    def _compute_loss(self, X: np.ndarray, y: np.ndarray) -> float:
        """计算铰链损失"""
        loss = 0
        for i in range(len(X)):
            margin = y[i] * (np.dot(self.weights, X[i]) + self.bias)
            loss += max(0, 1 - margin)
        
        # 添加正则化项
        loss += 0.5 * np.dot(self.weights, self.weights) / self.C
        return loss / len(X)
    
    def _find_support_vectors(self, X: np.ndarray, y: np.ndarray) -> np.ndarray:
        """找到支持向量"""
        support_vectors = []
        for i in range(len(X)):
            margin = y[i] * (np.dot(self.weights, X[i]) + self.bias)
            if abs(margin - 1) < 1e-5:  # 支持向量
                support_vectors.append(X[i])
        
        return np.array(support_vectors) if support_vectors else np.array([])
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """预测"""
        if not self.is_trained:
            raise ValueError("模型尚未训练")
        
        predictions = np.dot(X, self.weights) + self.bias
        return (predictions > 0).astype(int)
    
    def get_decision_boundary(self) -> Tuple[np.ndarray, float]:
        """获取决策边界"""
        return self.weights, self.bias

def demonstrate_svm():
    """演示SVM"""
    print("=== SVM演示 ===\n")
    
    # 生成线性可分的数据
    np.random.seed(42)
    n_samples = 100
    
    # 创建两个类别的数据
    X1 = np.random.multivariate_normal([0, 0], [[1, 0], [0, 1]], n_samples // 2)
    X2 = np.random.multivariate_normal([3, 3], [[1, 0], [0, 1]], n_samples // 2)
    
    X = np.vstack([X1, X2])
    y = np.hstack([np.zeros(n_samples // 2), np.ones(n_samples // 2)])
    
    # 创建数据集
    dataset = Dataset(X, y, ["feature_1", "feature_2"], "class")
    train_dataset, test_dataset = dataset.split()
    
    # 训练SVM
    svm_model = SVM(C=1.0, learning_rate=0.01, max_iterations=500)
    svm_model.fit(train_dataset)
    
    # 评估模型
    metrics = svm_model.evaluate(test_dataset)
    print(f"SVM评估结果: {metrics}")
    
    # 获取决策边界
    weights, bias = svm_model.get_decision_boundary()
    print(f"决策边界: {weights[0]}*x1 + {weights[1]}*x2 + {bias} = 0")
    
    # 支持向量数量
    print(f"支持向量数量: {len(svm_model.support_vectors)}")

if __name__ == "__main__":
    demonstrate_svm()
```

## 5. 神经网络

### 5.1 神经网络定义

**定义 5.1** (神经网络)
神经网络是由多个神经元层组成的计算模型。

**形式化定义**:
$$f(x) = \sigma(W_L \sigma(W_{L-1} \ldots \sigma(W_1 x + b_1) \ldots + b_{L-1}) + b_L)$$

### 5.2 Python实现

```python
class NeuralNetwork(Model):
    """神经网络模型"""
    
    def __init__(self, layers: List[int], learning_rate: float = 0.01, 
                 max_iterations: int = 1000):
        super().__init__(ModelType.NEURAL_NETWORK)
        self.layers = layers
        self.learning_rate = learning_rate
        self.max_iterations = max_iterations
        self.weights = []
        self.biases = []
        self._initialize_parameters()
    
    def _initialize_parameters(self):
        """初始化参数"""
        for i in range(len(self.layers) - 1):
            w = np.random.randn(self.layers[i + 1], self.layers[i]) * 0.01
            b = np.zeros((self.layers[i + 1], 1))
            self.weights.append(w)
            self.biases.append(b)
    
    def _sigmoid(self, z: np.ndarray) -> np.ndarray:
        """Sigmoid激活函数"""
        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))
    
    def _sigmoid_derivative(self, z: np.ndarray) -> np.ndarray:
        """Sigmoid导数"""
        s = self._sigmoid(z)
        return s * (1 - s)
    
    def _forward_propagation(self, X: np.ndarray) -> Tuple[List[np.ndarray], List[np.ndarray]]:
        """前向传播"""
        activations = [X.T]
        z_values = []
        
        for i in range(len(self.weights)):
            z = np.dot(self.weights[i], activations[-1]) + self.biases[i]
            z_values.append(z)
            activation = self._sigmoid(z)
            activations.append(activation)
        
        return activations, z_values
    
    def _backward_propagation(self, X: np.ndarray, y: np.ndarray, 
                            activations: List[np.ndarray], 
                            z_values: List[np.ndarray]) -> Tuple[List[np.ndarray], List[np.ndarray]]:
        """反向传播"""
        m = X.shape[0]
        y = y.reshape(1, -1)
        
        # 计算输出层误差
        delta = activations[-1] - y
        
        # 初始化梯度
        weight_gradients = []
        bias_gradients = []
        
        # 反向传播误差
        for i in range(len(self.weights) - 1, -1, -1):
            # 计算权重梯度
            dW = np.dot(delta, activations[i].T) / m
            db = np.sum(delta, axis=1, keepdims=True) / m
            
            weight_gradients.insert(0, dW)
            bias_gradients.insert(0, db)
            
            # 计算下一层的误差
            if i > 0:
                delta = np.dot(self.weights[i].T, delta) * self._sigmoid_derivative(z_values[i - 1])
        
        return weight_gradients, bias_gradients
    
    def fit(self, dataset: Dataset) -> 'NeuralNetwork':
        """训练神经网络"""
        X, y = dataset.X, dataset.y
        if y is None:
            raise ValueError("神经网络需要标记数据")
        
        for iteration in range(self.max_iterations):
            # 前向传播
            activations, z_values = self._forward_propagation(X)
            
            # 反向传播
            weight_gradients, bias_gradients = self._backward_propagation(
                X, y, activations, z_values
            )
            
            # 更新参数
            for i in range(len(self.weights)):
                self.weights[i] -= self.learning_rate * weight_gradients[i]
                self.biases[i] -= self.learning_rate * bias_gradients[i]
            
            # 计算损失
            if iteration % 100 == 0:
                loss = self._compute_loss(X, y)
                print(f"Iteration {iteration}, Loss: {loss:.4f}")
        
        self.is_trained = True
        return self
    
    def _compute_loss(self, X: np.ndarray, y: np.ndarray) -> float:
        """计算交叉熵损失"""
        activations, _ = self._forward_propagation(X)
        predictions = activations[-1].T
        
        epsilon = 1e-15
        predictions = np.clip(predictions, epsilon, 1 - epsilon)
        loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))
        return loss
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """预测"""
        if not self.is_trained:
            raise ValueError("模型尚未训练")
        
        activations, _ = self._forward_propagation(X)
        predictions = activations[-1].T
        return (predictions >= 0.5).astype(int).flatten()

def demonstrate_neural_network():
    """演示神经网络"""
    print("=== 神经网络演示 ===\n")
    
    # 生成XOR数据
    np.random.seed(42)
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    y = np.array([0, 1, 1, 0])
    
    # 创建数据集
    dataset = Dataset(X, y, ["input_1", "input_2"], "output")
    
    # 训练神经网络
    nn_model = NeuralNetwork(layers=[2, 4, 1], learning_rate=0.1, max_iterations=1000)
    nn_model.fit(dataset)
    
    # 评估模型
    metrics = nn_model.evaluate(dataset)
    print(f"神经网络评估结果: {metrics}")
    
    # 测试XOR
    print("\nXOR测试:")
    for i in range(len(X)):
        prediction = nn_model.predict(X[i:i+1])
        print(f"输入: {X[i]}, 预测: {prediction[0]}, 实际: {y[i]}")

if __name__ == "__main__":
    demonstrate_neural_network()
```

## 6. 模型评估

### 6.1 评估指标

```python
class ModelEvaluator:
    """模型评估器"""
    
    @staticmethod
    def cross_validation(model: Model, dataset: Dataset, k: int = 5) -> Dict[str, List[float]]:
        """K折交叉验证"""
        n_samples = len(dataset.X)
        fold_size = n_samples // k
        
        scores = []
        
        for i in range(k):
            # 分割数据
            start_idx = i * fold_size
            end_idx = start_idx + fold_size if i < k - 1 else n_samples
            
            # 创建验证集
            X_val = dataset.X[start_idx:end_idx]
            y_val = dataset.y[start_idx:end_idx] if dataset.y is not None else None
            val_dataset = Dataset(X_val, y_val, dataset.feature_names, dataset.target_name)
            
            # 创建训练集
            X_train = np.vstack([dataset.X[:start_idx], dataset.X[end_idx:]])
            y_train = np.hstack([dataset.y[:start_idx], dataset.y[end_idx:]]) if dataset.y is not None else None
            train_dataset = Dataset(X_train, y_train, dataset.feature_names, dataset.target_name)
            
            # 训练和评估
            model_copy = type(model)()  # 创建模型副本
            model_copy.fit(train_dataset)
            metrics = model_copy.evaluate(val_dataset)
            scores.append(metrics)
        
        # 汇总结果
        summary = {}
        for metric in scores[0].keys():
            values = [score[metric] for score in scores]
            summary[metric] = {
                'mean': np.mean(values),
                'std': np.std(values),
                'values': values
            }
        
        return summary
    
    @staticmethod
    def plot_learning_curve(model: Model, dataset: Dataset, 
                          train_sizes: List[float] = None) -> None:
        """绘制学习曲线"""
        if train_sizes is None:
            train_sizes = [0.1, 0.3, 0.5, 0.7, 0.9]
        
        train_scores = []
        val_scores = []
        
        for size in train_sizes:
            n_samples = int(len(dataset.X) * size)
            indices = np.random.choice(len(dataset.X), n_samples, replace=False)
            
            X_train = dataset.X[indices]
            y_train = dataset.y[indices] if dataset.y is not None else None
            train_dataset = Dataset(X_train, y_train, dataset.feature_names, dataset.target_name)
            
            # 分割验证集
            train_subset, val_subset = train_dataset.split(test_size=0.2)
            
            # 训练模型
            model_copy = type(model)()
            model_copy.fit(train_subset)
            
            # 评估
            train_metrics = model_copy.evaluate(train_subset)
            val_metrics = model_copy.evaluate(val_subset)
            
            train_scores.append(list(train_metrics.values())[0])
            val_scores.append(list(val_metrics.values())[0])
        
        # 绘制曲线
        plt.figure(figsize=(10, 6))
        plt.plot([len(dataset.X) * size for size in train_sizes], train_scores, 'o-', label='训练集')
        plt.plot([len(dataset.X) * size for size in train_sizes], val_scores, 'o-', label='验证集')
        plt.xlabel('训练样本数')
        plt.ylabel('准确率')
        plt.title('学习曲线')
        plt.legend()
        plt.grid(True)
        plt.show()

def demonstrate_model_evaluation():
    """演示模型评估"""
    print("=== 模型评估演示 ===\n")
    
    # 生成数据
    np.random.seed(42)
    n_samples = 1000
    n_features = 10
    
    X = np.random.randn(n_samples, n_features)
    y = (np.sum(X, axis=1) > 0).astype(int)
    
    dataset = Dataset(X, y, [f"feature_{i}" for i in range(n_features)], "target")
    
    # 创建模型
    models = [
        LogisticRegression(),
        DecisionTree(max_depth=5),
        SVM(C=1.0)
    ]
    
    # 交叉验证
    for model in models:
        print(f"\n{model.model_type.value} 交叉验证结果:")
        cv_results = ModelEvaluator.cross_validation(model, dataset, k=5)
        
        for metric, stats in cv_results.items():
            print(f"  {metric}: {stats['mean']:.4f} ± {stats['std']:.4f}")
    
    # 绘制学习曲线
    print("\n绘制学习曲线...")
    ModelEvaluator.plot_learning_curve(LogisticRegression(), dataset)

if __name__ == "__main__":
    demonstrate_model_evaluation()
```

## 7. 理论证明

### 7.1 学习理论

**定理 7.1** (VC维理论)
对于假设空间 $H$，如果VC维为 $d$，则泛化误差上界为：
$$\epsilon \leq \sqrt{\frac{d \log(2n/d) + \log(1/\delta)}{n}}$$

**证明思路**:

1. VC维衡量假设空间的复杂度
2. 复杂度越高，需要的样本越多
3. 泛化误差与样本数和复杂度相关

### 7.2 收敛性证明

**定理 7.2** (梯度下降收敛性)
对于凸函数，梯度下降算法能够收敛到全局最优解。

**证明**:

1. 凸函数具有唯一全局最优解
2. 梯度方向指向函数下降方向
3. 适当的学习率保证收敛

## 8. 应用实例

### 8.1 图像分类

```python
def demonstrate_image_classification():
    """演示图像分类"""
    print("=== 图像分类演示 ===\n")
    
    # 模拟图像数据
    np.random.seed(42)
    n_samples = 1000
    image_size = 28 * 28  # 28x28像素
    
    # 生成模拟图像特征
    X = np.random.randn(n_samples, image_size)
    
    # 生成标签（模拟手写数字分类）
    y = np.random.randint(0, 10, n_samples)
    
    dataset = Dataset(X, y, [f"pixel_{i}" for i in range(image_size)], "digit")
    train_dataset, test_dataset = dataset.split()
    
    # 训练多个模型
    models = {
        "逻辑回归": LogisticRegression(),
        "决策树": DecisionTree(max_depth=10),
        "SVM": SVM(C=1.0),
        "神经网络": NeuralNetwork(layers=[image_size, 128, 64, 10], learning_rate=0.01)
    }
    
    results = {}
    for name, model in models.items():
        print(f"训练 {name}...")
        model.fit(train_dataset)
        metrics = model.evaluate(test_dataset)
        results[name] = metrics
        print(f"{name} 准确率: {metrics.get('accuracy', 0):.4f}")
    
    # 比较结果
    print("\n模型比较:")
    for name, metrics in results.items():
        print(f"{name}: {metrics}")

if __name__ == "__main__":
    demonstrate_image_classification()
```

### 8.2 推荐系统

```python
class RecommendationSystem:
    """推荐系统"""
    
    def __init__(self, n_users: int, n_items: int, n_features: int = 10):
        self.n_users = n_users
        self.n_items = n_items
        self.n_features = n_features
        self.user_features = np.random.randn(n_users, n_features)
        self.item_features = np.random.randn(n_items, n_features)
    
    def predict_rating(self, user_id: int, item_id: int) -> float:
        """预测用户对物品的评分"""
        return np.dot(self.user_features[user_id], self.item_features[item_id])
    
    def recommend_items(self, user_id: int, n_recommendations: int = 5) -> List[int]:
        """为用户推荐物品"""
        predictions = []
        for item_id in range(self.n_items):
            rating = self.predict_rating(user_id, item_id)
            predictions.append((item_id, rating))
        
        # 按评分排序
        predictions.sort(key=lambda x: x[1], reverse=True)
        return [item_id for item_id, _ in predictions[:n_recommendations]]
    
    def train(self, ratings: List[Tuple[int, int, float]], 
             learning_rate: float = 0.01, max_iterations: int = 100):
        """训练推荐系统"""
        for iteration in range(max_iterations):
            total_loss = 0
            
            for user_id, item_id, true_rating in ratings:
                # 预测评分
                predicted_rating = self.predict_rating(user_id, item_id)
                
                # 计算误差
                error = true_rating - predicted_rating
                total_loss += error ** 2
                
                # 更新参数
                self.user_features[user_id] += learning_rate * error * self.item_features[item_id]
                self.item_features[item_id] += learning_rate * error * self.user_features[user_id]
            
            if iteration % 10 == 0:
                print(f"Iteration {iteration}, Loss: {total_loss:.4f}")

def demonstrate_recommendation_system():
    """演示推荐系统"""
    print("=== 推荐系统演示 ===\n")
    
    # 创建推荐系统
    n_users, n_items = 100, 50
    rec_system = RecommendationSystem(n_users, n_items)
    
    # 生成模拟评分数据
    np.random.seed(42)
    n_ratings = 1000
    ratings = []
    
    for _ in range(n_ratings):
        user_id = np.random.randint(0, n_users)
        item_id = np.random.randint(0, n_items)
        rating = np.random.randint(1, 6)  # 1-5分
        ratings.append((user_id, item_id, rating))
    
    # 训练推荐系统
    print("训练推荐系统...")
    rec_system.train(ratings, learning_rate=0.01, max_iterations=50)
    
    # 为用户推荐物品
    user_id = 0
    recommendations = rec_system.recommend_items(user_id, n_recommendations=5)
    print(f"为用户 {user_id} 推荐的物品: {recommendations}")
    
    # 预测评分
    item_id = 10
    predicted_rating = rec_system.predict_rating(user_id, item_id)
    print(f"用户 {user_id} 对物品 {item_id} 的预测评分: {predicted_rating:.2f}")

if __name__ == "__main__":
    demonstrate_recommendation_system()
```

## 9. 性能分析

### 9.1 时间复杂度

- **线性回归**: $O(n \times d \times iterations)$
- **逻辑回归**: $O(n \times d \times iterations)$
- **决策树**: $O(n \times d \times \log(n))$
- **SVM**: $O(n^2 \times d \times iterations)$
- **神经网络**: $O(n \times d \times L \times iterations)$

### 9.2 空间复杂度

- **线性/逻辑回归**: $O(d)$
- **决策树**: $O(n \times d)$
- **SVM**: $O(n \times d)$
- **神经网络**: $O(d \times L)$

## 10. 总结

本文档从形式化角度阐述了机器学习的理论基础，包括：

1. **基本概念**: 机器学习定义、学习类型、数据集结构
2. **经典算法**: 线性回归、逻辑回归、决策树、SVM、神经网络
3. **模型评估**: 交叉验证、学习曲线、评估指标
4. **理论证明**: 学习理论、收敛性分析
5. **应用实例**: 图像分类、推荐系统

所有概念都有完整的Python实现，包括：

- 完整的机器学习算法实现
- 模型训练和评估框架
- 数据预处理和特征工程
- 实际应用示例
- 性能分析和优化

机器学习为人工智能应用提供了强大的理论基础和实用工具。

---

*最后更新: 2024-12-19*
*下次更新: 完成深度学习文档后*
