# ä»£ç è´¨é‡æœ€ä½³å®è·µ

## ğŸ“‹ æ¦‚è¿°

ä»£ç è´¨é‡æ˜¯è½¯ä»¶å·¥ç¨‹çš„æ ¸å¿ƒè¦ç´ ï¼Œæ¶‰åŠä»£ç è§„èŒƒã€è®¾è®¡æ¨¡å¼ã€é‡æ„æŠ€æœ¯ç­‰ã€‚æœ¬æ–‡æ¡£æä¾›ä»£ç è´¨é‡çš„å½¢å¼åŒ–å®šä¹‰ã€æŠ€æœ¯æ¶æ„å’Œæœ€ä½³å®è·µã€‚

## 1. å½¢å¼åŒ–å®šä¹‰

### 1.1 ä»£ç è´¨é‡ç³»ç»Ÿå®šä¹‰

**å®šä¹‰ 1.1** (ä»£ç è´¨é‡ç³»ç»Ÿ)
ä»£ç è´¨é‡ç³»ç»Ÿæ˜¯ä¸€ä¸ªä¸ƒå…ƒç»„ $\mathcal{Q} = (S, R, T, M, C, A, E)$ï¼Œå…¶ä¸­ï¼š

- $S$ æ˜¯ä»£ç æ ‡å‡†ï¼Œ$S = (F, N, C, D)$
- $R$ æ˜¯é‡æ„è§„åˆ™ï¼Œ$R = (P, T, V)$
- $T$ æ˜¯æµ‹è¯•ç­–ç•¥ï¼Œ$T = (U, I, E)$
- $M$ æ˜¯åº¦é‡æŒ‡æ ‡ï¼Œ$M = (C, M, D)$
- $C$ æ˜¯ä»£ç å®¡æŸ¥ï¼Œ$C = (R, F, A)$
- $A$ æ˜¯è‡ªåŠ¨åŒ–å·¥å…·ï¼Œ$A = (L, F, T)$
- $E$ æ˜¯æŒç»­æ”¹è¿›ï¼Œ$E = (M, A, O)$

**å®šä¹‰ 1.2** (ä»£ç è´¨é‡åº¦é‡)
ä»£ç è´¨é‡åº¦é‡æ˜¯ä¸€ä¸ªå‡½æ•° $f: C \rightarrow Q$ï¼Œå…¶ä¸­ï¼š

- $C$ æ˜¯ä»£ç é›†åˆ
- $Q$ æ˜¯è´¨é‡åˆ†æ•°ï¼Œ$Q \in [0, 1]$

### 1.2 ä»£ç è´¨é‡æ ‡å‡†

**å®šä¹‰ 1.3** (ä»£ç è´¨é‡æ ‡å‡†)
ä»£ç è´¨é‡æ ‡å‡†æ˜¯ä¸€ä¸ªå››å…ƒç»„ $\mathcal{S} = (R, M, C, P)$ï¼Œå…¶ä¸­ï¼š

- $R$ æ˜¯å¯è¯»æ€§ï¼Œ$R = (N, C, F)$
- $M$ æ˜¯å¯ç»´æŠ¤æ€§ï¼Œ$M = (S, M, T)$
- $C$ æ˜¯å¤æ‚æ€§ï¼Œ$C = (C, D, N)$
- $P$ æ˜¯æ€§èƒ½ï¼Œ$P = (T, M, E)$

## 2. æŠ€æœ¯å®ç°

### 2.1 ä»£ç è´¨é‡æ£€æŸ¥å™¨

```python
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum
import ast
import re
import time
import logging
from pathlib import Path
import subprocess
import json

class QualityLevel(Enum):
    """è´¨é‡ç­‰çº§"""
    EXCELLENT = "excellent"
    GOOD = "good"
    FAIR = "fair"
    POOR = "poor"
    CRITICAL = "critical"

class IssueType(Enum):
    """é—®é¢˜ç±»å‹"""
    STYLE = "style"
    COMPLEXITY = "complexity"
    SECURITY = "security"
    PERFORMANCE = "performance"
    MAINTAINABILITY = "maintainability"

@dataclass
class CodeIssue:
    """ä»£ç é—®é¢˜"""
    file_path: str
    line_number: int
    column: int
    issue_type: IssueType
    severity: QualityLevel
    message: str
    code: str
    suggestion: Optional[str] = None

@dataclass
class QualityMetrics:
    """è´¨é‡æŒ‡æ ‡"""
    cyclomatic_complexity: float = 0.0
    lines_of_code: int = 0
    comment_ratio: float = 0.0
    test_coverage: float = 0.0
    maintainability_index: float = 0.0
    technical_debt: float = 0.0

class CodeAnalyzer(ABC):
    """ä»£ç åˆ†æå™¨æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def analyze(self, file_path: str) -> List[CodeIssue]:
        """åˆ†æä»£ç æ–‡ä»¶"""
        pass
    
    @abstractmethod
    def get_metrics(self, file_path: str) -> QualityMetrics:
        """è·å–è´¨é‡æŒ‡æ ‡"""
        pass

class StyleAnalyzer(CodeAnalyzer):
    """ä»£ç é£æ ¼åˆ†æå™¨"""
    
    def __init__(self):
        self.style_rules = {
            "line_length": 79,
            "function_length": 50,
            "class_length": 500,
            "variable_naming": r"^[a-z_][a-z0-9_]*$",
            "constant_naming": r"^[A-Z_][A-Z0-9_]*$",
            "class_naming": r"^[A-Z][a-zA-Z0-9]*$"
        }
    
    def analyze(self, file_path: str) -> List[CodeIssue]:
        """åˆ†æä»£ç é£æ ¼"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            for line_num, line in enumerate(lines, 1):
                # æ£€æŸ¥è¡Œé•¿åº¦
                if len(line.rstrip()) > self.style_rules["line_length"]:
                    issues.append(CodeIssue(
                        file_path=file_path,
                        line_number=line_num,
                        column=0,
                        issue_type=IssueType.STYLE,
                        severity=QualityLevel.FAIR,
                        message=f"Line too long ({len(line.rstrip())} characters)",
                        code=line.strip(),
                        suggestion="Break long lines or use line continuation"
                    ))
                
                # æ£€æŸ¥ç¼©è¿›
                if line.strip() and not line.startswith(' ' * 4) and not line.startswith('\t'):
                    if not line.startswith('#'):
                        issues.append(CodeIssue(
                            file_path=file_path,
                            line_number=line_num,
                            column=0,
                            issue_type=IssueType.STYLE,
                            severity=QualityLevel.POOR,
                            message="Inconsistent indentation",
                            code=line.strip(),
                            suggestion="Use 4 spaces for indentation"
                        ))
        
        except Exception as e:
            logging.error(f"Error analyzing {file_path}: {e}")
        
        return issues
    
    def get_metrics(self, file_path: str) -> QualityMetrics:
        """è·å–é£æ ¼æŒ‡æ ‡"""
        metrics = QualityMetrics()
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            metrics.lines_of_code = len(lines)
            
            # è®¡ç®—æ³¨é‡Šæ¯”ä¾‹
            comment_lines = sum(1 for line in lines if line.strip().startswith('#'))
            metrics.comment_ratio = comment_lines / max(metrics.lines_of_code, 1)
        
        except Exception as e:
            logging.error(f"Error getting metrics for {file_path}: {e}")
        
        return metrics

class ComplexityAnalyzer(CodeAnalyzer):
    """å¤æ‚åº¦åˆ†æå™¨"""
    
    def __init__(self):
        self.complexity_threshold = 10
    
    def analyze(self, file_path: str) -> List[CodeIssue]:
        """åˆ†æä»£ç å¤æ‚åº¦"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                tree = ast.parse(f.read())
            
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    complexity = self._calculate_cyclomatic_complexity(node)
                    
                    if complexity > self.complexity_threshold:
                        issues.append(CodeIssue(
                            file_path=file_path,
                            line_number=node.lineno,
                            column=node.col_offset,
                            issue_type=IssueType.COMPLEXITY,
                            severity=QualityLevel.POOR,
                            message=f"Function too complex (complexity: {complexity})",
                            code=ast.unparse(node),
                            suggestion="Break function into smaller functions"
                        ))
        
        except Exception as e:
            logging.error(f"Error analyzing complexity for {file_path}: {e}")
        
        return issues
    
    def _calculate_cyclomatic_complexity(self, node: ast.AST) -> int:
        """è®¡ç®—åœˆå¤æ‚åº¦"""
        complexity = 1  # åŸºç¡€å¤æ‚åº¦
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        
        return complexity
    
    def get_metrics(self, file_path: str) -> QualityMetrics:
        """è·å–å¤æ‚åº¦æŒ‡æ ‡"""
        metrics = QualityMetrics()
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                tree = ast.parse(f.read())
            
            total_complexity = 0
            function_count = 0
            
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    total_complexity += self._calculate_cyclomatic_complexity(node)
                    function_count += 1
            
            metrics.cyclomatic_complexity = total_complexity / max(function_count, 1)
        
        except Exception as e:
            logging.error(f"Error getting complexity metrics for {file_path}: {e}")
        
        return metrics

class SecurityAnalyzer(CodeAnalyzer):
    """å®‰å…¨åˆ†æå™¨"""
    
    def __init__(self):
        self.security_patterns = {
            r"eval\(": "Use of eval() is dangerous",
            r"exec\(": "Use of exec() is dangerous",
            r"subprocess\.call\(": "Potential command injection",
            r"os\.system\(": "Potential command injection",
            r"pickle\.loads\(": "Unsafe deserialization",
            r"input\(": "Unsafe user input",
            r"password.*=.*['\"][^'\"]*['\"]": "Hardcoded password",
            r"secret.*=.*['\"][^'\"]*['\"]": "Hardcoded secret"
        }
    
    def analyze(self, file_path: str) -> List[CodeIssue]:
        """åˆ†æå®‰å…¨æ¼æ´"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            for line_num, line in enumerate(lines, 1):
                for pattern, message in self.security_patterns.items():
                    if re.search(pattern, line, re.IGNORECASE):
                        issues.append(CodeIssue(
                            file_path=file_path,
                            line_number=line_num,
                            column=0,
                            issue_type=IssueType.SECURITY,
                            severity=QualityLevel.CRITICAL,
                            message=message,
                            code=line.strip(),
                            suggestion="Review and fix security vulnerability"
                        ))
        
        except Exception as e:
            logging.error(f"Error analyzing security for {file_path}: {e}")
        
        return issues
    
    def get_metrics(self, file_path: str) -> QualityMetrics:
        """è·å–å®‰å…¨æŒ‡æ ‡"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥è®¡ç®—å®‰å…¨é£é™©åˆ†æ•°
        return QualityMetrics()

class PerformanceAnalyzer(CodeAnalyzer):
    """æ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self):
        self.performance_patterns = {
            r"for.*in.*range\(len\(": "Inefficient iteration",
            r"\.append\(.*\)": "Consider using list comprehension",
            r"\.join\(\[.*\]\)": "Inefficient string concatenation",
            r"import \*": "Wildcard import",
            r"global ": "Global variable usage"
        }
    
    def analyze(self, file_path: str) -> List[CodeIssue]:
        """åˆ†ææ€§èƒ½é—®é¢˜"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            for line_num, line in enumerate(lines, 1):
                for pattern, message in self.performance_patterns.items():
                    if re.search(pattern, line):
                        issues.append(CodeIssue(
                            file_path=file_path,
                            line_number=line_num,
                            column=0,
                            issue_type=IssueType.PERFORMANCE,
                            severity=QualityLevel.FAIR,
                            message=message,
                            code=line.strip(),
                            suggestion="Optimize for better performance"
                        ))
        
        except Exception as e:
            logging.error(f"Error analyzing performance for {file_path}: {e}")
        
        return issues
    
    def get_metrics(self, file_path: str) -> QualityMetrics:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥åˆ†ææ€§èƒ½ç“¶é¢ˆ
        return QualityMetrics()

class CodeQualityManager:
    """ä»£ç è´¨é‡ç®¡ç†å™¨"""
    
    def __init__(self):
        self.analyzers = {
            IssueType.STYLE: StyleAnalyzer(),
            IssueType.COMPLEXITY: ComplexityAnalyzer(),
            IssueType.SECURITY: SecurityAnalyzer(),
            IssueType.PERFORMANCE: PerformanceAnalyzer()
        }
        self.issues: List[CodeIssue] = []
        self.metrics: Dict[str, QualityMetrics] = {}
    
    def analyze_file(self, file_path: str) -> Dict[IssueType, List[CodeIssue]]:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        file_issues = {}
        
        for issue_type, analyzer in self.analyzers.items():
            issues = analyzer.analyze(file_path)
            file_issues[issue_type] = issues
            self.issues.extend(issues)
        
        # è·å–è´¨é‡æŒ‡æ ‡
        self.metrics[file_path] = self._aggregate_metrics(file_path)
        
        return file_issues
    
    def analyze_directory(self, directory_path: str) -> Dict[str, Dict[IssueType, List[CodeIssue]]]:
        """åˆ†ææ•´ä¸ªç›®å½•"""
        results = {}
        
        for file_path in Path(directory_path).rglob("*.py"):
            if not self._should_skip_file(file_path):
                results[str(file_path)] = self.analyze_file(str(file_path))
        
        return results
    
    def _should_skip_file(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶"""
        skip_patterns = [
            "__pycache__",
            ".git",
            ".venv",
            "venv",
            "node_modules",
            "*.pyc"
        ]
        
        for pattern in skip_patterns:
            if pattern in str(file_path):
                return True
        
        return False
    
    def _aggregate_metrics(self, file_path: str) -> QualityMetrics:
        """èšåˆè´¨é‡æŒ‡æ ‡"""
        aggregated = QualityMetrics()
        
        for analyzer in self.analyzers.values():
            metrics = analyzer.get_metrics(file_path)
            aggregated.cyclomatic_complexity += metrics.cyclomatic_complexity
            aggregated.lines_of_code = max(aggregated.lines_of_code, metrics.lines_of_code)
            aggregated.comment_ratio = max(aggregated.comment_ratio, metrics.comment_ratio)
            aggregated.test_coverage += metrics.test_coverage
            aggregated.maintainability_index += metrics.maintainability_index
            aggregated.technical_debt += metrics.technical_debt
        
        # è®¡ç®—å¹³å‡å€¼
        analyzer_count = len(self.analyzers)
        aggregated.cyclomatic_complexity /= analyzer_count
        aggregated.test_coverage /= analyzer_count
        aggregated.maintainability_index /= analyzer_count
        aggregated.technical_debt /= analyzer_count
        
        return aggregated
    
    def get_quality_score(self) -> float:
        """è®¡ç®—æ€»ä½“è´¨é‡åˆ†æ•°"""
        if not self.issues:
            return 1.0
        
        # æ ¹æ®é—®é¢˜ä¸¥é‡ç¨‹åº¦è®¡ç®—åˆ†æ•°
        severity_weights = {
            QualityLevel.EXCELLENT: 0.0,
            QualityLevel.GOOD: 0.1,
            QualityLevel.FAIR: 0.3,
            QualityLevel.POOR: 0.6,
            QualityLevel.CRITICAL: 1.0
        }
        
        total_weight = 0
        for issue in self.issues:
            total_weight += severity_weights[issue.severity]
        
        average_weight = total_weight / len(self.issues)
        return max(0.0, 1.0 - average_weight)
    
    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        return {
            "summary": {
                "total_files": len(self.metrics),
                "total_issues": len(self.issues),
                "quality_score": self.get_quality_score(),
                "analysis_timestamp": time.time()
            },
            "issues_by_type": self._group_issues_by_type(),
            "issues_by_severity": self._group_issues_by_severity(),
            "metrics": {path: self._metrics_to_dict(metrics) for path, metrics in self.metrics.items()},
            "recommendations": self._generate_recommendations()
        }
    
    def _group_issues_by_type(self) -> Dict[IssueType, int]:
        """æŒ‰ç±»å‹åˆ†ç»„é—®é¢˜"""
        grouped = {}
        for issue in self.issues:
            grouped[issue.issue_type] = grouped.get(issue.issue_type, 0) + 1
        return grouped
    
    def _group_issues_by_severity(self) -> Dict[QualityLevel, int]:
        """æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„é—®é¢˜"""
        grouped = {}
        for issue in self.issues:
            grouped[issue.severity] = grouped.get(issue.severity, 0) + 1
        return grouped
    
    def _metrics_to_dict(self, metrics: QualityMetrics) -> Dict[str, Any]:
        """è½¬æ¢æŒ‡æ ‡ä¸ºå­—å…¸"""
        return {
            "cyclomatic_complexity": metrics.cyclomatic_complexity,
            "lines_of_code": metrics.lines_of_code,
            "comment_ratio": metrics.comment_ratio,
            "test_coverage": metrics.test_coverage,
            "maintainability_index": metrics.maintainability_index,
            "technical_debt": metrics.technical_debt
        }
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # åŸºäºé—®é¢˜ç±»å‹ç”Ÿæˆå»ºè®®
        if IssueType.STYLE in self._group_issues_by_type():
            recommendations.append("Improve code style and formatting")
        
        if IssueType.COMPLEXITY in self._group_issues_by_type():
            recommendations.append("Reduce code complexity by breaking down large functions")
        
        if IssueType.SECURITY in self._group_issues_by_type():
            recommendations.append("Address security vulnerabilities immediately")
        
        if IssueType.PERFORMANCE in self._group_issues_by_type():
            recommendations.append("Optimize performance-critical code sections")
        
        return recommendations
```

### 2.2 ä»£ç é‡æ„å·¥å…·

```python
class CodeRefactoringTool:
    """ä»£ç é‡æ„å·¥å…·"""
    
    def __init__(self):
        self.refactoring_patterns = {
            "extract_method": self._extract_method,
            "rename_variable": self._rename_variable,
            "simplify_condition": self._simplify_condition,
            "remove_duplicate": self._remove_duplicate
        }
    
    def refactor_file(self, file_path: str, refactoring_type: str, **kwargs) -> bool:
        """é‡æ„æ–‡ä»¶"""
        if refactoring_type not in self.refactoring_patterns:
            return False
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ‰§è¡Œé‡æ„
            new_content = self.refactoring_patterns[refactoring_type](content, **kwargs)
            
            # å†™å›æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            return True
        
        except Exception as e:
            logging.error(f"Error refactoring {file_path}: {e}")
            return False
    
    def _extract_method(self, content: str, method_name: str, 
                       start_line: int, end_line: int) -> str:
        """æå–æ–¹æ³•"""
        lines = content.split('\n')
        
        # æå–è¦é‡æ„çš„ä»£ç 
        method_code = lines[start_line-1:end_line]
        
        # åˆ›å»ºæ–°æ–¹æ³•
        new_method = f"\ndef {method_name}():\n"
        new_method += "    " + "\n    ".join(method_code) + "\n"
        
        # æ›¿æ¢åŸä»£ç 
        lines[start_line-1:end_line] = [f"    {method_name}()"]
        
        # æ’å…¥æ–°æ–¹æ³•
        lines.insert(start_line-1, new_method)
        
        return '\n'.join(lines)
    
    def _rename_variable(self, content: str, old_name: str, new_name: str) -> str:
        """é‡å‘½åå˜é‡"""
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢å˜é‡å
        pattern = r'\b' + re.escape(old_name) + r'\b'
        return re.sub(pattern, new_name, content)
    
    def _simplify_condition(self, content: str, condition: str, 
                           simplified: str) -> str:
        """ç®€åŒ–æ¡ä»¶"""
        return content.replace(condition, simplified)
    
    def _remove_duplicate(self, content: str) -> str:
        """ç§»é™¤é‡å¤ä»£ç """
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨æ›´å¤æ‚çš„ç®—æ³•
        lines = content.split('\n')
        seen = set()
        unique_lines = []
        
        for line in lines:
            stripped = line.strip()
            if stripped and stripped not in seen:
                seen.add(stripped)
                unique_lines.append(line)
            elif not stripped:
                unique_lines.append(line)
        
        return '\n'.join(unique_lines)
```

### 2.3 ä»£ç å®¡æŸ¥ç³»ç»Ÿ

```python
class CodeReview:
    """ä»£ç å®¡æŸ¥"""
    
    def __init__(self, reviewer: str, author: str):
        self.reviewer = reviewer
        self.author = author
        self.comments: List[Dict] = []
        self.status = "pending"
        self.created_at = time.time()
    
    def add_comment(self, file_path: str, line_number: int, 
                   message: str, severity: QualityLevel = QualityLevel.FAIR):
        """æ·»åŠ å®¡æŸ¥è¯„è®º"""
        comment = {
            "file_path": file_path,
            "line_number": line_number,
            "message": message,
            "severity": severity,
            "timestamp": time.time(),
            "reviewer": self.reviewer
        }
        self.comments.append(comment)
    
    def approve(self):
        """æ‰¹å‡†ä»£ç """
        self.status = "approved"
    
    def reject(self, reason: str):
        """æ‹’ç»ä»£ç """
        self.status = "rejected"
        self.comments.append({
            "message": f"Rejected: {reason}",
            "severity": QualityLevel.CRITICAL,
            "timestamp": time.time(),
            "reviewer": self.reviewer
        })
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–å®¡æŸ¥æ‘˜è¦"""
        return {
            "reviewer": self.reviewer,
            "author": self.author,
            "status": self.status,
            "total_comments": len(self.comments),
            "created_at": self.created_at,
            "comments": self.comments
        }

class CodeReviewSystem:
    """ä»£ç å®¡æŸ¥ç³»ç»Ÿ"""
    
    def __init__(self):
        self.reviews: Dict[str, CodeReview] = {}
        self.review_templates = {
            "security": [
                "Check for security vulnerabilities",
                "Verify input validation",
                "Review authentication and authorization"
            ],
            "performance": [
                "Check for performance bottlenecks",
                "Review algorithm efficiency",
                "Verify resource usage"
            ],
            "maintainability": [
                "Check code readability",
                "Review function complexity",
                "Verify documentation quality"
            ]
        }
    
    def create_review(self, review_id: str, reviewer: str, author: str) -> CodeReview:
        """åˆ›å»ºä»£ç å®¡æŸ¥"""
        review = CodeReview(reviewer, author)
        self.reviews[review_id] = review
        return review
    
    def get_review(self, review_id: str) -> Optional[CodeReview]:
        """è·å–ä»£ç å®¡æŸ¥"""
        return self.reviews.get(review_id)
    
    def get_review_template(self, template_type: str) -> List[str]:
        """è·å–å®¡æŸ¥æ¨¡æ¿"""
        return self.review_templates.get(template_type, [])
    
    def generate_review_report(self, review_id: str) -> Dict[str, Any]:
        """ç”Ÿæˆå®¡æŸ¥æŠ¥å‘Š"""
        review = self.get_review(review_id)
        if not review:
            return {}
        
        summary = review.get_summary()
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„è¯„è®º
        comments_by_severity = {}
        for comment in review.comments:
            severity = comment["severity"]
            if severity not in comments_by_severity:
                comments_by_severity[severity] = []
            comments_by_severity[severity].append(comment)
        
        return {
            "summary": summary,
            "comments_by_severity": comments_by_severity,
            "recommendations": self._generate_review_recommendations(review)
        }
    
    def _generate_review_recommendations(self, review: CodeReview) -> List[str]:
        """ç”Ÿæˆå®¡æŸ¥å»ºè®®"""
        recommendations = []
        
        critical_comments = [c for c in review.comments 
                           if c["severity"] == QualityLevel.CRITICAL]
        if critical_comments:
            recommendations.append("Address critical issues before approval")
        
        if len(review.comments) > 10:
            recommendations.append("Consider breaking down the changes into smaller PRs")
        
        return recommendations
```

## 3. å®é™…åº”ç”¨ç¤ºä¾‹

### 3.1 å®Œæ•´çš„ä»£ç è´¨é‡ç®¡ç†ç³»ç»Ÿ

```python
class CodeQualityManagementSystem:
    """å®Œæ•´çš„ä»£ç è´¨é‡ç®¡ç†ç³»ç»Ÿ"""
    
    def __init__(self):
        self.quality_manager = CodeQualityManager()
        self.refactoring_tool = CodeRefactoringTool()
        self.review_system = CodeReviewSystem()
        self.config = {
            "quality_threshold": 0.8,
            "max_complexity": 10,
            "min_test_coverage": 0.8
        }
    
    def analyze_project(self, project_path: str) -> Dict[str, Any]:
        """åˆ†ææ•´ä¸ªé¡¹ç›®"""
        # åˆ†æä»£ç è´¨é‡
        analysis_results = self.quality_manager.analyze_directory(project_path)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.quality_manager.generate_report()
        
        # æ£€æŸ¥è´¨é‡é˜ˆå€¼
        quality_score = self.quality_manager.get_quality_score()
        meets_threshold = quality_score >= self.config["quality_threshold"]
        
        return {
            "analysis_results": analysis_results,
            "quality_report": report,
            "quality_score": quality_score,
            "meets_threshold": meets_threshold,
            "recommendations": self._generate_project_recommendations(report)
        }
    
    def auto_refactor(self, file_path: str) -> bool:
        """è‡ªåŠ¨é‡æ„æ–‡ä»¶"""
        # åˆ†ææ–‡ä»¶
        issues = self.quality_manager.analyze_file(file_path)
        
        # åº”ç”¨é‡æ„
        refactored = False
        
        # å¤„ç†å¤æ‚åº¦é—®é¢˜
        complexity_issues = issues.get(IssueType.COMPLEXITY, [])
        for issue in complexity_issues:
            if "Function too complex" in issue.message:
                # å°è¯•æå–æ–¹æ³•
                refactored = self.refactoring_tool.refactor_file(
                    file_path, "extract_method",
                    method_name="extracted_method",
                    start_line=issue.line_number,
                    end_line=issue.line_number + 10
                )
        
        return refactored
    
    def create_code_review(self, review_id: str, reviewer: str, 
                          author: str, files: List[str]) -> CodeReview:
        """åˆ›å»ºä»£ç å®¡æŸ¥"""
        review = self.review_system.create_review(review_id, reviewer, author)
        
        # è‡ªåŠ¨åˆ†ææ–‡ä»¶å¹¶æ·»åŠ è¯„è®º
        for file_path in files:
            issues = self.quality_manager.analyze_file(file_path)
            
            for issue_type, file_issues in issues.items():
                for issue in file_issues:
                    if issue.severity in [QualityLevel.POOR, QualityLevel.CRITICAL]:
                        review.add_comment(
                            file_path=issue.file_path,
                            line_number=issue.line_number,
                            message=issue.message,
                            severity=issue.severity
                        )
        
        return review
    
    def _generate_project_recommendations(self, report: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆé¡¹ç›®å»ºè®®"""
        recommendations = []
        
        quality_score = report["summary"]["quality_score"]
        if quality_score < self.config["quality_threshold"]:
            recommendations.append(f"Increase code quality score to {self.config['quality_threshold']}")
        
        issues_by_type = report["issues_by_type"]
        if IssueType.SECURITY in issues_by_type:
            recommendations.append("Address security issues immediately")
        
        if IssueType.COMPLEXITY in issues_by_type:
            recommendations.append("Reduce code complexity")
        
        return recommendations
    
    def generate_quality_dashboard(self, project_path: str) -> Dict[str, Any]:
        """ç”Ÿæˆè´¨é‡ä»ªè¡¨æ¿"""
        analysis = self.analyze_project(project_path)
        
        return {
            "project_name": Path(project_path).name,
            "analysis_date": time.time(),
            "quality_score": analysis["quality_score"],
            "quality_level": self._get_quality_level(analysis["quality_score"]),
            "issues_summary": analysis["quality_report"]["summary"],
            "top_issues": self._get_top_issues(analysis["quality_report"]),
            "trends": self._get_quality_trends(project_path),
            "recommendations": analysis["recommendations"]
        }
    
    def _get_quality_level(self, score: float) -> str:
        """è·å–è´¨é‡ç­‰çº§"""
        if score >= 0.9:
            return "Excellent"
        elif score >= 0.8:
            return "Good"
        elif score >= 0.7:
            return "Fair"
        elif score >= 0.6:
            return "Poor"
        else:
            return "Critical"
    
    def _get_top_issues(self, report: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è·å–ä¸»è¦é—®é¢˜"""
        issues_by_severity = report["issues_by_severity"]
        top_issues = []
        
        for severity, count in issues_by_severity.items():
            if severity in [QualityLevel.CRITICAL, QualityLevel.POOR]:
                top_issues.append({
                    "severity": severity.value,
                    "count": count,
                    "priority": "high" if severity == QualityLevel.CRITICAL else "medium"
                })
        
        return sorted(top_issues, key=lambda x: x["priority"] == "high", reverse=True)
    
    def _get_quality_trends(self, project_path: str) -> Dict[str, Any]:
        """è·å–è´¨é‡è¶‹åŠ¿"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ä»å†å²æ•°æ®ä¸­è·å–
        return {
            "trend": "improving",
            "change_rate": 0.05,
            "last_analysis": time.time() - 86400  # 1å¤©å‰
        }

# ä½¿ç”¨ç¤ºä¾‹
def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºè´¨é‡ç®¡ç†ç³»ç»Ÿ
    qms = CodeQualityManagementSystem()
    
    # åˆ†æé¡¹ç›®
    project_path = "."
    analysis = qms.analyze_project(project_path)
    
    print("Code Quality Analysis Report:")
    print(f"Quality Score: {analysis['quality_score']:.2f}")
    print(f"Meets Threshold: {analysis['meets_threshold']}")
    print(f"Total Issues: {analysis['quality_report']['summary']['total_issues']}")
    
    # ç”Ÿæˆä»ªè¡¨æ¿
    dashboard = qms.generate_quality_dashboard(project_path)
    print(f"\nQuality Level: {dashboard['quality_level']}")
    print(f"Top Issues: {len(dashboard['top_issues'])}")
    
    # åˆ›å»ºä»£ç å®¡æŸ¥
    review = qms.create_code_review(
        "review-001",
        "reviewer@example.com",
        "author@example.com",
        ["main.py"]
    )
    
    print(f"\nCode Review Status: {review.status}")
    print(f"Total Comments: {len(review.comments)}")

if __name__ == "__main__":
    main()
```

## 4. æ€»ç»“

### 4.1 æŠ€æœ¯è¦ç‚¹

1. **é™æ€åˆ†æ**: ä»£ç è´¨é‡è‡ªåŠ¨æ£€æŸ¥
2. **é‡æ„å·¥å…·**: è‡ªåŠ¨åŒ–ä»£ç é‡æ„
3. **å®¡æŸ¥ç³»ç»Ÿ**: ä»£ç å®¡æŸ¥æµç¨‹ç®¡ç†
4. **è´¨é‡åº¦é‡**: å®¢è§‚çš„è´¨é‡è¯„ä¼°æŒ‡æ ‡
5. **æŒç»­æ”¹è¿›**: è´¨é‡ç›‘æ§å’Œä¼˜åŒ–

### 4.2 æœ€ä½³å®è·µ

1. **è‡ªåŠ¨åŒ–æ£€æŸ¥**: é›†æˆåˆ°CI/CDæµç¨‹
2. **ä»£ç è§„èŒƒ**: ç»Ÿä¸€çš„ç¼–ç æ ‡å‡†
3. **å®šæœŸå®¡æŸ¥**: å®šæœŸçš„ä»£ç å®¡æŸ¥
4. **è´¨é‡é—¨ç¦**: è´¨é‡é˜ˆå€¼æ§åˆ¶
5. **æŒç»­ç›‘æ§**: è´¨é‡è¶‹åŠ¿è·Ÿè¸ª

### 4.3 æ‰©å±•æ–¹å‘

1. **AIè¾…åŠ©**: æœºå™¨å­¦ä¹ ä»£ç åˆ†æ
2. **å¯è§†åŒ–**: è´¨é‡æŒ‡æ ‡å¯è§†åŒ–
3. **é›†æˆå·¥å…·**: ä¸IDEå’ŒCI/CDé›†æˆ
4. **å›¢é˜Ÿåä½œ**: å›¢é˜Ÿè´¨é‡æ–‡åŒ–
5. **çŸ¥è¯†åº“**: æœ€ä½³å®è·µçŸ¥è¯†åº“

---

**ç›¸å…³æ–‡æ¡£**:

- [APIè®¾è®¡æœ€ä½³å®è·µ](./07-02-01-APIè®¾è®¡æœ€ä½³å®è·µ.md)
- [æµ‹è¯•æœ€ä½³å®è·µ](./07-02-03-æµ‹è¯•æœ€ä½³å®è·µ.md)
- [æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ](./07-02-04-æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ.md)
