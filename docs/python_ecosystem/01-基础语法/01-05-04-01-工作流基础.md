# å·¥ä½œæµæ¶æ„åŸºç¡€

## ğŸ“‹ æ¦‚è¿°

å·¥ä½œæµæ¶æ„æ˜¯å¤„ç†å¤æ‚ä¸šåŠ¡æµç¨‹çš„ç³»ç»Ÿè®¾è®¡æ¨¡å¼ï¼Œé€šè¿‡å®šä¹‰ã€æ‰§è¡Œå’Œç›‘æ§ä¸šåŠ¡æµç¨‹æ¥å®ç°ä¸šåŠ¡é€»è¾‘çš„è‡ªåŠ¨åŒ–å’Œåè°ƒã€‚

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### å·¥ä½œæµå®šä¹‰

**å½¢å¼åŒ–å®šä¹‰**ï¼šå·¥ä½œæµæ˜¯ä¸€ä¸ªäº”å…ƒç»„ $WF = (S, T, E, I, F)$ï¼Œå…¶ä¸­ï¼š

- $S = \{s_1, s_2, ..., s_n\}$ æ˜¯çŠ¶æ€é›†åˆ
- $T = \{t_1, t_2, ..., t_m\}$ æ˜¯ä»»åŠ¡é›†åˆ
- $E = \{e_1, e_2, ..., e_k\}$ æ˜¯äº‹ä»¶é›†åˆ
- $I \subseteq S \times T \times S$ æ˜¯çŠ¶æ€è½¬æ¢å…³ç³»
- $F: S \rightarrow \{true, false\}$ æ˜¯ç»ˆæ­¢æ¡ä»¶å‡½æ•°

### å·¥ä½œæµæ‰§è¡Œ

**æ‰§è¡Œè·¯å¾„**ï¼šå·¥ä½œæµçš„æ‰§è¡Œè·¯å¾„æ˜¯ä¸€ä¸ªçŠ¶æ€åºåˆ— $P = (s_0, s_1, ..., s_n)$ï¼Œå…¶ä¸­ï¼š

- $s_0$ æ˜¯åˆå§‹çŠ¶æ€
- $(s_i, t_j, s_{i+1}) \in I$ å¯¹äºæ‰€æœ‰ $i < n$
- $F(s_n) = true$

## ğŸ”§ Pythonå®ç°

### å·¥ä½œæµå¼•æ“æ ¸å¿ƒ

```python
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Callable, Set
from dataclasses import dataclass, field
from enum import Enum
import asyncio
import json
import logging
from datetime import datetime
import uuid

# å·¥ä½œæµçŠ¶æ€
class WorkflowStatus(Enum):
    CREATED = "created"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    SUSPENDED = "suspended"

# ä»»åŠ¡çŠ¶æ€
class TaskStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    SKIPPED = "skipped"

# å·¥ä½œæµå®šä¹‰
@dataclass
class WorkflowDefinition:
    id: str
    name: str
    version: str
    description: str
    states: Dict[str, 'WorkflowState']
    initial_state: str
    final_states: Set[str]
    variables: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)

# å·¥ä½œæµçŠ¶æ€
@dataclass
class WorkflowState:
    id: str
    name: str
    tasks: List['WorkflowTask']
    transitions: List['StateTransition']
    entry_actions: List[Callable] = field(default_factory=list)
    exit_actions: List[Callable] = field(default_factory=list)
    timeout: Optional[int] = None

# å·¥ä½œæµä»»åŠ¡
@dataclass
class WorkflowTask:
    id: str
    name: str
    task_type: str
    parameters: Dict[str, Any]
    retry_policy: Optional['RetryPolicy'] = None
    timeout: Optional[int] = None
    dependencies: List[str] = field(default_factory=list)

# çŠ¶æ€è½¬æ¢
@dataclass
class StateTransition:
    from_state: str
    to_state: str
    condition: Optional[Callable] = None
    actions: List[Callable] = field(default_factory=list)
    event: Optional[str] = None

# é‡è¯•ç­–ç•¥
@dataclass
class RetryPolicy:
    max_attempts: int = 3
    initial_delay: float = 1.0
    max_delay: float = 60.0
    backoff_multiplier: float = 2.0
    retry_on_exceptions: List[type] = field(default_factory=list)

# å·¥ä½œæµå®ä¾‹
@dataclass
class WorkflowInstance:
    id: str
    definition_id: str
    status: WorkflowStatus
    current_state: str
    variables: Dict[str, Any]
    task_results: Dict[str, Any]
    history: List['WorkflowEvent']
    created_at: datetime
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    error_message: Optional[str] = None

# å·¥ä½œæµäº‹ä»¶
@dataclass
class WorkflowEvent:
    id: str
    timestamp: datetime
    event_type: str
    state: str
    task_id: Optional[str] = None
    data: Dict[str, Any] = field(default_factory=dict)

# å·¥ä½œæµå¼•æ“
class WorkflowEngine:
    """å·¥ä½œæµå¼•æ“æ ¸å¿ƒç±»"""
    
    def __init__(self):
        self.definitions: Dict[str, WorkflowDefinition] = {}
        self.instances: Dict[str, WorkflowInstance] = {}
        self.task_handlers: Dict[str, Callable] = {}
        self.logger = logging.getLogger("workflow_engine")
        
    def register_definition(self, definition: WorkflowDefinition) -> None:
        """æ³¨å†Œå·¥ä½œæµå®šä¹‰"""
        self.definitions[definition.id] = definition
        self.logger.info(f"Workflow definition registered: {definition.name}")
        
    def register_task_handler(self, task_type: str, handler: Callable) -> None:
        """æ³¨å†Œä»»åŠ¡å¤„ç†å™¨"""
        self.task_handlers[task_type] = handler
        self.logger.info(f"Task handler registered: {task_type}")
        
    async def create_instance(self, definition_id: str, variables: Dict[str, Any] = None) -> WorkflowInstance:
        """åˆ›å»ºå·¥ä½œæµå®ä¾‹"""
        if definition_id not in self.definitions:
            raise ValueError(f"Workflow definition not found: {definition_id}")
            
        definition = self.definitions[definition_id]
        
        instance = WorkflowInstance(
            id=str(uuid.uuid4()),
            definition_id=definition_id,
            status=WorkflowStatus.CREATED,
            current_state=definition.initial_state,
            variables=variables or {},
            task_results={},
            history=[],
            created_at=datetime.now()
        )
        
        self.instances[instance.id] = instance
        self.logger.info(f"Workflow instance created: {instance.id}")
        
        # è®°å½•åˆ›å»ºäº‹ä»¶
        self._record_event(instance, "instance_created", definition.initial_state)
        
        return instance
        
    async def start_instance(self, instance_id: str) -> None:
        """å¯åŠ¨å·¥ä½œæµå®ä¾‹"""
        instance = self.instances.get(instance_id)
        if not instance:
            raise ValueError(f"Workflow instance not found: {instance_id}")
            
        instance.status = WorkflowStatus.RUNNING
        instance.started_at = datetime.now()
        
        self._record_event(instance, "instance_started", instance.current_state)
        
        # å¼€å§‹æ‰§è¡Œ
        asyncio.create_task(self._execute_instance(instance))
        
    async def _execute_instance(self, instance: WorkflowInstance) -> None:
        """æ‰§è¡Œå·¥ä½œæµå®ä¾‹"""
        try:
            definition = self.definitions[instance.definition_id]
            
            while instance.status == WorkflowStatus.RUNNING:
                current_state = definition.states[instance.current_state]
                
                # æ‰§è¡Œè¿›å…¥åŠ¨ä½œ
                await self._execute_actions(current_state.entry_actions, instance)
                
                # æ‰§è¡Œä»»åŠ¡
                await self._execute_tasks(current_state.tasks, instance)
                
                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç»ˆæ­¢çŠ¶æ€
                if instance.current_state in definition.final_states:
                    instance.status = WorkflowStatus.COMPLETED
                    instance.completed_at = datetime.now()
                    self._record_event(instance, "instance_completed", instance.current_state)
                    break
                    
                # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªçŠ¶æ€
                next_state = await self._find_next_state(current_state, instance)
                if next_state:
                    # æ‰§è¡Œé€€å‡ºåŠ¨ä½œ
                    await self._execute_actions(current_state.exit_actions, instance)
                    
                    # è½¬æ¢åˆ°ä¸‹ä¸€ä¸ªçŠ¶æ€
                    instance.current_state = next_state
                    self._record_event(instance, "state_transition", next_state)
                else:
                    # æ²¡æœ‰æ‰¾åˆ°ä¸‹ä¸€ä¸ªçŠ¶æ€ï¼Œæš‚åœæ‰§è¡Œ
                    instance.status = WorkflowStatus.SUSPENDED
                    self._record_event(instance, "instance_suspended", instance.current_state)
                    break
                    
        except Exception as e:
            instance.status = WorkflowStatus.FAILED
            instance.error_message = str(e)
            instance.completed_at = datetime.now()
            self._record_event(instance, "instance_failed", instance.current_state, error=str(e))
            self.logger.error(f"Workflow execution failed: {e}")
            
    async def _execute_tasks(self, tasks: List[WorkflowTask], instance: WorkflowInstance) -> None:
        """æ‰§è¡Œä»»åŠ¡åˆ—è¡¨"""
        # æŒ‰ä¾èµ–å…³ç³»æ’åºä»»åŠ¡
        sorted_tasks = self._sort_tasks_by_dependencies(tasks)
        
        # å¹¶è¡Œæ‰§è¡Œæ²¡æœ‰ä¾èµ–å…³ç³»çš„ä»»åŠ¡
        task_groups = self._group_tasks_by_dependencies(sorted_tasks)
        
        for group in task_groups:
            # å¹¶è¡Œæ‰§è¡Œç»„å†…ä»»åŠ¡
            await asyncio.gather(*[
                self._execute_task(task, instance) for task in group
            ])
            
    async def _execute_task(self, task: WorkflowTask, instance: WorkflowInstance) -> Any:
        """æ‰§è¡Œå•ä¸ªä»»åŠ¡"""
        self._record_event(instance, "task_started", instance.current_state, task_id=task.id)
        
        try:
            # æ£€æŸ¥ä»»åŠ¡å¤„ç†å™¨
            if task.task_type not in self.task_handlers:
                raise ValueError(f"Task handler not found: {task.task_type}")
                
            handler = self.task_handlers[task.task_type]
            
            # æ‰§è¡Œä»»åŠ¡ï¼ˆå¸¦é‡è¯•ï¼‰
            result = await self._execute_with_retry(handler, task, instance)
            
            # ä¿å­˜ç»“æœ
            instance.task_results[task.id] = result
            
            self._record_event(instance, "task_completed", instance.current_state, task_id=task.id)
            return result
            
        except Exception as e:
            self._record_event(instance, "task_failed", instance.current_state, task_id=task.id, error=str(e))
            raise e
            
    async def _execute_with_retry(self, handler: Callable, task: WorkflowTask, instance: WorkflowInstance) -> Any:
        """å¸¦é‡è¯•çš„ä»»åŠ¡æ‰§è¡Œ"""
        if not task.retry_policy:
            return await handler(task.parameters, instance.variables)
            
        last_exception = None
        
        for attempt in range(task.retry_policy.max_attempts):
            try:
                return await handler(task.parameters, instance.variables)
            except Exception as e:
                last_exception = e
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•
                if (task.retry_policy.retry_on_exceptions and 
                    not any(isinstance(e, exc_type) for exc_type in task.retry_policy.retry_on_exceptions)):
                    raise e
                    
                if attempt < task.retry_policy.max_attempts - 1:
                    # è®¡ç®—å»¶è¿Ÿæ—¶é—´
                    delay = min(
                        task.retry_policy.initial_delay * (task.retry_policy.backoff_multiplier ** attempt),
                        task.retry_policy.max_delay
                    )
                    await asyncio.sleep(delay)
                    
        raise last_exception
        
    def _sort_tasks_by_dependencies(self, tasks: List[WorkflowTask]) -> List[WorkflowTask]:
        """æŒ‰ä¾èµ–å…³ç³»æ’åºä»»åŠ¡"""
        # ç®€åŒ–å®ç°ï¼šæ‹“æ‰‘æ’åº
        task_map = {task.id: task for task in tasks}
        result = []
        visited = set()
        
        def visit(task_id: str):
            if task_id in visited:
                return
            visited.add(task_id)
            
            task = task_map[task_id]
            for dep_id in task.dependencies:
                if dep_id in task_map:
                    visit(dep_id)
            result.append(task)
            
        for task in tasks:
            visit(task.id)
            
        return result
        
    def _group_tasks_by_dependencies(self, tasks: List[WorkflowTask]) -> List[List[WorkflowTask]]:
        """æŒ‰ä¾èµ–å…³ç³»åˆ†ç»„ä»»åŠ¡"""
        groups = []
        current_group = []
        
        for task in tasks:
            # æ£€æŸ¥å½“å‰ä»»åŠ¡æ˜¯å¦å¯ä»¥ä¸å½“å‰ç»„å¹¶è¡Œ
            can_parallel = True
            for group_task in current_group:
                if task.id in group_task.dependencies or group_task.id in task.dependencies:
                    can_parallel = False
                    break
                    
            if can_parallel:
                current_group.append(task)
            else:
                if current_group:
                    groups.append(current_group)
                current_group = [task]
                
        if current_group:
            groups.append(current_group)
            
        return groups
        
    async def _find_next_state(self, current_state: WorkflowState, instance: WorkflowInstance) -> Optional[str]:
        """æŸ¥æ‰¾ä¸‹ä¸€ä¸ªçŠ¶æ€"""
        for transition in current_state.transitions:
            if transition.condition is None or await transition.condition(instance.variables):
                # æ‰§è¡Œè½¬æ¢åŠ¨ä½œ
                await self._execute_actions(transition.actions, instance)
                return transition.to_state
        return None
        
    async def _execute_actions(self, actions: List[Callable], instance: WorkflowInstance) -> None:
        """æ‰§è¡ŒåŠ¨ä½œåˆ—è¡¨"""
        for action in actions:
            try:
                await action(instance.variables)
            except Exception as e:
                self.logger.error(f"Action execution failed: {e}")
                
    def _record_event(self, instance: WorkflowInstance, event_type: str, state: str, 
                     task_id: Optional[str] = None, error: Optional[str] = None) -> None:
        """è®°å½•å·¥ä½œæµäº‹ä»¶"""
        event = WorkflowEvent(
            id=str(uuid.uuid4()),
            timestamp=datetime.now(),
            event_type=event_type,
            state=state,
            task_id=task_id,
            data={"error": error} if error else {}
        )
        instance.history.append(event)
        
    def get_instance(self, instance_id: str) -> Optional[WorkflowInstance]:
        """è·å–å·¥ä½œæµå®ä¾‹"""
        return self.instances.get(instance_id)
        
    def list_instances(self, status: Optional[WorkflowStatus] = None) -> List[WorkflowInstance]:
        """åˆ—å‡ºå·¥ä½œæµå®ä¾‹"""
        instances = list(self.instances.values())
        if status:
            instances = [i for i in instances if i.status == status]
        return instances
```

### çŠ¶æ€æœºå®ç°

```python
from typing import Dict, Any, Optional, List, Callable
from dataclasses import dataclass
from enum import Enum

# çŠ¶æ€æœºçŠ¶æ€
class StateMachineState(Enum):
    IDLE = "idle"
    RUNNING = "running"
    COMPLETED = "completed"
    ERROR = "error"

# çŠ¶æ€æœºå®šä¹‰
@dataclass
class StateMachineDefinition:
    name: str
    states: Dict[str, 'StateDefinition']
    initial_state: str
    final_states: Set[str]
    transitions: List['TransitionDefinition']

# çŠ¶æ€å®šä¹‰
@dataclass
class StateDefinition:
    name: str
    entry_action: Optional[Callable] = None
    exit_action: Optional[Callable] = None
    timeout: Optional[int] = None
    auto_transition: Optional[str] = None

# è½¬æ¢å®šä¹‰
@dataclass
class TransitionDefinition:
    from_state: str
    to_state: str
    event: Optional[str] = None
    condition: Optional[Callable] = None
    action: Optional[Callable] = None

# çŠ¶æ€æœºå®ä¾‹
@dataclass
class StateMachineInstance:
    id: str
    definition: StateMachineDefinition
    current_state: str
    status: StateMachineState
    variables: Dict[str, Any]
    history: List[Dict[str, Any]]

# çŠ¶æ€æœºå¼•æ“
class StateMachineEngine:
    """çŠ¶æ€æœºå¼•æ“"""
    
    def __init__(self):
        self.definitions: Dict[str, StateMachineDefinition] = {}
        self.instances: Dict[str, StateMachineInstance] = {}
        self.logger = logging.getLogger("state_machine_engine")
        
    def register_definition(self, definition: StateMachineDefinition) -> None:
        """æ³¨å†ŒçŠ¶æ€æœºå®šä¹‰"""
        self.definitions[definition.name] = definition
        self.logger.info(f"State machine definition registered: {definition.name}")
        
    def create_instance(self, definition_name: str, variables: Dict[str, Any] = None) -> StateMachineInstance:
        """åˆ›å»ºçŠ¶æ€æœºå®ä¾‹"""
        if definition_name not in self.definitions:
            raise ValueError(f"State machine definition not found: {definition_name}")
            
        definition = self.definitions[definition_name]
        
        instance = StateMachineInstance(
            id=str(uuid.uuid4()),
            definition=definition,
            current_state=definition.initial_state,
            status=StateMachineState.IDLE,
            variables=variables or {},
            history=[]
        )
        
        self.instances[instance.id] = instance
        self.logger.info(f"State machine instance created: {instance.id}")
        
        return instance
        
    async def start_instance(self, instance_id: str) -> None:
        """å¯åŠ¨çŠ¶æ€æœºå®ä¾‹"""
        instance = self.instances.get(instance_id)
        if not instance:
            raise ValueError(f"State machine instance not found: {instance_id}")
            
        instance.status = StateMachineState.RUNNING
        await self._enter_state(instance, instance.current_state)
        
    async def send_event(self, instance_id: str, event: str, data: Dict[str, Any] = None) -> bool:
        """å‘é€äº‹ä»¶åˆ°çŠ¶æ€æœº"""
        instance = self.instances.get(instance_id)
        if not instance:
            raise ValueError(f"State machine instance not found: {instance_id}")
            
        if instance.status != StateMachineState.RUNNING:
            return False
            
        # æŸ¥æ‰¾åŒ¹é…çš„è½¬æ¢
        transition = self._find_transition(instance, event)
        if transition:
            await self._execute_transition(instance, transition, data)
            return True
        else:
            self.logger.warning(f"No transition found for event {event} in state {instance.current_state}")
            return False
            
    def _find_transition(self, instance: StateMachineInstance, event: str) -> Optional[TransitionDefinition]:
        """æŸ¥æ‰¾åŒ¹é…çš„è½¬æ¢"""
        for transition in instance.definition.transitions:
            if (transition.from_state == instance.current_state and 
                transition.event == event):
                # æ£€æŸ¥æ¡ä»¶
                if transition.condition is None or transition.condition(instance.variables):
                    return transition
        return None
        
    async def _execute_transition(self, instance: StateMachineInstance, 
                                transition: TransitionDefinition, data: Dict[str, Any] = None) -> None:
        """æ‰§è¡ŒçŠ¶æ€è½¬æ¢"""
        # æ‰§è¡Œé€€å‡ºåŠ¨ä½œ
        current_state_def = instance.definition.states[instance.current_state]
        if current_state_def.exit_action:
            await current_state_def.exit_action(instance.variables)
            
        # æ‰§è¡Œè½¬æ¢åŠ¨ä½œ
        if transition.action:
            await transition.action(instance.variables, data)
            
        # è®°å½•å†å²
        instance.history.append({
            "timestamp": datetime.now().isoformat(),
            "from_state": instance.current_state,
            "to_state": transition.to_state,
            "event": transition.event,
            "data": data
        })
        
        # æ›´æ–°çŠ¶æ€
        instance.current_state = transition.to_state
        
        # è¿›å…¥æ–°çŠ¶æ€
        await self._enter_state(instance, transition.to_state)
        
    async def _enter_state(self, instance: StateMachineInstance, state_name: str) -> None:
        """è¿›å…¥çŠ¶æ€"""
        state_def = instance.definition.states[state_name]
        
        # æ‰§è¡Œè¿›å…¥åŠ¨ä½œ
        if state_def.entry_action:
            await state_def.entry_action(instance.variables)
            
        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ç»ˆçŠ¶æ€
        if state_name in instance.definition.final_states:
            instance.status = StateMachineState.COMPLETED
            self.logger.info(f"State machine instance completed: {instance.id}")
        elif state_def.auto_transition:
            # è‡ªåŠ¨è½¬æ¢
            await asyncio.sleep(0.1)  # é¿å…ç«‹å³è½¬æ¢
            await self.send_event(instance.id, "auto", {})
            
    def get_instance(self, instance_id: str) -> Optional[StateMachineInstance]:
        """è·å–çŠ¶æ€æœºå®ä¾‹"""
        return self.instances.get(instance_id)
        
    def list_instances(self, status: Optional[StateMachineState] = None) -> List[StateMachineInstance]:
        """åˆ—å‡ºçŠ¶æ€æœºå®ä¾‹"""
        instances = list(self.instances.values())
        if status:
            instances = [i for i in instances if i.status == status]
        return instances
```

### ä¸šåŠ¡æµç¨‹å»ºæ¨¡

```python
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass
import json

# ä¸šåŠ¡æµç¨‹èŠ‚ç‚¹ç±»å‹
class NodeType(Enum):
    START = "start"
    TASK = "task"
    GATEWAY = "gateway"
    SUBPROCESS = "subprocess"
    END = "end"

# ç½‘å…³ç±»å‹
class GatewayType(Enum):
    EXCLUSIVE = "exclusive"  # æ’ä»–ç½‘å…³
    PARALLEL = "parallel"    # å¹¶è¡Œç½‘å…³
    INCLUSIVE = "inclusive"  # åŒ…å®¹ç½‘å…³

# ä¸šåŠ¡æµç¨‹èŠ‚ç‚¹
@dataclass
class ProcessNode:
    id: str
    name: str
    node_type: NodeType
    position: Dict[str, float]  # x, yåæ ‡
    properties: Dict[str, Any] = None
    gateway_type: Optional[GatewayType] = None
    
    def __post_init__(self):
        if self.properties is None:
            self.properties = {}

# ä¸šåŠ¡æµç¨‹è¿æ¥
@dataclass
class ProcessConnection:
    id: str
    source_node: str
    target_node: str
    condition: Optional[str] = None
    properties: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.properties is None:
            self.properties = {}

# ä¸šåŠ¡æµç¨‹å®šä¹‰
@dataclass
class ProcessDefinition:
    id: str
    name: str
    version: str
    nodes: Dict[str, ProcessNode]
    connections: List[ProcessConnection]
    variables: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.variables is None:
            self.variables = {}

# ä¸šåŠ¡æµç¨‹å®ä¾‹
@dataclass
class ProcessInstance:
    id: str
    definition_id: str
    status: WorkflowStatus
    current_nodes: List[str]
    variables: Dict[str, Any]
    token_positions: Dict[str, List[str]]  # ä»¤ç‰Œä½ç½®
    history: List[Dict[str, Any]]
    created_at: datetime
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None

# ä¸šåŠ¡æµç¨‹å¼•æ“
class ProcessEngine:
    """ä¸šåŠ¡æµç¨‹å¼•æ“"""
    
    def __init__(self):
        self.definitions: Dict[str, ProcessDefinition] = {}
        self.instances: Dict[str, ProcessInstance] = {}
        self.task_handlers: Dict[str, Callable] = {}
        self.logger = logging.getLogger("process_engine")
        
    def register_definition(self, definition: ProcessDefinition) -> None:
        """æ³¨å†Œä¸šåŠ¡æµç¨‹å®šä¹‰"""
        self.definitions[definition.id] = definition
        self.logger.info(f"Process definition registered: {definition.name}")
        
    def register_task_handler(self, task_name: str, handler: Callable) -> None:
        """æ³¨å†Œä»»åŠ¡å¤„ç†å™¨"""
        self.task_handlers[task_name] = handler
        self.logger.info(f"Task handler registered: {task_name}")
        
    def create_instance(self, definition_id: str, variables: Dict[str, Any] = None) -> ProcessInstance:
        """åˆ›å»ºä¸šåŠ¡æµç¨‹å®ä¾‹"""
        if definition_id not in self.definitions:
            raise ValueError(f"Process definition not found: {definition_id}")
            
        definition = self.definitions[definition_id]
        
        # æ‰¾åˆ°å¼€å§‹èŠ‚ç‚¹
        start_nodes = [node_id for node_id, node in definition.nodes.items() 
                      if node.node_type == NodeType.START]
        
        if not start_nodes:
            raise ValueError("No start node found in process definition")
            
        instance = ProcessInstance(
            id=str(uuid.uuid4()),
            definition_id=definition_id,
            status=WorkflowStatus.CREATED,
            current_nodes=start_nodes,
            variables=variables or {},
            token_positions={start_nodes[0]: ["token_1"]},
            history=[],
            created_at=datetime.now()
        )
        
        self.instances[instance.id] = instance
        self.logger.info(f"Process instance created: {instance.id}")
        
        return instance
        
    async def start_instance(self, instance_id: str) -> None:
        """å¯åŠ¨ä¸šåŠ¡æµç¨‹å®ä¾‹"""
        instance = self.instances.get(instance_id)
        if not instance:
            raise ValueError(f"Process instance not found: {instance_id}")
            
        instance.status = WorkflowStatus.RUNNING
        instance.started_at = datetime.now()
        
        # å¼€å§‹æ‰§è¡Œ
        asyncio.create_task(self._execute_instance(instance))
        
    async def _execute_instance(self, instance: ProcessInstance) -> None:
        """æ‰§è¡Œä¸šåŠ¡æµç¨‹å®ä¾‹"""
        try:
            definition = self.definitions[instance.definition_id]
            
            while instance.status == WorkflowStatus.RUNNING:
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯æ‰§è¡Œçš„èŠ‚ç‚¹
                executable_nodes = self._find_executable_nodes(instance, definition)
                
                if not executable_nodes:
                    # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                    if self._is_completed(instance, definition):
                        instance.status = WorkflowStatus.COMPLETED
                        instance.completed_at = datetime.now()
                        self.logger.info(f"Process instance completed: {instance.id}")
                        break
                    else:
                        # ç­‰å¾…æ›´å¤šä»¤ç‰Œ
                        await asyncio.sleep(1)
                        continue
                        
                # å¹¶è¡Œæ‰§è¡Œå¯æ‰§è¡ŒèŠ‚ç‚¹
                await asyncio.gather(*[
                    self._execute_node(instance, definition, node_id)
                    for node_id in executable_nodes
                ])
                
        except Exception as e:
            instance.status = WorkflowStatus.FAILED
            instance.completed_at = datetime.now()
            self.logger.error(f"Process execution failed: {e}")
            
    def _find_executable_nodes(self, instance: ProcessInstance, definition: ProcessDefinition) -> List[str]:
        """æŸ¥æ‰¾å¯æ‰§è¡Œçš„èŠ‚ç‚¹"""
        executable = []
        
        for node_id in instance.current_nodes:
            if node_id in instance.token_positions and instance.token_positions[node_id]:
                node = definition.nodes[node_id]
                if node.node_type == NodeType.TASK:
                    executable.append(node_id)
                elif node.node_type == NodeType.GATEWAY:
                    # ç½‘å…³éœ€è¦ç‰¹æ®Šå¤„ç†
                    pass
                    
        return executable
        
    async def _execute_node(self, instance: ProcessInstance, definition: ProcessDefinition, node_id: str) -> None:
        """æ‰§è¡ŒèŠ‚ç‚¹"""
        node = definition.nodes[node_id]
        
        if node.node_type == NodeType.TASK:
            await self._execute_task_node(instance, definition, node)
        elif node.node_type == NodeType.GATEWAY:
            await self._execute_gateway_node(instance, definition, node)
        elif node.node_type == NodeType.SUBPROCESS:
            await self._execute_subprocess_node(instance, definition, node)
            
    async def _execute_task_node(self, instance: ProcessInstance, definition: ProcessDefinition, node: ProcessNode) -> None:
        """æ‰§è¡Œä»»åŠ¡èŠ‚ç‚¹"""
        # æ¶ˆè´¹ä»¤ç‰Œ
        tokens = instance.token_positions[node.id]
        if tokens:
            tokens.pop(0)
            
        # æ‰§è¡Œä»»åŠ¡
        task_name = node.properties.get("task_name")
        if task_name and task_name in self.task_handlers:
            handler = self.task_handlers[task_name]
            await handler(node.properties, instance.variables)
            
        # ç”Ÿæˆè¾“å‡ºä»¤ç‰Œ
        output_connections = [conn for conn in definition.connections if conn.source_node == node.id]
        for connection in output_connections:
            if connection.target_node not in instance.token_positions:
                instance.token_positions[connection.target_node] = []
            instance.token_positions[connection.target_node].append(f"token_{uuid.uuid4()}")
            
        # è®°å½•å†å²
        instance.history.append({
            "timestamp": datetime.now().isoformat(),
            "node_id": node.id,
            "node_type": "task",
            "action": "completed"
        })
        
    async def _execute_gateway_node(self, instance: ProcessInstance, definition: ProcessDefinition, node: ProcessNode) -> None:
        """æ‰§è¡Œç½‘å…³èŠ‚ç‚¹"""
        # æ¶ˆè´¹ä»¤ç‰Œ
        tokens = instance.token_positions[node.id]
        if tokens:
            tokens.pop(0)
            
        output_connections = [conn for conn in definition.connections if conn.source_node == node.id]
        
        if node.gateway_type == GatewayType.EXCLUSIVE:
            # æ’ä»–ç½‘å…³ï¼šé€‰æ‹©ä¸€ä¸ªè¾“å‡º
            for connection in output_connections:
                if self._evaluate_condition(connection.condition, instance.variables):
                    self._add_token(instance, connection.target_node)
                    break
                    
        elif node.gateway_type == GatewayType.PARALLEL:
            # å¹¶è¡Œç½‘å…³ï¼šæ‰€æœ‰è¾“å‡º
            for connection in output_connections:
                self._add_token(instance, connection.target_node)
                
        elif node.gateway_type == GatewayType.INCLUSIVE:
            # åŒ…å®¹ç½‘å…³ï¼šæ»¡è¶³æ¡ä»¶çš„è¾“å‡º
            for connection in output_connections:
                if self._evaluate_condition(connection.condition, instance.variables):
                    self._add_token(instance, connection.target_node)
                    
    def _evaluate_condition(self, condition: Optional[str], variables: Dict[str, Any]) -> bool:
        """è¯„ä¼°æ¡ä»¶"""
        if not condition:
            return True
            
        try:
            # ç®€å•çš„æ¡ä»¶è¯„ä¼°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨æ›´å®‰å…¨çš„è¡¨è¾¾å¼è§£æå™¨
            return eval(condition, {"__builtins__": {}}, variables)
        except Exception:
            return False
            
    def _add_token(self, instance: ProcessInstance, node_id: str) -> None:
        """æ·»åŠ ä»¤ç‰Œ"""
        if node_id not in instance.token_positions:
            instance.token_positions[node_id] = []
        instance.token_positions[node_id].append(f"token_{uuid.uuid4()}")
        
    def _is_completed(self, instance: ProcessInstance, definition: ProcessDefinition) -> bool:
        """æ£€æŸ¥æ˜¯å¦å®Œæˆ"""
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»¤ç‰Œåœ¨ç»“æŸèŠ‚ç‚¹
        end_nodes = [node_id for node_id, node in definition.nodes.items() 
                    if node.node_type == NodeType.END]
        
        for end_node in end_nodes:
            if end_node in instance.token_positions and instance.token_positions[end_node]:
                return True
        return False
        
    def get_instance(self, instance_id: str) -> Optional[ProcessInstance]:
        """è·å–ä¸šåŠ¡æµç¨‹å®ä¾‹"""
        return self.instances.get(instance_id)
        
    def list_instances(self, status: Optional[WorkflowStatus] = None) -> List[ProcessInstance]:
        """åˆ—å‡ºä¸šåŠ¡æµç¨‹å®ä¾‹"""
        instances = list(self.instances.values())
        if status:
            instances = [i for i in instances if i.status == status]
        return instances
```

## ğŸ“Š æ€§èƒ½åˆ†æ

### å·¥ä½œæµå¤æ‚åº¦

**çŠ¶æ€ç©ºé—´å¤æ‚åº¦**ï¼š$Complexity(WF) = |S| \times |T| \times |E|$

**æ‰§è¡Œè·¯å¾„æ•°é‡**ï¼š$PathCount(WF) = \sum_{s \in S} \sum_{t \in T} |\{s' | (s, t, s') \in I\}|$

### æ€§èƒ½æŒ‡æ ‡

**ååé‡**ï¼š$Throughput = \frac{Completed\_Workflows}{Time}$

**å¹³å‡æ‰§è¡Œæ—¶é—´**ï¼š$AvgExecutionTime = \frac{\sum_{i=1}^{n} ExecutionTime_i}{n}$

**èµ„æºåˆ©ç”¨ç‡**ï¼š$ResourceUtilization = \frac{Active\_Resources}{Total\_Resources}$

## ğŸ›¡ï¸ é”™è¯¯å¤„ç†

### å¼‚å¸¸å¤„ç†ç­–ç•¥

```python
class ErrorHandlingStrategy:
    """é”™è¯¯å¤„ç†ç­–ç•¥"""
    
    def __init__(self):
        self.retry_policies: Dict[str, RetryPolicy] = {}
        self.fallback_handlers: Dict[str, Callable] = {}
        self.error_notifiers: List[Callable] = []
        
    def add_retry_policy(self, task_type: str, policy: RetryPolicy) -> None:
        """æ·»åŠ é‡è¯•ç­–ç•¥"""
        self.retry_policies[task_type] = policy
        
    def add_fallback_handler(self, task_type: str, handler: Callable) -> None:
        """æ·»åŠ å›é€€å¤„ç†å™¨"""
        self.fallback_handlers[task_type] = handler
        
    def add_error_notifier(self, notifier: Callable) -> None:
        """æ·»åŠ é”™è¯¯é€šçŸ¥å™¨"""
        self.error_notifiers.append(notifier)
        
    async def handle_error(self, task_type: str, error: Exception, context: Dict[str, Any]) -> None:
        """å¤„ç†é”™è¯¯"""
        # å‘é€é€šçŸ¥
        for notifier in self.error_notifiers:
            try:
                await notifier(task_type, error, context)
            except Exception as e:
                logging.error(f"Error notifier failed: {e}")
                
        # æ‰§è¡Œå›é€€å¤„ç†
        if task_type in self.fallback_handlers:
            try:
                await self.fallback_handlers[task_type](error, context)
            except Exception as e:
                logging.error(f"Fallback handler failed: {e}")
```

## ğŸ“‹ æœ€ä½³å®è·µ

### 1. å·¥ä½œæµè®¾è®¡åŸåˆ™

- **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªå·¥ä½œæµåªå¤„ç†ä¸€ä¸ªä¸šåŠ¡åœºæ™¯
- **å¯é‡ç”¨æ€§**ï¼šè®¾è®¡å¯é‡ç”¨çš„å·¥ä½œæµç»„ä»¶
- **å¯è§‚æµ‹æ€§**ï¼šæä¾›è¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—å’Œç›‘æ§
- **å®¹é”™æ€§**ï¼šå®ç°å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶

### 2. æ€§èƒ½ä¼˜åŒ–

- **å¹¶è¡Œæ‰§è¡Œ**ï¼šåˆ©ç”¨å¹¶è¡Œæ€§æé«˜æ‰§è¡Œæ•ˆç‡
- **èµ„æºæ± åŒ–**ï¼šå¤ç”¨è®¡ç®—èµ„æº
- **ç¼“å­˜æœºåˆ¶**ï¼šç¼“å­˜ä¸­é—´ç»“æœ
- **è´Ÿè½½å‡è¡¡**ï¼šåˆ†æ•£å·¥ä½œè´Ÿè½½

### 3. ç›‘æ§å’Œè°ƒè¯•

```python
class WorkflowMonitor:
    """å·¥ä½œæµç›‘æ§å™¨"""
    
    def __init__(self):
        self.metrics: Dict[str, List[float]] = {}
        self.alerts: List[Dict[str, Any]] = []
        
    def record_metric(self, metric_name: str, value: float) -> None:
        """è®°å½•æŒ‡æ ‡"""
        if metric_name not in self.metrics:
            self.metrics[metric_name] = []
        self.metrics[metric_name].append(value)
        
    def get_average_metric(self, metric_name: str) -> float:
        """è·å–å¹³å‡æŒ‡æ ‡"""
        if metric_name not in self.metrics or not self.metrics[metric_name]:
            return 0.0
        return sum(self.metrics[metric_name]) / len(self.metrics[metric_name])
        
    def add_alert(self, alert_type: str, message: str, severity: str = "warning") -> None:
        """æ·»åŠ å‘Šè­¦"""
        self.alerts.append({
            "type": alert_type,
            "message": message,
            "severity": severity,
            "timestamp": datetime.now().isoformat()
        })
        
    def get_metrics_summary(self) -> Dict[str, Dict[str, float]]:
        """è·å–æŒ‡æ ‡æ‘˜è¦"""
        summary = {}
        for metric_name, values in self.metrics.items():
            if values:
                summary[metric_name] = {
                    "average": sum(values) / len(values),
                    "min": min(values),
                    "max": max(values),
                    "count": len(values)
                }
        return summary
```

## ğŸ”— ç›¸å…³é“¾æ¥

- [05-æ¶æ„é¢†åŸŸ/05-02-å¾®æœåŠ¡æ¶æ„/05-02-01-å¾®æœåŠ¡åŸºç¡€.md](../05-02-å¾®æœåŠ¡æ¶æ„/05-02-01-å¾®æœåŠ¡åŸºç¡€.md) - å¾®æœåŠ¡æ¶æ„åŸºç¡€
- [05-æ¶æ„é¢†åŸŸ/05-03-CI_CD/05-03-01-CI_CDåŸºç¡€.md](../05-03-CI_CD/05-03-01-CI_CDåŸºç¡€.md) - CI/CDåŸºç¡€
- [02-ç†è®ºåŸºç¡€/02-01-ç®—æ³•ç†è®º/02-01-01-ç®—æ³•åŸºç¡€.md](../../02-ç†è®ºåŸºç¡€/02-01-ç®—æ³•ç†è®º/02-01-01-ç®—æ³•åŸºç¡€.md) - ç®—æ³•ç†è®ºåŸºç¡€

---

*æœ¬æ–‡æ¡£æä¾›äº†å·¥ä½œæµæ¶æ„çš„å®Œæ•´ç†è®ºåŸºç¡€å’ŒPythonå®ç°ï¼ŒåŒ…æ‹¬å·¥ä½œæµå¼•æ“ã€çŠ¶æ€æœºã€ä¸šåŠ¡æµç¨‹å»ºæ¨¡ç­‰æ ¸å¿ƒç»„ä»¶ã€‚*
