# Pandas æ•°æ®åˆ†æ

**å¼ºå¤§çš„æ•°æ®åˆ†æå’Œå¤„ç†åº“**

---

## ğŸ“‹ æ¦‚è¿°

Pandasæ˜¯Pythonä¸­æœ€æµè¡Œçš„æ•°æ®åˆ†æåº“ï¼Œæä¾›é«˜æ€§èƒ½ã€æ˜“ç”¨çš„æ•°æ®ç»“æ„å’Œæ•°æ®åˆ†æå·¥å…·ã€‚

### æ ¸å¿ƒç‰¹æ€§

- ğŸ“Š **DataFrame** - å¼ºå¤§çš„è¡¨æ ¼æ•°æ®ç»“æ„
- ğŸ”„ **æ•°æ®æ¸…æ´—** - å¤„ç†ç¼ºå¤±å€¼ã€é‡å¤æ•°æ®
- ğŸ“ˆ **æ•°æ®åˆ†æ** - åˆ†ç»„ã€èšåˆã€é€è§†
- ğŸ“ **æ–‡ä»¶I/O** - æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼
- â±ï¸ **æ—¶é—´åºåˆ—** - å¼ºå¤§çš„æ—¶é—´åºåˆ—åŠŸèƒ½

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
uv add pandas
```

### Hello Pandas

```python
import pandas as pd

# åˆ›å»ºDataFrame
df = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie'],
    'age': [25, 30, 35],
    'city': ['NYC', 'LA', 'Chicago']
})

print(df)
```

---

## ğŸ’» æ ¸å¿ƒæ•°æ®ç»“æ„

### 1. Series (ä¸€ç»´)

```python
# ä»åˆ—è¡¨åˆ›å»º
s = pd.Series([1, 2, 3, 4, 5])

# è‡ªå®šä¹‰ç´¢å¼•
s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])

# ä»å­—å…¸åˆ›å»º
s = pd.Series({'a': 1, 'b': 2, 'c': 3})

# è®¿é—®å…ƒç´ 
print(s['a'])      # 1
print(s[0])        # 1
```

### 2. DataFrame (äºŒç»´)

```python
# ä»å­—å…¸åˆ›å»º
df = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [4, 5, 6],
    'C': [7, 8, 9]
})

# ä»åˆ—è¡¨åˆ›å»º
df = pd.DataFrame(
    [[1, 4, 7], [2, 5, 8], [3, 6, 9]],
    columns=['A', 'B', 'C']
)

# æŸ¥çœ‹æ•°æ®
print(df.head())       # å‰5è¡Œ
print(df.tail(3))      # å3è¡Œ
print(df.info())       # ä¿¡æ¯
print(df.describe())   # ç»Ÿè®¡æ‘˜è¦
```

---

## ğŸ“ æ•°æ®è¯»å–

### è¯»å–æ–‡ä»¶

```python
# CSV
df = pd.read_csv('data.csv')
df = pd.read_csv('data.csv', sep=';', encoding='utf-8')

# Excel
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')

# JSON
df = pd.read_json('data.json')

# SQL
import sqlite3
conn = sqlite3.connect('database.db')
df = pd.read_sql_query('SELECT * FROM users', conn)

# Parquet (æ¨èï¼Œæœ€å¿«)
df = pd.read_parquet('data.parquet')
```

### ä¿å­˜æ–‡ä»¶

```python
# CSV
df.to_csv('output.csv', index=False)

# Excel
df.to_excel('output.xlsx', sheet_name='Data', index=False)

# JSON
df.to_json('output.json', orient='records')

# Parquet
df.to_parquet('output.parquet')
```

---

## ğŸ” æ•°æ®é€‰æ‹©

### åˆ—é€‰æ‹©

```python
# å•åˆ—
df['A']          # Series
df.A             # Series (ä»…å½“åˆ—åæ˜¯æœ‰æ•ˆæ ‡è¯†ç¬¦æ—¶)

# å¤šåˆ—
df[['A', 'B']]   # DataFrame
```

### è¡Œé€‰æ‹©

```python
# iloc - ä½ç½®ç´¢å¼•
df.iloc[0]          # ç¬¬1è¡Œ
df.iloc[0:3]        # å‰3è¡Œ
df.iloc[[0, 2, 4]]  # æŒ‡å®šè¡Œ

# loc - æ ‡ç­¾ç´¢å¼•
df.loc[0]           # ç´¢å¼•ä¸º0çš„è¡Œ
df.loc[0:2]         # ç´¢å¼•0åˆ°2çš„è¡Œ

# å¸ƒå°”ç´¢å¼•
df[df['age'] > 25]
df[(df['age'] > 25) & (df['city'] == 'NYC')]
```

### æ¡ä»¶é€‰æ‹©

```python
# queryæ–¹æ³•
df.query('age > 25 and city == "NYC"')

# isin
df[df['city'].isin(['NYC', 'LA'])]

# between
df[df['age'].between(25, 35)]
```

---

## ğŸ”„ æ•°æ®æ¸…æ´—

### å¤„ç†ç¼ºå¤±å€¼

```python
# æ£€æŸ¥ç¼ºå¤±å€¼
df.isnull()          # è¿”å›å¸ƒå°”DataFrame
df.isnull().sum()    # æ¯åˆ—ç¼ºå¤±å€¼æ•°é‡

# åˆ é™¤ç¼ºå¤±å€¼
df.dropna()          # åˆ é™¤ä»»ä½•åŒ…å«NaNçš„è¡Œ
df.dropna(axis=1)    # åˆ é™¤ä»»ä½•åŒ…å«NaNçš„åˆ—
df.dropna(subset=['age'])  # åˆ é™¤ageåˆ—ä¸ºNaNçš„è¡Œ

# å¡«å……ç¼ºå¤±å€¼
df.fillna(0)         # ç”¨0å¡«å……
df.fillna(method='ffill')  # å‰å‘å¡«å……
df.fillna(method='bfill')  # åå‘å¡«å……
df['age'].fillna(df['age'].mean())  # ç”¨å‡å€¼å¡«å……
```

### å¤„ç†é‡å¤å€¼

```python
# æ£€æŸ¥é‡å¤
df.duplicated()      # è¿”å›å¸ƒå°”Series

# åˆ é™¤é‡å¤
df.drop_duplicates()
df.drop_duplicates(subset=['name'], keep='first')
```

### æ•°æ®ç±»å‹è½¬æ¢

```python
# æŸ¥çœ‹ç±»å‹
df.dtypes

# è½¬æ¢ç±»å‹
df['age'] = df['age'].astype(int)
df['date'] = pd.to_datetime(df['date'])
df['category'] = df['category'].astype('category')
```

---

## ğŸ“Š æ•°æ®è½¬æ¢

### æ·»åŠ /åˆ é™¤åˆ—

```python
# æ·»åŠ åˆ—
df['new_col'] = df['A'] + df['B']
df['age_group'] = df['age'].apply(lambda x: 'young' if x < 30 else 'old')

# åˆ é™¤åˆ—
df.drop('new_col', axis=1, inplace=True)
df.drop(['col1', 'col2'], axis=1, inplace=True)
```

### é‡å‘½å

```python
# é‡å‘½ååˆ—
df.rename(columns={'old_name': 'new_name'}, inplace=True)

# é‡å‘½åç´¢å¼•
df.rename(index={0: 'first', 1: 'second'}, inplace=True)
```

### åº”ç”¨å‡½æ•°

```python
# apply - å¯¹åˆ—/è¡Œåº”ç”¨å‡½æ•°
df['age'].apply(lambda x: x * 2)
df.apply(lambda row: row['A'] + row['B'], axis=1)

# applymap - å¯¹æ¯ä¸ªå…ƒç´ åº”ç”¨å‡½æ•°
df.applymap(lambda x: x * 2)

# map - æ˜ å°„å€¼
df['grade'] = df['score'].map({100: 'A', 90: 'B', 80: 'C'})
```

---

## ğŸ“ˆ åˆ†ç»„å’Œèšåˆ

### åˆ†ç»„æ“ä½œ

```python
# ç®€å•åˆ†ç»„
grouped = df.groupby('city')

# èšåˆå‡½æ•°
grouped.mean()
grouped.sum()
grouped.count()
grouped.size()

# å¤šåˆ—åˆ†ç»„
df.groupby(['city', 'gender']).mean()

# å¤šä¸ªèšåˆå‡½æ•°
df.groupby('city').agg({
    'age': ['mean', 'min', 'max'],
    'salary': 'sum'
})

# è‡ªå®šä¹‰èšåˆ
df.groupby('city').agg(
    avg_age=('age', 'mean'),
    total_salary=('salary', 'sum'),
    count=('name', 'count')
)
```

### é€è§†è¡¨

```python
# é€è§†è¡¨
pivot = pd.pivot_table(
    df,
    values='salary',
    index='city',
    columns='gender',
    aggfunc='mean'
)

# äº¤å‰è¡¨
crosstab = pd.crosstab(
    df['city'],
    df['gender'],
    values=df['salary'],
    aggfunc='mean'
)
```

---

## ğŸ”— åˆå¹¶æ•°æ®

### concat - è¿æ¥

```python
# å‚ç›´è¿æ¥
result = pd.concat([df1, df2])

# æ°´å¹³è¿æ¥
result = pd.concat([df1, df2], axis=1)
```

### merge - åˆå¹¶

```python
# Inner join
merged = pd.merge(df1, df2, on='key')

# Left join
merged = pd.merge(df1, df2, on='key', how='left')

# Right join
merged = pd.merge(df1, df2, on='key', how='right')

# Outer join
merged = pd.merge(df1, df2, on='key', how='outer')

# å¤šé”®åˆå¹¶
merged = pd.merge(df1, df2, on=['key1', 'key2'])
```

### join

```python
# åŸºäºç´¢å¼•join
result = df1.join(df2)
result = df1.join(df2, how='left')
```

---

## â±ï¸ æ—¶é—´åºåˆ—

### æ—¥æœŸå¤„ç†

```python
# åˆ›å»ºæ—¥æœŸèŒƒå›´
dates = pd.date_range('2025-01-01', periods=10, freq='D')

# è§£ææ—¥æœŸ
df['date'] = pd.to_datetime(df['date_string'])

# æå–æ—¥æœŸç»„ä»¶
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day
df['weekday'] = df['date'].dt.day_name()

# æ—¶é—´å·®
df['days_diff'] = (df['end_date'] - df['start_date']).dt.days
```

### æ—¶é—´åºåˆ—æ“ä½œ

```python
# è®¾ç½®æ—¥æœŸç´¢å¼•
df.set_index('date', inplace=True)

# é‡é‡‡æ ·
daily_data = hourly_data.resample('D').mean()
monthly_data = daily_data.resample('M').sum()

# æ»šåŠ¨çª—å£
rolling_mean = df['value'].rolling(window=7).mean()

# ç§»ä½
df['prev_value'] = df['value'].shift(1)
df['pct_change'] = df['value'].pct_change()
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. ä½¿ç”¨å‘é‡åŒ–æ“ä½œ

```python
# âŒ å·® - å¾ªç¯
for i in range(len(df)):
    df.loc[i, 'result'] = df.loc[i, 'A'] + df.loc[i, 'B']

# âœ… å¥½ - å‘é‡åŒ–
df['result'] = df['A'] + df['B']
```

### 2. é€‰æ‹©åˆé€‚çš„æ•°æ®ç±»å‹

```python
# å‡å°‘å†…å­˜ä½¿ç”¨
df['category'] = df['category'].astype('category')
df['int_col'] = df['int_col'].astype('int32')  # è€Œä¸æ˜¯int64
```

### 3. ä½¿ç”¨Parquetæ ¼å¼

```python
# âœ… Parquet - å¿«ä¸”å‹ç¼©
df.to_parquet('data.parquet')
df = pd.read_parquet('data.parquet')

# âŒ CSV - æ…¢ä¸”å ç©ºé—´
df.to_csv('data.csv')
df = pd.read_csv('data.csv')
```

---

## ğŸ“š å®ç”¨æŠ€å·§

### é“¾å¼æ“ä½œ

```python
result = (df
    .query('age > 25')
    .groupby('city')
    .agg({'salary': 'mean'})
    .sort_values('salary', ascending=False)
    .head(10)
)
```

### æ ·å¼å’Œæ ¼å¼åŒ–

```python
# æ•°å€¼æ ¼å¼åŒ–
df.style.format({'price': '${:.2f}', 'percentage': '{:.1%}'})

# é«˜äº®æ˜¾ç¤º
df.style.highlight_max(axis=0)
df.style.highlight_min(axis=1)

# æ¡ä»¶æ ¼å¼åŒ–
def color_negative_red(val):
    color = 'red' if val < 0 else 'black'
    return f'color: {color}'

df.style.applymap(color_negative_red)
```

---

## ğŸ†š Pandas vs Polars

| ç‰¹æ€§ | Pandas | Polars |
|------|--------|--------|
| æ€§èƒ½ | â­â­â­ | â­â­â­â­â­ |
| å†…å­˜æ•ˆç‡ | â­â­â­ | â­â­â­â­â­ |
| æ˜“ç”¨æ€§ | â­â­â­â­â­ | â­â­â­â­ |
| ç”Ÿæ€ç³»ç»Ÿ | â­â­â­â­â­ | â­â­â­ |
| æ–‡æ¡£ | â­â­â­â­â­ | â­â­â­â­ |

**å»ºè®®**: æ–°é¡¹ç›®ä¼˜å…ˆä½¿ç”¨Polarsï¼Œç°æœ‰é¡¹ç›®å¯ç»§ç»­ä½¿ç”¨Pandas

---

## ğŸ”— ç›¸å…³èµ„æº

- [å®˜æ–¹æ–‡æ¡£](https://pandas.pydata.org/docs/)
- [10åˆ†é’Ÿå…¥é—¨Pandas](https://pandas.pydata.org/docs/user_guide/10min.html)
- [Pandas Cookbook](https://pandas.pydata.org/docs/user_guide/cookbook.html)

---

**æœ€åæ›´æ–°**: 2025å¹´10æœˆ28æ—¥

