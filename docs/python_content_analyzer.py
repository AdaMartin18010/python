#!/usr/bin/env python3
"""
Pythonå†…å®¹åˆ†æå·¥å…·

ç”¨äºåˆ†æç°æœ‰æ–‡æ¡£ä¸­ä¸Pythonç›¸å…³çš„å†…å®¹ï¼Œå¹¶ç”Ÿæˆè¿ç§»å»ºè®®ã€‚
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Tuple, Set
from collections import defaultdict
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class PythonContentAnalyzer:
    """Pythonå†…å®¹åˆ†æå™¨"""
    
    def __init__(self, base_path: str = "docs"):
        self.base_path = Path(base_path)
        
        # Pythonç›¸å…³å…³é”®è¯
        self.python_keywords = {
            'python', 'py', 'pip', 'poetry', 'uv', 'conda', 'virtualenv',
            'django', 'flask', 'fastapi', 'tornado', 'sqlalchemy',
            'pandas', 'numpy', 'matplotlib', 'seaborn', 'scikit-learn',
            'tensorflow', 'pytorch', 'keras', 'jupyter', 'ipython',
            'pytest', 'unittest', 'nose', 'coverage', 'black', 'flake8',
            'mypy', 'pylint', 'sphinx', 'docstring', 'pep8', 'pep',
            'async', 'await', 'asyncio', 'threading', 'multiprocessing',
            'decorator', 'generator', 'iterator', 'contextmanager',
            'metaclass', 'descriptor', 'property', 'slots', 'dataclass',
            'type_hint', 'typing', 'mypy', 'pydantic', 'marshmallow',
            'celery', 'redis', 'postgresql', 'mysql', 'sqlite',
            'docker', 'kubernetes', 'ansible', 'salt', 'jenkins',
            'git', 'github', 'gitlab', 'bitbucket', 'travis', 'circleci'
        }
        
        # æ–‡ä»¶ç±»å‹æ˜ å°„
        self.file_type_mapping = {
            'python': ['.py', '.pyx', '.pyi'],
            'markdown': ['.md', '.markdown'],
            'documentation': ['.rst', '.txt', '.adoc'],
            'config': ['.toml', '.yaml', '.yml', '.json', '.ini', '.cfg'],
            'other': ['.sh', '.bat', '.ps1', '.js', '.html', '.css']
        }
        
        # å†…å®¹åˆ†ç±»è§„åˆ™
        self.content_categories = {
            'core_python': {
                'keywords': ['python', 'py', 'syntax', 'grammar', 'language'],
                'patterns': [r'python\s+[0-9]+\.[0-9]+', r'pep\s+[0-9]+']
            },
            'ecosystem': {
                'keywords': ['pip', 'poetry', 'uv', 'conda', 'virtualenv', 'requirements'],
                'patterns': [r'pip\s+install', r'poetry\s+add', r'uv\s+pip']
            },
            'web_frameworks': {
                'keywords': ['django', 'flask', 'fastapi', 'tornado', 'bottle'],
                'patterns': [r'from\s+django', r'from\s+flask', r'from\s+fastapi']
            },
            'data_science': {
                'keywords': ['pandas', 'numpy', 'matplotlib', 'seaborn', 'scikit-learn'],
                'patterns': [r'import\s+pandas', r'import\s+numpy', r'import\s+sklearn']
            },
            'machine_learning': {
                'keywords': ['tensorflow', 'pytorch', 'keras', 'scikit-learn', 'xgboost'],
                'patterns': [r'import\s+tensorflow', r'import\s+torch', r'import\s+keras']
            },
            'testing': {
                'keywords': ['pytest', 'unittest', 'nose', 'coverage', 'mock'],
                'patterns': [r'import\s+pytest', r'import\s+unittest', r'def\s+test_']
            },
            'devops': {
                'keywords': ['docker', 'kubernetes', 'ansible', 'jenkins', 'git'],
                'patterns': [r'docker\s+run', r'kubectl', r'ansible-playbook']
            },
            'security': {
                'keywords': ['security', 'cryptography', 'hashlib', 'ssl', 'tls'],
                'patterns': [r'import\s+cryptography', r'import\s+hashlib', r'import\s+ssl']
            },
            'performance': {
                'keywords': ['performance', 'profiling', 'cprofile', 'memory', 'optimization'],
                'patterns': [r'import\s+cProfile', r'import\s+memory_profiler']
            }
        }

    def analyze_directory(self) -> Dict:
        """åˆ†ææ•´ä¸ªç›®å½•ç»“æ„"""
        logger.info("å¼€å§‹åˆ†æç›®å½•ç»“æ„...")
        
        analysis_result = {
            'total_files': 0,
            'python_files': 0,
            'markdown_files': 0,
            'python_related_files': 0,
            'file_types': defaultdict(int),
            'python_keywords_found': set(),
            'content_categories': defaultdict(list),
            'migration_candidates': [],
            'removal_candidates': [],
            'directory_structure': {},
            'file_details': []
        }
        
        # éå†æ‰€æœ‰æ–‡ä»¶
        for file_path in self.base_path.rglob('*'):
            if file_path.is_file():
                analysis_result['total_files'] += 1
                file_info = self._analyze_file(file_path)
                analysis_result['file_details'].append(file_info)
                
                # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
                file_ext = file_path.suffix.lower()
                analysis_result['file_types'][file_ext] += 1
                
                # ç»Ÿè®¡Pythonç›¸å…³æ–‡ä»¶
                if file_ext in self.file_type_mapping['python']:
                    analysis_result['python_files'] += 1
                elif file_ext in self.file_type_mapping['markdown']:
                    analysis_result['markdown_files'] += 1
                
                # åˆ†æå†…å®¹ç›¸å…³æ€§
                if file_info['python_related']:
                    analysis_result['python_related_files'] += 1
                    analysis_result['migration_candidates'].append(file_info)
                    analysis_result['python_keywords_found'].update(file_info['python_keywords'])
                    
                    # åˆ†ç±»å†…å®¹
                    for category, keywords in file_info['categories'].items():
                        if keywords:
                            analysis_result['content_categories'][category].append(file_info)
                else:
                    analysis_result['removal_candidates'].append(file_info)
        
        # åˆ†æç›®å½•ç»“æ„
        analysis_result['directory_structure'] = self._analyze_directory_structure()
        
        return analysis_result

    def _analyze_file(self, file_path: Path) -> Dict:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        file_info = {
            'path': str(file_path.relative_to(self.base_path)),
            'name': file_path.name,
            'size': file_path.stat().st_size,
            'extension': file_path.suffix.lower(),
            'python_related': False,
            'python_keywords': set(),
            'categories': defaultdict(set),
            'content_score': 0,
            'migration_target': None
        }
        
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read().lower()
            
            # æ£€æŸ¥Pythonå…³é”®è¯
            found_keywords = set()
            for keyword in self.python_keywords:
                if keyword in content:
                    found_keywords.add(keyword)
            
            file_info['python_keywords'] = found_keywords
            
            # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
            if found_keywords:
                file_info['python_related'] = True
                file_info['content_score'] = len(found_keywords) / len(self.python_keywords)
            
            # åˆ†ç±»å†…å®¹
            for category, rules in self.content_categories.items():
                category_keywords = set()
                for keyword in rules['keywords']:
                    if keyword in content:
                        category_keywords.add(keyword)
                
                for pattern in rules['patterns']:
                    if re.search(pattern, content, re.IGNORECASE):
                        category_keywords.add(pattern)
                
                if category_keywords:
                    file_info['categories'][category] = category_keywords
            
            # ç¡®å®šè¿ç§»ç›®æ ‡
            file_info['migration_target'] = self._determine_migration_target(file_info)
            
        except Exception as e:
            logger.warning(f"åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return file_info

    def _determine_migration_target(self, file_info: Dict) -> str:
        """ç¡®å®šæ–‡ä»¶è¿ç§»ç›®æ ‡"""
        categories = file_info['categories']
        
        # æ ¹æ®å†…å®¹åˆ†ç±»ç¡®å®šè¿ç§»ç›®æ ‡
        if 'core_python' in categories:
            return '01-PythonåŸºç¡€'
        elif 'ecosystem' in categories:
            return '03-Pythonç”Ÿæ€ç³»ç»Ÿ'
        elif 'web_frameworks' in categories:
            return '08-Python Webå¼€å‘'
        elif 'data_science' in categories or 'machine_learning' in categories:
            return '09-Pythonæ•°æ®ç§‘å­¦'
        elif 'testing' in categories:
            return '03-Pythonç”Ÿæ€ç³»ç»Ÿ/03-03-Pythonæµ‹è¯•æ¡†æ¶'
        elif 'devops' in categories:
            return '10-Pythonè‡ªåŠ¨åŒ–è¿ç»´'
        elif 'security' in categories:
            return '06-Pythonå®‰å…¨ç¼–ç¨‹'
        elif 'performance' in categories:
            return '05-Pythonæ€§èƒ½ä¼˜åŒ–'
        else:
            return '12-Pythonæœ€ä½³å®è·µ'

    def _analyze_directory_structure(self) -> Dict:
        """åˆ†æç›®å½•ç»“æ„"""
        structure = {}
        
        for item in self.base_path.rglob('*'):
            if item.is_dir():
                relative_path = str(item.relative_to(self.base_path))
                structure[relative_path] = {
                    'files': len(list(item.glob('*.md'))) + len(list(item.glob('*.py'))),
                    'subdirs': len([x for x in item.iterdir() if x.is_dir()]),
                    'python_related': self._is_directory_python_related(item)
                }
        
        return structure

    def _is_directory_python_related(self, dir_path: Path) -> bool:
        """åˆ¤æ–­ç›®å½•æ˜¯å¦ä¸Pythonç›¸å…³"""
        python_files = list(dir_path.rglob('*.py'))
        markdown_files = list(dir_path.rglob('*.md'))
        
        # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«Pythonå…³é”®è¯
        for file_path in python_files + markdown_files:
            if any(keyword in file_path.name.lower() for keyword in self.python_keywords):
                return True
        
        return False

    def generate_migration_report(self, analysis_result: Dict) -> str:
        """ç”Ÿæˆè¿ç§»æŠ¥å‘Š"""
        report = []
        report.append("# Pythonå†…å®¹åˆ†ææŠ¥å‘Š")
        report.append("")
        
        # æ€»ä½“ç»Ÿè®¡
        report.append("## ğŸ“Š æ€»ä½“ç»Ÿè®¡")
        report.append("")
        report.append(f"- **æ€»æ–‡ä»¶æ•°**: {analysis_result['total_files']}")
        report.append(f"- **Pythonæ–‡ä»¶æ•°**: {analysis_result['python_files']}")
        report.append(f"- **Markdownæ–‡ä»¶æ•°**: {analysis_result['markdown_files']}")
        report.append(f"- **Pythonç›¸å…³æ–‡ä»¶æ•°**: {analysis_result['python_related_files']}")
        report.append(f"- **Pythonç›¸å…³æ€§æ¯”ä¾‹**: {analysis_result['python_related_files']/analysis_result['total_files']*100:.1f}%")
        report.append("")
        
        # æ–‡ä»¶ç±»å‹ç»Ÿè®¡
        report.append("## ğŸ“ æ–‡ä»¶ç±»å‹ç»Ÿè®¡")
        report.append("")
        for ext, count in sorted(analysis_result['file_types'].items(), key=lambda x: x[1], reverse=True):
            report.append(f"- **{ext}**: {count} ä¸ªæ–‡ä»¶")
        report.append("")
        
        # å†…å®¹åˆ†ç±»ç»Ÿè®¡
        report.append("## ğŸ·ï¸ å†…å®¹åˆ†ç±»ç»Ÿè®¡")
        report.append("")
        for category, files in analysis_result['content_categories'].items():
            report.append(f"- **{category}**: {len(files)} ä¸ªæ–‡ä»¶")
        report.append("")
        
        # è¿ç§»å€™é€‰æ–‡ä»¶
        report.append("## âœ… è¿ç§»å€™é€‰æ–‡ä»¶")
        report.append("")
        for file_info in analysis_result['migration_candidates'][:20]:  # æ˜¾ç¤ºå‰20ä¸ª
            report.append(f"- `{file_info['path']}` -> `{file_info['migration_target']}` (åˆ†æ•°: {file_info['content_score']:.2f})")
        report.append("")
        
        # ç§»é™¤å€™é€‰æ–‡ä»¶
        report.append("## âŒ ç§»é™¤å€™é€‰æ–‡ä»¶")
        report.append("")
        for file_info in analysis_result['removal_candidates'][:20]:  # æ˜¾ç¤ºå‰20ä¸ª
            report.append(f"- `{file_info['path']}` (æ— Pythonç›¸å…³å†…å®¹)")
        report.append("")
        
        # Pythonå…³é”®è¯ç»Ÿè®¡
        report.append("## ğŸ” å‘ç°çš„Pythonå…³é”®è¯")
        report.append("")
        for keyword in sorted(analysis_result['python_keywords_found']):
            report.append(f"- `{keyword}`")
        report.append("")
        
        # è¿ç§»å»ºè®®
        report.append("## ğŸš€ è¿ç§»å»ºè®®")
        report.append("")
        report.append("### 1. é«˜ä¼˜å…ˆçº§è¿ç§»")
        high_priority = [f for f in analysis_result['migration_candidates'] if f['content_score'] > 0.5]
        for file_info in high_priority[:10]:
            report.append(f"- `{file_info['path']}` -> `{file_info['migration_target']}`")
        report.append("")
        
        report.append("### 2. ä¸­ä¼˜å…ˆçº§è¿ç§»")
        medium_priority = [f for f in analysis_result['migration_candidates'] if 0.2 < f['content_score'] <= 0.5]
        for file_info in medium_priority[:10]:
            report.append(f"- `{file_info['path']}` -> `{file_info['migration_target']}`")
        report.append("")
        
        report.append("### 3. å¯ç§»é™¤å†…å®¹")
        for file_info in analysis_result['removal_candidates'][:10]:
            report.append(f"- `{file_info['path']}`")
        report.append("")
        
        return "\n".join(report)

    def save_analysis_result(self, analysis_result: Dict, output_file: str = "python_analysis_result.json"):
        """ä¿å­˜åˆ†æç»“æœåˆ°JSONæ–‡ä»¶"""
        # è½¬æ¢setä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
        serializable_result = {}
        for key, value in analysis_result.items():
            if isinstance(value, set):
                serializable_result[key] = list(value)
            elif isinstance(value, defaultdict):
                serializable_result[key] = dict(value)
            else:
                serializable_result[key] = value
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_result, f, indent=2, ensure_ascii=False)
        
        logger.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    def generate_migration_script(self, analysis_result: Dict) -> str:
        """ç”Ÿæˆè¿ç§»è„šæœ¬"""
        script_lines = [
            "#!/bin/bash",
            "# Pythonå†…å®¹è¿ç§»è„šæœ¬",
            "# åŸºäºåˆ†æç»“æœè‡ªåŠ¨ç”Ÿæˆ",
            "",
            "echo 'å¼€å§‹Pythonå†…å®¹è¿ç§»...'",
            "",
            "# åˆ›å»ºå¤‡ä»½",
            f"cp -r {self.base_path} docs_backup_$(date +%Y%m%d)",
            "",
            "# åˆ›å»ºæ–°ç›®å½•ç»“æ„",
            "mkdir -p docs/python_knowledge",
            ""
        ]
        
        # æ·»åŠ è¿ç§»å‘½ä»¤
        for file_info in analysis_result['migration_candidates']:
            if file_info['migration_target']:
                source_path = file_info['path']
                target_path = f"docs/python_knowledge/{file_info['migration_target']}"
                
                script_lines.extend([
                    f"# è¿ç§»: {source_path}",
                    f"mkdir -p {target_path}",
                    f"cp '{source_path}' '{target_path}/'",
                    ""
                ])
        
        script_lines.extend([
            "echo 'è¿ç§»å®Œæˆ!'",
            "echo 'è¯·æ£€æŸ¥è¿ç§»ç»“æœå¹¶æ›´æ–°å¯¼èˆªæ–‡ä»¶'"
        ])
        
        return "\n".join(script_lines)

def main():
    """ä¸»å‡½æ•°"""
    analyzer = PythonContentAnalyzer()
    
    print("Pythonå†…å®¹åˆ†æå·¥å…·")
    print("=" * 50)
    
    # æ‰§è¡Œåˆ†æ
    print("æ­£åœ¨åˆ†æç›®å½•å†…å®¹...")
    analysis_result = analyzer.analyze_directory()
    
    # ç”ŸæˆæŠ¥å‘Š
    print("æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    report = analyzer.generate_migration_report(analysis_result)
    
    # ä¿å­˜æŠ¥å‘Š
    with open("python_analysis_report.md", "w", encoding="utf-8") as f:
        f.write(report)
    
    # ä¿å­˜åˆ†æç»“æœ
    analyzer.save_analysis_result(analysis_result)
    
    # ç”Ÿæˆè¿ç§»è„šæœ¬
    migration_script = analyzer.generate_migration_script(analysis_result)
    with open("migrate_python_content.sh", "w", encoding="utf-8") as f:
        f.write(migration_script)
    
    print("åˆ†æå®Œæˆ!")
    print(f"- åˆ†ææŠ¥å‘Š: python_analysis_report.md")
    print(f"- åˆ†æç»“æœ: python_analysis_result.json")
    print(f"- è¿ç§»è„šæœ¬: migrate_python_content.sh")
    
    # æ˜¾ç¤ºå…³é”®ç»Ÿè®¡
    print("\nå…³é”®ç»Ÿè®¡:")
    print(f"- æ€»æ–‡ä»¶æ•°: {analysis_result['total_files']}")
    print(f"- Pythonç›¸å…³æ–‡ä»¶: {analysis_result['python_related_files']}")
    print(f"- ç›¸å…³æ€§æ¯”ä¾‹: {analysis_result['python_related_files']/analysis_result['total_files']*100:.1f}%")

if __name__ == "__main__":
    main() 